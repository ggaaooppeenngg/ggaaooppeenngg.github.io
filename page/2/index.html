<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="_85tctgPWrqH2EPVuuD5IT6KE-tW8nH0hTISJDMnShg">
  <meta name="baidu-site-verification" content="bb16c5b1fd3302c18e0015bef11eea42">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"ggaaooppeenngg.github.io","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.22.0","exturl":false,"sidebar":{"position":"right","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12,"onmobile":false},"hljswrap":true,"copycode":{"enable":true,"style":"default"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="为什么计算机科学是无限的但生命是有限的">
<meta property="og:type" content="website">
<meta property="og:title" content="ggaaooppeenngg">
<meta property="og:url" content="https://ggaaooppeenngg.github.io/page/2/index.html">
<meta property="og:site_name" content="ggaaooppeenngg">
<meta property="og:description" content="为什么计算机科学是无限的但生命是有限的">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="ggaaooppeenngg">
<meta property="article:tag" content="ggaaooppeenngg,kernel,sysml,golang,python,rust">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://ggaaooppeenngg.github.io/page/2/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/2/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>ggaaooppeenngg</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-62096626-1"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"UA-62096626-1","only_pageview":false,"measure_protocol_api_secret":null}</script>
  <script src="/js/third-party/analytics/google-analytics.js"></script>

  <script src="/js/third-party/analytics/baidu-analytics.js"></script>
  <script async src="https://hm.baidu.com/hm.js?bb16c5b1fd3302c18e0015bef11eea42"></script>







  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">ggaaooppeenngg</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">为什么计算机科学是无限的但生命是有限的</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签<span class="badge">135</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="th fa-fw"></i>分类<span class="badge">14</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档<span class="badge">79</span></a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">ggaaooppeenngg</p>
  <div class="site-description" itemprop="description">为什么计算机科学是无限的但生命是有限的</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">79</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">135</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/ggaaooppeenngg" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;ggaaooppeenngg" rel="noopener me" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:peng.gao.dut@gmail.com" title="E-Mail → mailto:peng.gao.dut@gmail.com" rel="noopener me" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ggaaooppeenngg.github.io/zh-CN/2025/01/07/GaLore%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ggaaooppeenngg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ggaaooppeenngg">
      <meta itemprop="description" content="为什么计算机科学是无限的但生命是有限的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ggaaooppeenngg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/zh-CN/2025/01/07/GaLore%E5%88%86%E6%9E%90/" class="post-title-link" itemprop="url">GaLore分析</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-01-07 15:41:06" itemprop="dateCreated datePublished" datetime="2025-01-07T15:41:06+08:00">2025-01-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-28 18:39:05" itemprop="dateModified" datetime="2025-03-28T18:39:05+08:00">2025-03-28</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/zh-CN/2025/01/07/GaLore%E5%88%86%E6%9E%90/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="zh-CN/2025/01/07/GaLore分析/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>LoRA一般的设定是认为微调任务应该只需要在一个更小的子空间去训练即可不需要复用基座模型的大空间，从而实现低成本的微调。<br>LoRA的前提是问题是不是在子空间能得到最优解。在线性回归 y=W x 中，如果最优 W * 是高秩的，那么对 W 施加低秩假设永远不会导致最优解，无论使用什么优化器。</p>
<p>Gradient Low-Rank Projection (GaLore) 允许全参数学习，但比 LoRA 等常见的低秩自适应方法更具内存效率。</p>
<p>使用单个批处理大小从头开始预训练 LLaMA7B 模型至少需要 58 GB 内存（14GB 用于可训练参数，42GB 用于 Adam 优化器状态和权重梯度，2GB 用于激活函数）。这使得训练在消费级 GPU 上不可行，例如具有 24GB 内存的 NVIDIA RTX 4090。</p>
<p>他证明梯度可能具有低秩结构，如果我们能够在优化器状态中保留梯度的一个小 “核心” 的梯度统计信息，而不是完整的梯度本身，那么内存消耗就可以大幅降低。这就引出了 GaLore 策略。<br>他的关键思想是利用权重矩阵 W 的梯度 G 上做LoRA，而不是试图将权重矩阵本身近似为低秩。他的核心逻辑用Torch写出来如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> weight <span class="keyword">in</span> model.parameters():</span><br><span class="line">    grad = weight.grad</span><br><span class="line">    <span class="comment"># original space -&gt; compact space</span></span><br><span class="line">    lor_grad = project(grad)</span><br><span class="line">    <span class="comment"># update by Adam, Adafactor, etc.</span></span><br><span class="line">    lor_update = update(lor_grad)</span><br><span class="line">    <span class="comment"># compact space -&gt; original space </span></span><br><span class="line">    update = project_back(lor_update) </span><br><span class="line">    weight.data += update</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ggaaooppeenngg.github.io/zh-CN/2024/12/26/Sequence-Parallelism/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ggaaooppeenngg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ggaaooppeenngg">
      <meta itemprop="description" content="为什么计算机科学是无限的但生命是有限的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ggaaooppeenngg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/zh-CN/2024/12/26/Sequence-Parallelism/" class="post-title-link" itemprop="url">Sequence Parallelism</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-12-26 16:12:55" itemprop="dateCreated datePublished" datetime="2024-12-26T16:12:55+08:00">2024-12-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-28 18:39:05" itemprop="dateModified" datetime="2025-03-28T18:39:05+08:00">2025-03-28</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/zh-CN/2024/12/26/Sequence-Parallelism/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="zh-CN/2024/12/26/Sequence-Parallelism/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Sequence-Parallelism"><a href="#Sequence-Parallelism" class="headerlink" title="Sequence Parallelism"></a>Sequence Parallelism</h1><p>假设有4个chunk，切四份。</p>
<img data-src="/zh-CN/2024/12/26/Sequence-Parallelism/step_0.png" class="">

<p>初始化状态，每个GPU都有自己的 Qn Kn，可以计算出对应的注意力矩阵，然后类似AllReduce的方式传递切分的K。</p>
<img data-src="/zh-CN/2024/12/26/Sequence-Parallelism/step_1.png" class="">

<p>第一步环形传递K，然后再算一次注意力矩阵。</p>
<img data-src="/zh-CN/2024/12/26/Sequence-Parallelism/step_2.png" class="">

<p>第二步环形传递K，然后再算一次注意力矩阵。</p>
<img data-src="/zh-CN/2024/12/26/Sequence-Parallelism/step_3.png" class="">

<p>第三步全部传完，得到完整的Sn。</p>
<p>然后 Sn 和 Vn 的计算也是类似的，经过三次环形传递Vn，然后每一份可以单独和小s的那一份做乘法。</p>
<p>所以K和V的传播都要经历 3 次(N-1)的集合通信。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ggaaooppeenngg.github.io/zh-CN/2024/12/25/Mooncacke%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ggaaooppeenngg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ggaaooppeenngg">
      <meta itemprop="description" content="为什么计算机科学是无限的但生命是有限的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ggaaooppeenngg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/zh-CN/2024/12/25/Mooncacke%E5%88%86%E6%9E%90/" class="post-title-link" itemprop="url">Mooncacke分析</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-12-25 18:06:12" itemprop="dateCreated datePublished" datetime="2024-12-25T18:06:12+08:00">2024-12-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-28 18:39:05" itemprop="dateModified" datetime="2025-03-28T18:39:05+08:00">2025-03-28</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/zh-CN/2024/12/25/Mooncacke%E5%88%86%E6%9E%90/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="zh-CN/2024/12/25/Mooncacke分析/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>LLM推理的核心在于KVCache的调度。</p>
<ol>
<li>尽可能多次重用KV缓存，以减少所需的计算资源；</li>
<li>每批次最大化token数量，从而改善Model FLOPs Utilization (MFU)。</li>
</ol>
<p>如果从远程内存获取KVCache，会增加数据传输时间，从而延长TTFT（Time To First Token）。因此，当本地KVCache的增量计算时间少于传输时间时，可以复用本地的KVCache，即使它不是最匹配的。而增大batch意味着系统处理的大批量数据，导致TBT（Token Between Token）延长，可以将负载均衡到低负载的Decode Instance。</p>
<h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><img data-src="/zh-CN/2024/12/25/Mooncacke%E5%88%86%E6%9E%90/arch.png" class="">

<p>Mooncake的架构图主要分为三个部分：Prefill Instance，Decode Instance，Conductor。</p>
<ol>
<li>Cache-aware Prefill Scheduler：负责调度Request到Prefill Instance，主要考虑load和KVCache的复用率。</li>
<li>KVCache Balance Scheduler：负责从匹配最多前缀的P2P传输KVCache到Instance（Decode和Prefill）。</li>
<li>Load-balance Decoding Scheduler：负责负载均衡调度Request到Decode Instance。</li>
</ol>
<p>Prefill Instance要满足TTFT SLO，最小化MFU，保证KVCache &lt; DRAM。<br>Decode Instance要满足TBT SLO，保证KVCache &lt; VRAM。<br>Inter-Node Transfer基于RDMA的P2P，这也是一个较大的开销。</p>
<p>Mooncake的方法总结如下：</p>
<ol>
<li>转移可重用的KVCache，将尽可能多的可重用KVCache转移至Prefill Instance，减少增量计算的时间。</li>
<li>Prefill Instance Pool分层并分块处理，并持续输出给对应的Decode Instance。分层指的是Layer-wise KVCache的异步保存，分块指的是Chunked Pipeline Parallelism。</li>
<li>独立的Decode Instance Pool加载KVCache，通过连续批处理解码tokens。</li>
</ol>
<p>Mooncake的主要特点是将prefill和decode拆开，并调度KVCache块。</p>
<p>Reject Policy：如果一个请求不能在服务水平内完成其完整的执行，那么就应该尽早拒绝这个请求，基于这个理念需要设计一些拒绝策略，被称作Overloaded-Scheduling。</p>
<h3 id="KVCache的复制"><a href="#KVCache的复制" class="headerlink" title="KVCache的复制"></a>KVCache的复制</h3><p>KVCache的调度主要是利用KV Cache（VRAM，DRAM），利用RDMA带宽。</p>
<p>下图是一个Prefill和Decode分离的计算过程。</p>
<img data-src="/zh-CN/2024/12/25/Mooncacke%E5%88%86%E6%9E%90/kv_transfer.png" class="">

<p>如果了解vLLM中的prefill和decode以及管理block的方法，这个图其实很简单。</p>
<p>首先通过Hash判断block是否相同，例如很多系统提示词都是一样的，这部分的复用率很高。</p>
<p>Prefill Instance已经有了ABCDE（这里是一个P2P的过程，但我看开源的版本有个KVCache Store的WIP，不知道后面会不会有一个中心化的KVCache Store的组件）。然后计算了FGHI，存入了KV Cache（在CPU mem上），论文里面提到这个prefill在超过<code>prefill_chunk</code> tokens数量会做chunked prefill。</p>
<p>接着通过Messenger以RDMA的方式发给Decode Instance。Decode Instance基于ABCDEFGHI的prompt对应的KV Cache开始decode的过程。</p>
<p>根据请求模式，它可以使用缓存淘汰算法，如LRU（最近最少使用），LFU（最不常用的），或基于请求特征的算法。这些KVCache块在CPU和GPU之间的传输由一个独立的（GPUDirect）RDMA组件Messenger处理。这种架构还使我们能够为外部用户提供KVCache缓存API，从而实现更高的缓存重用性。</p>
<p>Mooncake已经开源了他的<a target="_blank" rel="noopener" href="https://github.com/kvcache-ai/Mooncake">代码</a>，目前只有Transfer Engine。</p>
<p>基于这个架构，Conductor的主要功能是：</p>
<ol>
<li>根据当前的KVCache分布和工作负载，分发请求。</li>
<li>复制或交换某些KVCache块，以便于未来推理。如果某些块的数据在未来被频繁访问，Conductor可能会将其复制到其他节点上，从而提高推理效率。</li>
</ol>
<p>Mooncake的一个争论点是，是否需要在存在chunked prefill的情况下采用这种分离架构。毕竟，chunked prefill可以填补许多pipeline中的气泡，并且能让prefill和decode节点相对统一，只需要关心一种instance，对于scheduler比较友好。</p>
<ol>
<li><p>不分离的优点：</p>
<ul>
<li>所有节点被视为平等，使调度更简单；</li>
<li>将chunked prefill内联到解码批处理中可以提高解码批次的计算强度，从而提高MFU。</li>
</ul>
</li>
<li><p>分离的优点：</p>
<ul>
<li>长文本的跨节点并行和VRAM的节省。长文本输入是输出的10倍甚至100倍，对于相同的模型来说，prefill需要多节点配置才能满足显存需求。prefill阶段可以进行layer-wise prefill，每次保存大量KVCache，而decode阶段每次只需保存一个KVCache。因此，prefill阶段可以通过layer-wise prefill来减少VRAM占用。</li>
</ul>
</li>
</ol>
<blockquote>
<p>是这么理解么？异步的Store KVCache可以节省保存的时间，但这是Prefill和Decode分离的理由么？Decode阶段应该是不保存KVCache?</p>
</blockquote>
<p>然而，经过仔细考虑，论文决定保持Mooncake的分离架构。只有在请求的prefill可以不进行chunking且不影响TBT SLO的情况下，才会将其内联到解码批次中。我们这样决定的主要原因有两个：</p>
<ol>
<li><p>Prefill节点需要不同的跨节点并行设置来处理长上下文 (§5.1)。</p>
</li>
<li><p>这为节省VRAM提供了独特的机会 (§5.2)。</p>
</li>
<li><p>大模型需要部署在多机上，进行TP后，每一层都需要进行一次基于RDMA的reduce，这个过程开销巨大。虽然有一些Sequence Parallelism的方法，但效果并不理想，且无法避免跨节点通信。而Mooncake采用的是CPP（Chunked Parallelism Pipeline），将序列按<code>prefill_chunk</code>大小切分，交给prefill pool的不同节点，这些节点被切分成更小的节点池（pipelined prefill node group）。</p>
</li>
</ol>
<blockquote>
<p>疑问：他们是pipe的不同部分？还是完全对等的？目前感觉是PP是分layer做Pipe，而CPP是sequence分chunked做pipe。24引用的论文中提到的Sequence Pipeline可以再看一下，应该对理解这个有帮助。</p>
</blockquote>
<ol start="2">
<li>Layer-wise prefill，这有点像airllm项目，在计算过程中动态加载KVCache。在每次注意力计算时，KVCache是异步加载的，计算当前层时可以异步加载下一层，并且当前层结束后可以异步保存当前层。论文中认为KVCache的保存时间可以被完全省略（相较于加载计算保存的线性循环）。这样也可以降低VRAM的占用。</li>
</ol>
<h3 id="调度算法"><a href="#调度算法" class="headerlink" title="调度算法"></a>调度算法</h3><ol>
<li><p><strong>选择Prefill实例</strong>：</p>
<ul>
<li>如果Prefill节点上缓存了足够的前缀（由<code>kvcache_balancing_threshold</code>控制），则选择预估TTFT最小的实例：<code>TTFT = min(T_queue + T_prefill)</code>。</li>
<li>如果Prefill节点上缓存不足，则选择<code>TTFT = min(T_queue + T_prefill + T_transfer)</code>最小的实例，其中<code>T_transfer</code>指的是有最长匹配的KVCache的实例拷贝到当前实例的预估时间。</li>
</ul>
</li>
<li><p><strong>选择Decode实例</strong>：</p>
<ul>
<li>通过负载均衡的方式预估TBT。</li>
<li>如果TBT和TTFT不满足SLO，则拒绝请求，并触发KVCache的传输。</li>
</ul>
</li>
<li><p><strong>预测模型</strong>：</p>
<ul>
<li>预估模型用于预测传输时间和决策传输。</li>
<li>数据传输时间难以预测，因为它不仅取决于数据大小，还依赖于当前网络状态，特别是当发送节点处于拥塞状态时。</li>
</ul>
</li>
<li><p><strong>KVCache复制</strong>：</p>
<ul>
<li>热门的KVCache块需要被复制以确保高可用性。</li>
</ul>
</li>
<li><p><strong>调度器目标</strong>：</p>
<ul>
<li>保证低Cache负载和高Cache命中率。</li>
</ul>
</li>
<li><p><strong>高负载情况下的策略</strong>：</p>
<ul>
<li>请求可能不会被直接发送给缓存最长前缀的实例，而是转发给备选实例。备选实例会主动从缓存持有者处检索KV缓存并存储本地。</li>
<li>当最佳的远程前缀匹配长度不超过当前本地可重用前缀的阈值时，系统优先使用本地缓存，而不是从远程实例获取令牌。</li>
</ul>
</li>
</ol>
<p>这些策略不仅减少了请求的Prefill时间，还自动复制热点缓存，使其在多台机器上更广泛地分布。</p>
<h3 id="拒绝策略"><a href="#拒绝策略" class="headerlink" title="拒绝策略"></a>拒绝策略</h3><p>论文提到了一种基于预测的拒绝策略。Prefill和Decode的负载节奏是相反的，可能在Decode负载高时，Prefill负载较低。此时如果拒绝请求，会导致Decode负载下降，而Prefill完成后Decode负载又会升高，进而再次拒绝请求。引入预测拒绝策略后，可以使Prefill过程更加平滑，减少频繁拒绝请求的情况，从而减小负载节奏的波动。</p>
<img data-src="/zh-CN/2024/12/25/Mooncacke%E5%88%86%E6%9E%90/reject_policy.png" class="">

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ggaaooppeenngg.github.io/zh-CN/2024/12/23/Rust%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0llama/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ggaaooppeenngg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ggaaooppeenngg">
      <meta itemprop="description" content="为什么计算机科学是无限的但生命是有限的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ggaaooppeenngg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/zh-CN/2024/12/23/Rust%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0llama/" class="post-title-link" itemprop="url">Rust从零实现llama</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-12-23 16:57:18" itemprop="dateCreated datePublished" datetime="2024-12-23T16:57:18+08:00">2024-12-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-28 18:39:05" itemprop="dateModified" datetime="2025-03-28T18:39:05+08:00">2025-03-28</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/zh-CN/2024/12/23/Rust%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0llama/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="zh-CN/2024/12/23/Rust从零实现llama/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>参考Pytorch版本的<a target="_blank" rel="noopener" href="https://github.com/bkitano/llama-from-scratch">llama-from-scratch</a>。原文中的RmsNorm的平均值多算了一个维度，这里改成了正确的版本。</p>
<p>首先需要下载<a target="_blank" rel="noopener" href="https://github.com/karpathy/char-rnn/blob/master/data/tinyshakespeare/input.txt">TinyShakespeare</a>数据集，这是一个莎士比亚文字数据集。本文档将<em>大致</em>遵循论文的布局，并跳过一些明显的步骤，比如设置虚拟环境和安装依赖项。</p>
<p>我们最终将实现的内容预览：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="built_in">println!</span>(<span class="title function_ invoke__">generate</span>(llama, MASTER_CONFIG, <span class="number">500</span>, device)[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">ZELBETH:</span><br><span class="line">Sey solmenter! <span class="symbol">&#x27;tis</span> tonguerered <span class="keyword">if</span> berryishdd, and What his stabe, you, and, but all I pilJefals, mode with,</span><br><span class="line">Vurint <span class="keyword">as</span> steolated have loven OlD the queen<span class="symbol">&#x27;d</span> refore</span><br><span class="line">Are been, good plmp:</span><br><span class="line"></span><br><span class="line">Proforne, wift<span class="symbol">&#x27;es</span> swleen, was no bunderes<span class="symbol">&#x27;d</span> a a quain beath!</span><br><span class="line">Tybell is my gateer stalk smen<span class="symbol">&#x27;d</span> <span class="keyword">as</span> be matious dazest brink thou</span><br><span class="line">lord</span><br><span class="line">Enves were cIUll, afe and whwas seath This a is, an tale hoice his his onety Meall-tearn not murkawn, fase bettizen<span class="symbol">&#x27;d</span> her,</span><br><span class="line">To belacquesterer? baxewed wupl usweggs yet tall</span><br><span class="line">An</span><br></pre></td></tr></table></figure>

<p>实现过程中可能涉及一些 Rust 的使用方法，与 Python 有所不同，这里不做过多说明，具体的 Rust 语法可以参考其他文档。</p>
<h2 id="迭代工作：从小模块开始，保持确定性，然后逐步构建"><a href="#迭代工作：从小模块开始，保持确定性，然后逐步构建" class="headerlink" title="迭代工作：从小模块开始，保持确定性，然后逐步构建"></a>迭代工作：从小模块开始，保持确定性，然后逐步构建</h2><ol>
<li>创建所有需要的辅助函数，以便定量测试模型（数据拆分、训练、绘制损失）。</li>
<li>从论文中挑选出不同的组件，然后逐一实现，边训练边评估。</li>
</ol>
<h2 id="确保你的层按预期工作"><a href="#确保你的层按预期工作" class="headerlink" title="确保你的层按预期工作"></a>确保你的层按预期工作</h2><ol>
<li>经常使用 <code>.shape()</code>。<code>assert</code> 是你的朋友。</li>
<li>先在不进行矩阵乘法的情况下计算结果，然后使用 <code>candle</code> 函数使其高效。</li>
<li>有一个测试来确保你的层是正确的。例如，RoPE 嵌入有一个特定的属性，你可以测试它。对于 Transformer，你可以通过查看注意力矩阵来测试注意力是否正常工作。</li>
<li>在各种批次、序列和嵌入大小上测试你的层。即使它适用于一种大小，它可能不适用于其他大小，这将在推理时导致问题。</li>
</ol>
<h2 id="关于-Llama"><a href="#关于-Llama" class="headerlink" title="关于 Llama"></a>关于 Llama</h2><p>Llama 是一种基于 Transformer 的语言建模模型。它是一个自回归模型，也称为 CausalModel，模型会将输出中的 token 加入到输入中，不断迭代推理，直到超过上下文长度或遇到停止符。Meta AI <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/llama">开源</a>了 Llama，并明确表示他们的目标是使模型在推理时更高效，而不是优化训练成本。</p>
<p>接下来，我们将加载库并开始实现。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> candle_core::&#123;DType, Device, IndexOp, <span class="type">Result</span>, Tensor, D&#125;;</span><br><span class="line"><span class="keyword">use</span> candle_nn::ops::softmax;</span><br><span class="line"><span class="keyword">use</span> candle_nn::&#123;</span><br><span class="line">    embedding, linear, loss, AdamW, Embedding, Init, Linear, Module, Optimizer, ParamsAdamW,</span><br><span class="line">    VarBuilder,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">use</span> core::<span class="type">f32</span>;</span><br><span class="line"><span class="keyword">use</span> rand::Rng;</span><br><span class="line"><span class="keyword">use</span> std::collections::HashMap;</span><br><span class="line"><span class="keyword">use</span> std::fs;</span><br><span class="line"><span class="keyword">use</span> std::time;</span><br></pre></td></tr></table></figure>

<h2 id="设置数据集"><a href="#设置数据集" class="headerlink" title="设置数据集"></a>设置数据集</h2><p>虽然 Llama 在 1.4T 个标记上进行训练，但我们的数据集 TinyShakespeare，即莎士比亚所有作品的集合，大约只有 100 万个字符。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> std::collections::HashMap;</span><br><span class="line"><span class="keyword">use</span> std::fs;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="comment">// Read the entire content of the file</span></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">lines</span> = fs::<span class="title function_ invoke__">read_to_string</span>(<span class="string">&quot;./input.txt&quot;</span>)</span><br><span class="line">        .<span class="title function_ invoke__">expect</span>(<span class="string">&quot;Failed to read the file&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create a sorted set of unique characters</span></span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">vocab</span>: <span class="type">Vec</span>&lt;<span class="type">char</span>&gt; = lines.<span class="title function_ invoke__">chars</span>().<span class="title function_ invoke__">collect</span>();</span><br><span class="line">    vocab.<span class="title function_ invoke__">sort_unstable</span>();</span><br><span class="line">    vocab.<span class="title function_ invoke__">dedup</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create itos and stoi mappings</span></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">itos</span>: HashMap&lt;<span class="type">usize</span>, <span class="type">char</span>&gt; = vocab.<span class="title function_ invoke__">iter</span>().<span class="title function_ invoke__">enumerate</span>().<span class="title function_ invoke__">map</span>(|(i, &amp;ch)| (i, ch)).<span class="title function_ invoke__">collect</span>();</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">stoi</span>: HashMap&lt;<span class="type">char</span>, <span class="type">usize</span>&gt; = vocab.<span class="title function_ invoke__">iter</span>().<span class="title function_ invoke__">enumerate</span>().<span class="title function_ invoke__">map</span>(|(i, &amp;ch)| (ch, i)).<span class="title function_ invoke__">collect</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Print the first 30 characters of the file</span></span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;&quot;</span>, &amp;lines[..<span class="number">30</span>.<span class="title function_ invoke__">min</span>(lines.<span class="title function_ invoke__">len</span>())]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<pre><code>First Citizen:
Before we proce
</code></pre>
<p>他们使用了<a target="_blank" rel="noopener" href="https://github.com/google/sentencepiece">SentencePiece</a>字节对编码分词器，但我们将只使用一个简单的字符级分词器。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> std::collections::HashMap;</span><br><span class="line"><span class="keyword">use</span> std::fs;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Vocab</span> &#123;</span><br><span class="line">    itos: HashMap&lt;<span class="type">u32</span>, <span class="type">char</span>&gt;,</span><br><span class="line">    stoi: HashMap&lt;<span class="type">char</span>, <span class="type">u32</span>&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">Vocab</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">new</span>(itos: HashMap&lt;<span class="type">u32</span>, <span class="type">char</span>&gt;, stoi: HashMap&lt;<span class="type">char</span>, <span class="type">u32</span>&gt;) <span class="punctuation">-&gt;</span> Vocab &#123;</span><br><span class="line">        Vocab &#123; itos, stoi &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">decode</span>(&amp;<span class="keyword">self</span>, ids: &amp;[<span class="type">u32</span>]) <span class="punctuation">-&gt;</span> <span class="type">String</span> &#123;</span><br><span class="line">        ids.<span class="title function_ invoke__">iter</span>().<span class="title function_ invoke__">map</span>(|&amp;id| <span class="keyword">self</span>.itos[&amp;id]).<span class="title function_ invoke__">collect</span>()</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">encode</span>(&amp;<span class="keyword">self</span>, text: &amp;<span class="type">str</span>) <span class="punctuation">-&gt;</span> <span class="type">Vec</span>&lt;<span class="type">u32</span>&gt; &#123;</span><br><span class="line">        text.<span class="title function_ invoke__">chars</span>().<span class="title function_ invoke__">map</span>(|ch| <span class="keyword">self</span>.stoi[&amp;ch]).<span class="title function_ invoke__">collect</span>()</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">len</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">usize</span> &#123;</span><br><span class="line">        <span class="keyword">self</span>.itos.<span class="title function_ invoke__">len</span>()</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">build</span>(lines: &amp;<span class="type">str</span>) <span class="punctuation">-&gt;</span> <span class="keyword">Self</span> &#123;</span><br><span class="line">        <span class="comment">// Create a sorted set of unique characters</span></span><br><span class="line">        <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">vocab</span>: <span class="type">Vec</span>&lt;<span class="type">char</span>&gt; = lines.<span class="title function_ invoke__">chars</span>().<span class="title function_ invoke__">collect</span>();</span><br><span class="line">        vocab.<span class="title function_ invoke__">sort</span>();</span><br><span class="line">        vocab.<span class="title function_ invoke__">dedup</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Create itos and stoi mappings</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">itos</span>: HashMap&lt;<span class="type">u32</span>, <span class="type">char</span>&gt; = vocab</span><br><span class="line">            .<span class="title function_ invoke__">iter</span>()</span><br><span class="line">            .<span class="title function_ invoke__">enumerate</span>()</span><br><span class="line">            .<span class="title function_ invoke__">map</span>(|(i, &amp;ch)| (i <span class="keyword">as</span> <span class="type">u32</span>, ch))</span><br><span class="line">            .<span class="title function_ invoke__">collect</span>();</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">stoi</span>: HashMap&lt;<span class="type">char</span>, <span class="type">u32</span>&gt; = vocab</span><br><span class="line">            .<span class="title function_ invoke__">iter</span>()</span><br><span class="line">            .<span class="title function_ invoke__">enumerate</span>()</span><br><span class="line">            .<span class="title function_ invoke__">map</span>(|(i, &amp;ch)| (ch, i <span class="keyword">as</span> <span class="type">u32</span>))</span><br><span class="line">            .<span class="title function_ invoke__">collect</span>();</span><br><span class="line">        <span class="keyword">Self</span> &#123; itos, stoi &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="comment">// Read the entire content of the file</span></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">lines</span> = fs::<span class="title function_ invoke__">read_to_string</span>(<span class="string">&quot;./input.txt&quot;</span>).<span class="title function_ invoke__">expect</span>(<span class="string">&quot;Failed to read the file&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">vocab</span> = Vocab::<span class="title function_ invoke__">build</span>(&amp;lines);</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;vocab size = &#123;&#125;&quot;</span>, vocab.<span class="title function_ invoke__">len</span>());</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;&quot;</span>, vocab.<span class="title function_ invoke__">decode</span>(&amp;vocab.<span class="title function_ invoke__">encode</span>(<span class="string">&quot;hello&quot;</span>)));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<pre><code>vocab size = 65
hello
</code></pre>
<p>由于数据集较小，我们无需担心内存存储问题。</p>
<p>我们创建了一个 <code>config</code> 对象来存储基本的模型参数。这样可以提高代码的可读性，并且便于修改配置。Rust 是强类型语言，因此所有变量都有明确的类型。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">modeConfig</span> = ModelConfig &#123;</span><br><span class="line">    vocab_size: vocab.<span class="title function_ invoke__">len</span>(),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">dataset</span> = Tensor::<span class="title function_ invoke__">from_slice</span>(&amp;vocab.<span class="title function_ invoke__">encode</span>(&amp;lines), (lines.<span class="title function_ invoke__">len</span>(),), &amp;Device::Cpu).<span class="title function_ invoke__">unwrap</span>();</span><br><span class="line"><span class="built_in">println!</span>(<span class="string">&quot;&#123;:?&#125;&quot;</span>, dataset.<span class="title function_ invoke__">shape</span>());</span><br></pre></td></tr></table></figure>

<pre><code>[1115394]
</code></pre>
<p>让我们创建一个方法 <code>get_batches</code> 来生成训练数据和目标的批次。我们将使用相同的方法来生成验证和测试数据，通过 <code>split</code> 参数来控制。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">get_batches</span>(</span><br><span class="line">    dataset: &amp;Tensor,</span><br><span class="line">    split: &amp;<span class="type">str</span>,</span><br><span class="line">    batch_size: <span class="type">usize</span>,</span><br><span class="line">    context_length: <span class="type">usize</span>,</span><br><span class="line">) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;(Tensor, Tensor)&gt; &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">len_of_dataset</span> = dataset.<span class="title function_ invoke__">shape</span>().<span class="title function_ invoke__">dim</span>(<span class="number">0</span>).<span class="title function_ invoke__">unwrap</span>() <span class="keyword">as</span> <span class="type">f32</span>;</span><br><span class="line">    <span class="comment">// 按照 0.8 0.1 0.1 的比例切分训练集, 验证集和测试集</span></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">batch_data</span> = <span class="keyword">match</span> split &#123;</span><br><span class="line">        <span class="string">&quot;val&quot;</span> =&gt; &amp;dataset.<span class="title function_ invoke__">i</span>((<span class="number">0.8</span> * len_of_dataset) <span class="keyword">as</span> <span class="type">usize</span>..(<span class="number">0.9</span> * len_of_dataset) <span class="keyword">as</span> <span class="type">usize</span>)?,</span><br><span class="line">        <span class="string">&quot;test&quot;</span> =&gt; &amp;dataset.<span class="title function_ invoke__">i</span>((<span class="number">0.9</span> * len_of_dataset) <span class="keyword">as</span> <span class="type">usize</span>..)?,</span><br><span class="line">        _ =&gt; &amp;dataset.<span class="title function_ invoke__">i</span>(..(<span class="number">0.8</span> * len_of_dataset) <span class="keyword">as</span> <span class="type">usize</span>)?,</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="comment">// 生成随机index</span></span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">rng</span> = rand::<span class="title function_ invoke__">thread_rng</span>();</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">data_len</span> = batch_data.<span class="title function_ invoke__">shape</span>().<span class="title function_ invoke__">dim</span>(<span class="number">0</span>)?;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">indices</span>: <span class="type">Vec</span>&lt;<span class="type">usize</span>&gt; = (<span class="number">0</span>..batch_size)</span><br><span class="line">        .<span class="title function_ invoke__">map</span>(|_| rng.<span class="title function_ invoke__">gen_range</span>(<span class="number">0</span>..data_len - context_length - <span class="number">1</span>))</span><br><span class="line">        .<span class="title function_ invoke__">collect</span>();</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">x_batches</span> = <span class="type">Vec</span>::<span class="title function_ invoke__">with_capacity</span>(batch_size);</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">y_batches</span> = <span class="type">Vec</span>::<span class="title function_ invoke__">with_capacity</span>(batch_size);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> <span class="variable">idx</span> <span class="keyword">in</span> indices &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">x</span> = batch_data.<span class="title function_ invoke__">i</span>(idx..(idx + context_length))?;</span><br><span class="line">        <span class="comment">// y 是 x 后面的一个字符</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">y</span> = batch_data.<span class="title function_ invoke__">i</span>((idx + <span class="number">1</span>)..(idx + context_length + <span class="number">1</span>))?;</span><br><span class="line">        x_batches.<span class="title function_ invoke__">push</span>(x);</span><br><span class="line">        y_batches.<span class="title function_ invoke__">push</span>(y);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// stack 和 cat 的区别是, stack 是在新的维度上堆叠, cat 是在已有的维度上堆叠</span></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">x_tensor</span> = Tensor::<span class="title function_ invoke__">stack</span>(&amp;x_batches, <span class="number">0</span>)?;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">y_tensor</span> = Tensor::<span class="title function_ invoke__">stack</span>(&amp;y_batches, <span class="number">0</span>)?;</span><br><span class="line">    <span class="title function_ invoke__">Ok</span>((x_tensor, y_tensor))</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// in fn main</span></span><br><span class="line">modeConfig.context_length = <span class="number">16</span>;</span><br><span class="line">modeConfig.batch_size = <span class="number">8</span>;</span><br><span class="line"><span class="keyword">let</span> <span class="variable">batch</span> = <span class="title function_ invoke__">get_batches</span>(</span><br><span class="line">    &amp;dataset,</span><br><span class="line">    <span class="string">&quot;train&quot;</span>,</span><br><span class="line">    modeConfig.batch_size,</span><br><span class="line">    modeConfig.context_length,</span><br><span class="line">)?;</span><br><span class="line"><span class="built_in">println!</span>(</span><br><span class="line">    <span class="string">&quot;batch size &#123;&#125;, context_length &#123;&#125;&quot;</span>,</span><br><span class="line">    batch.<span class="number">0</span>.<span class="title function_ invoke__">shape</span>().<span class="title function_ invoke__">dim</span>(<span class="number">0</span>)?,</span><br><span class="line">    batch.<span class="number">0</span>.<span class="title function_ invoke__">shape</span>().<span class="title function_ invoke__">dim</span>(<span class="number">1</span>)?</span><br><span class="line">);</span><br><span class="line"><span class="keyword">for</span> <span class="variable">i</span> <span class="keyword">in</span> <span class="number">0</span>..modeConfig.batch_size &#123;</span><br><span class="line">    <span class="built_in">println!</span>(</span><br><span class="line">        <span class="string">&quot;&#123;:?&#125;, &#123;:?&#125;&quot;</span>,</span><br><span class="line">        vocab.<span class="title function_ invoke__">decode</span>(&amp;batch.<span class="number">0</span>.<span class="title function_ invoke__">i</span>(i)?.<span class="title function_ invoke__">to_vec1</span>()?),</span><br><span class="line">        vocab.<span class="title function_ invoke__">decode</span>(&amp;batch.<span class="number">1</span>.<span class="title function_ invoke__">i</span>(i)?.<span class="title function_ invoke__">to_vec1</span>()?),</span><br><span class="line">    );</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>&quot;:\nBut, that I&#39;ll&quot;, &quot;\nBut, that I&#39;ll &quot;
&quot;ng?\nWhy, then th&quot;, &quot;g?\nWhy, then the&quot;
&quot;s so blind, but &quot;, &quot; so blind, but s&quot;
&quot;thy offices,\nSo &quot;, &quot;hy offices,\nSo r&quot;
&quot;ords, how plainl&quot;, &quot;rds, how plainly&quot;
&quot;IET:\nHere&#39;s such&quot;, &quot;ET:\nHere&#39;s such &quot;
&quot;wer\nTo take off &quot;, &quot;er\nTo take off s&quot;
&quot; hurry from the &quot;, &quot;hurry from the f&quot;
</code></pre>
<p>实现论文有趣的一点在于，模型“工作”有两个方面：编译（你的张量是否在各层之间匹配）和训练（损失是否下降）。<br>我们还要定义评估模型的方法。我们希望在定义模型之前就这样做，因为我们希望在训练模型时使用它来评估模型的性能。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">evaluate_loss</span>(</span><br><span class="line">    model: &amp;SimpleBrokenModel,</span><br><span class="line">    dataset: &amp;Tensor,</span><br><span class="line">    vocab: &amp;Vocab,</span><br><span class="line">    config: ModelConfig,</span><br><span class="line">) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;HashMap&lt;<span class="type">String</span>, <span class="type">f32</span>&gt;&gt; &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">out</span> = HashMap::<span class="title function_ invoke__">new</span>();</span><br><span class="line">    <span class="keyword">for</span> <span class="variable">split</span> <span class="keyword">in</span> [<span class="string">&quot;train&quot;</span>, <span class="string">&quot;val&quot;</span>] &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">losses</span> = <span class="type">Vec</span>::<span class="title function_ invoke__">new</span>();</span><br><span class="line">        <span class="keyword">for</span> <span class="variable">_</span> <span class="keyword">in</span> <span class="number">0</span>..<span class="number">10</span> &#123;</span><br><span class="line">            <span class="keyword">let</span> (xs, ys) = <span class="title function_ invoke__">get_batches</span>(&amp;dataset, split, config.batch_size, config.context_length)?;</span><br><span class="line">            <span class="keyword">let</span> (_, loss) = model.forward(&amp;xs, <span class="title function_ invoke__">Some</span>(&amp;ys))?;</span><br><span class="line">            <span class="keyword">let</span> <span class="variable">loss</span> = loss.<span class="title function_ invoke__">unwrap</span>();</span><br><span class="line">            losses.<span class="title function_ invoke__">push</span>(loss.to_scalar::&lt;<span class="type">f32</span>&gt;()?);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">avg_loss</span> = losses.<span class="title function_ invoke__">iter</span>().sum::&lt;<span class="type">f32</span>&gt;() / losses.<span class="title function_ invoke__">len</span>() <span class="keyword">as</span> <span class="type">f32</span>;</span><br><span class="line">        out.<span class="title function_ invoke__">insert</span>(split.<span class="title function_ invoke__">to_owned</span>(), avg_loss);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="title function_ invoke__">Ok</span>(out)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="设置一个可以工作的简单模型"><a href="#设置一个可以工作的简单模型" class="headerlink" title="设置一个可以工作的简单模型"></a>设置一个可以工作的简单模型</h2><p>这是一个带有嵌入的基本前馈神经网络。它是我们将要开始的基础模型，然后我们将逐步替换其部分内容，直到最终得到 Llama 论文中描述的模型。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">SimpleBrokenModel</span> &#123;</span><br><span class="line">    embedding: Embedding,</span><br><span class="line">    mlp: Sequential,</span><br><span class="line">    config: ModelConfig,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">SimpleBrokenModel</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">forward</span>(&amp;<span class="keyword">self</span>, x: &amp;Tensor, targets: <span class="type">Option</span>&lt;&amp;Tensor&gt;) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;(Tensor, <span class="type">Option</span>&lt;Tensor&gt;)&gt; &#123;</span><br><span class="line">        <span class="comment">// 潜入层</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">embeds</span> = <span class="keyword">self</span>.embedding.forward(x)?;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 线性和激活层</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">logits</span> = <span class="keyword">self</span>.mlp.forward(&amp;embeds)?;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 如果提供了targets就计算loss，不然视为推理，计算logits就可以。</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Some</span>(targets) = targets &#123;</span><br><span class="line">            <span class="comment">// 负的似然函数</span></span><br><span class="line">            <span class="comment">// -log(x) 越大，loss 越小</span></span><br><span class="line">            <span class="comment">// y =  [0, 0 , 0, 0, 1, ...,0,0]</span></span><br><span class="line">            <span class="comment">// y&#x27; = [4, 5,  6, 7, 8, ...,11,12 ]</span></span><br><span class="line">            <span class="comment">// 这个 cross_entropy 帮我们做了一个 log softmax</span></span><br><span class="line">            <span class="comment">// y&#x27; = [0.1, 0.12, 0.13, 0.64, ..., 0,0]</span></span><br><span class="line">            <span class="comment">// loss = -log(0.64)</span></span><br><span class="line">            <span class="comment">// 当 -log(q) = 4.17 q = 0.015 大概 1/64,vocab_size = 65,所以基本是在瞎猜。</span></span><br><span class="line">            <span class="keyword">let</span> <span class="variable">loss</span> = loss::<span class="title function_ invoke__">cross_entropy</span>(</span><br><span class="line">                &amp;logits.<span class="title function_ invoke__">reshape</span>(((), <span class="keyword">self</span>.config.vocab_size))?,</span><br><span class="line">                &amp;targets.<span class="title function_ invoke__">reshape</span>(((),))?,</span><br><span class="line">            )?;</span><br><span class="line">            <span class="title function_ invoke__">Ok</span>((logits, <span class="title function_ invoke__">Some</span>(loss)))</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="title function_ invoke__">Ok</span>((logits, <span class="literal">None</span>))</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// VarBuilder是用来构建参数的，我们目前不加载和保存模型参数，但是candle的用法必须基于这个。</span></span><br><span class="line">    <span class="comment">// vb.pp 会在参数树中加入参数的前缀，这样可以方便的查看参数的结构。</span></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">load</span>(vb: VarBuilder, config: ModelConfig) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;(<span class="keyword">Self</span>)&gt; &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">embedding</span> = <span class="title function_ invoke__">embedding</span>(</span><br><span class="line">            config.vocab_size,</span><br><span class="line">            config.d_model,</span><br><span class="line">            vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;model.embed_tokens&quot;</span>),</span><br><span class="line">        )?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">mlp</span> = sequential::<span class="title function_ invoke__">seq</span>()</span><br><span class="line">            .<span class="title function_ invoke__">add</span>(<span class="title function_ invoke__">linear</span>(</span><br><span class="line">                config.d_model,</span><br><span class="line">                config.d_model,</span><br><span class="line">                vb.<span class="title function_ invoke__">push_prefix</span>(<span class="string">&quot;model.fc1&quot;</span>),</span><br><span class="line">            )?)</span><br><span class="line">            .<span class="title function_ invoke__">add</span>(Activation::Relu)</span><br><span class="line">            .<span class="title function_ invoke__">add</span>(<span class="title function_ invoke__">linear</span>(</span><br><span class="line">                config.d_model,</span><br><span class="line">                config.vocab_size,</span><br><span class="line">                vb.<span class="title function_ invoke__">push_prefix</span>(<span class="string">&quot;model.fc2&quot;</span>),</span><br><span class="line">            )?);</span><br><span class="line">        <span class="title function_ invoke__">Ok</span>(<span class="keyword">Self</span> &#123;</span><br><span class="line">            embedding,</span><br><span class="line">            mlp,</span><br><span class="line">            config,</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// in fn main</span></span><br><span class="line">modeConfig.d_model = <span class="number">128</span>;</span><br><span class="line">modeConfig.batch_size = <span class="number">32</span>;</span><br><span class="line"><span class="keyword">let</span> (xs, ys) = <span class="title function_ invoke__">get_batches</span>(</span><br><span class="line">    &amp;dataset,</span><br><span class="line">    <span class="string">&quot;train&quot;</span>,</span><br><span class="line">    modeConfig.batch_size,</span><br><span class="line">    modeConfig.context_length,</span><br><span class="line">)?;</span><br><span class="line"><span class="keyword">let</span> <span class="variable">varmap</span> = candle_nn::VarMap::<span class="title function_ invoke__">new</span>();</span><br><span class="line"><span class="keyword">let</span> <span class="variable">vb</span> = candle_nn::VarBuilder::<span class="title function_ invoke__">from_varmap</span>(&amp;varmap, DType::F32, &amp;Device::Cpu);</span><br><span class="line"><span class="keyword">let</span> <span class="variable">model</span> = SimpleBrokenModel::<span class="title function_ invoke__">load</span>(vb, modeConfig)?;</span><br><span class="line"><span class="keyword">let</span> (logits, loss) = model.forward(&amp;xs, <span class="title function_ invoke__">Some</span>(&amp;ys))?;</span><br><span class="line"><span class="built_in">println!</span>(<span class="string">&quot;&#123;:?&#125; &#123;:?&#125;&quot;</span>, logits, loss);</span><br><span class="line"><span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">params_count</span>: <span class="type">usize</span> = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (name, var) <span class="keyword">in</span> varmap.<span class="title function_ invoke__">data</span>().<span class="title function_ invoke__">lock</span>().<span class="title function_ invoke__">unwrap</span>().<span class="title function_ invoke__">iter</span>() &#123;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;: &#123;:?&#125;&quot;</span>, name, var.<span class="title function_ invoke__">elem_count</span>());</span><br><span class="line">    params_count += var.<span class="title function_ invoke__">elem_count</span>();</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">println!</span>(<span class="string">&quot;params count: &#123;&#125;&quot;</span>, params_count);</span><br></pre></td></tr></table></figure>

<pre><code>Tensor[dims 32, 16, 65; f32] Some(Tensor[5.266067; f32])
model.fc2.weight: 8320
model.embed_tokens.weight: 8320
model.fc1.bias: 128
model.fc2.bias: 65
model.fc1.weight: 16384
params count: 33217
</code></pre>
<p>在这一点上，我们必须开始关注张量的形状，并让矩阵的维度匹配。查看我们模型定义中的这一行：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">loss</span> = loss::<span class="title function_ invoke__">cross_entropy</span>(</span><br><span class="line">    &amp;logits.<span class="title function_ invoke__">reshape</span>(((), <span class="keyword">self</span>.config.vocab_size))?,</span><br><span class="line">    &amp;targets.<span class="title function_ invoke__">reshape</span>(((),))?,</span><br><span class="line">)?;</span><br></pre></td></tr></table></figure>

<p>我们必须调整 <code>logits</code> 和 <code>targets</code> 张量的形状，以便在比较时它们的维度匹配。我们使用 <code>reshape</code> 方法来实现这一点。<br><code>()</code> 参数的意思是“从其他维度推断这个维度”。所以，在这种情况下，我们是在说“将 <code>logits</code> 和 <code>targets</code> 重新调整为具有相同行数的形状，并使用所需的列数来实现这一点”。这是处理批量数据时的常见模式。</p>
<p>让我们训练我们的 <code>SimpleBrokenModel</code> 以确保梯度流动。在确认这一点之后，我们可以替换它的部分内容以匹配 Llama，再次训练并跟踪我们的进展。在这一点上，我开始记录我的训练运行日志，这样如果我搞砸了，我可以轻松地回到之前的运行。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">train</span>(</span><br><span class="line">    config: ModelConfig,</span><br><span class="line">    model: &amp;SimpleBrokenModel,</span><br><span class="line">    opt: &amp;<span class="keyword">mut</span> AdamW,</span><br><span class="line">    dataset: &amp;Tensor,</span><br><span class="line">    vocab: &amp;Vocab,</span><br><span class="line">) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;()&gt; &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">start_time</span> = std::time::Instant::<span class="title function_ invoke__">now</span>();</span><br><span class="line">    <span class="keyword">for</span> <span class="variable">epoch</span> <span class="keyword">in</span> <span class="number">0</span>..config.epochs &#123;</span><br><span class="line">        <span class="keyword">let</span> (xs, ys) = <span class="title function_ invoke__">get_batches</span>(&amp;dataset, <span class="string">&quot;train&quot;</span>, config.batch_size, config.context_length)?;</span><br><span class="line">        <span class="keyword">let</span> (_, loss) = model.forward(&amp;xs, <span class="title function_ invoke__">Some</span>(&amp;ys))?;</span><br><span class="line">        opt.<span class="title function_ invoke__">backward_step</span>(&amp;loss.<span class="title function_ invoke__">unwrap</span>())?;</span><br><span class="line">        <span class="keyword">if</span> epoch % config.log_interval == <span class="number">0</span> &#123;</span><br><span class="line">            <span class="keyword">let</span> <span class="variable">batch_duration</span> = start_time.<span class="title function_ invoke__">elapsed</span>().<span class="title function_ invoke__">as_secs_f32</span>();</span><br><span class="line">            <span class="keyword">let</span> <span class="variable">loss</span> = <span class="title function_ invoke__">evaluate_loss</span>(&amp;model, dataset, vocab, config)?;</span><br><span class="line">            <span class="keyword">let</span> <span class="variable">val_loss</span> = loss.<span class="title function_ invoke__">get</span>(<span class="string">&quot;val&quot;</span>).<span class="title function_ invoke__">unwrap</span>();</span><br><span class="line">            <span class="keyword">let</span> <span class="variable">eta</span> = batch_duration * (config.epochs - epoch) <span class="keyword">as</span> <span class="type">f32</span>;</span><br><span class="line">            <span class="keyword">let</span> <span class="variable">eta</span> = eta.<span class="title function_ invoke__">round</span>();</span><br><span class="line">            <span class="built_in">println!</span>(</span><br><span class="line">                <span class="string">&quot;Epoch: &#123;epoch&#125; | Loss: &#123;val_loss&#125; | Time: &#123;batch_duration&#125; | ETA in seconds &#123;eta&#125;&quot;</span></span><br><span class="line">            );</span><br><span class="line">            start_time = time::Instant::<span class="title function_ invoke__">now</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="title function_ invoke__">Ok</span>(())</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// in fn main</span></span><br><span class="line">modeConfig.log_interval = <span class="number">10</span>;</span><br><span class="line">modeConfig.epochs = <span class="number">100</span>;</span><br><span class="line"><span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">opt</span> = candle_nn::AdamW::<span class="title function_ invoke__">new</span>(varmap.<span class="title function_ invoke__">all_vars</span>(), ParamsAdamW::<span class="title function_ invoke__">default</span>())?;</span><br><span class="line"><span class="title function_ invoke__">train</span>(modeConfig, &amp;model, &amp;<span class="keyword">mut</span> opt, &amp;dataset, &amp;vocab)?;</span><br><span class="line"><span class="keyword">let</span> <span class="variable">out</span> = <span class="title function_ invoke__">evaluate_loss</span>(&amp;model, &amp;dataset, &amp;vocab, modeConfig);</span><br><span class="line"><span class="built_in">println!</span>(<span class="string">&quot;&#123;:?&#125;&quot;</span>, out);</span><br></pre></td></tr></table></figure>

<pre><code>Epoch: 10 | Loss: 3.9159875 | Time: 6.5813394 | ETA in seconds 599
Epoch: 20 | Loss: 3.26492 | Time: 6.3639965 | ETA in seconds 515
Epoch: 30 | Loss: 2.9944448 | Time: 6.3596206 | ETA in seconds 452
Epoch: 40 | Loss: 2.8793342 | Time: 6.357106 | ETA in seconds 388
Epoch: 50 | Loss: 2.7827232 | Time: 6.3562865 | ETA in seconds 324
Epoch: 60 | Loss: 2.764416 | Time: 6.352279 | ETA in seconds 260
Epoch: 70 | Loss: 2.7196321 | Time: 6.356127 | ETA in seconds 197
Epoch: 80 | Loss: 2.7631993 | Time: 6.357493 | ETA in seconds 134
Epoch: 90 | Loss: 2.696882 | Time: 6.358631 | ETA in seconds 70
Epoch: 100 | Loss: 2.670012 | Time: 6.3603354 | ETA in seconds 6
Ok(&#123;&quot;train&quot;: 2.591057, &quot;val&quot;: 2.6625311&#125;)
</code></pre>
<!-- 注意我们得到的训练曲线几乎没有下降。我们怎么知道它几乎没有训练？
我们必须使用基本原理。训练前的交叉熵损失是4.17，1000个epoch后的损失是3.93。我们如何直观地理解这一点？ -->

<!-- 在这种情况下，交叉熵指的是我们选择错误单词的可能性。所以这里，

$$
H(T, q) = - \sum_{i = 1}^{N} \frac{1}{N} \log q(x_i)
$$

其中 $q(x_i)$ 是模型估计的选择正确单词的概率。如果 $q(x_i)$ 接近1，那么 $\log q$ 接近0；同样，如果 $q$ 很小，那么 $\log q$ 是一个大的负数，
所以 $-\log q$ 将是一个大的正数。现在建立直觉：开始时，$-\log q = 4.17$，所以 $q = 0.015$，大约是 $\frac{1}{64.715}$。
回想一下，词汇量 $|V| = 65$，所以我们基本上在说模型在选择下一个字母时和从我们的词汇表中随机选择一样好。
训练后，$-\log q = 3.93$，所以我们现在基本上在50个字母之间选择。这是一个非常小的改进，所以可能有问题。

为了直观地理解损失与模型性能的关系，想象模型在 $\tilde V$ 个标记之间选择；当 $\tilde V$ 很小时，模型更有可能猜对。此外，我们知道 $\max \tilde V = V$，这可以帮助我们理解我们的模型是否在学习。

$$\tilde V = \exp(L)$$

让我们尝试调试发生了什么。注意在我们的模型中，我们在logits上使用了softmax层，这是一个将数字向量压缩成概率分布的函数。但是对于使用内置的 `F.cross_entropy` 函数，我们需要直接传递[未归一化的logits](https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html)。所以让我们从模型中删除它并再次尝试。 -->
<!-- 
很好，现在我们的损失是 $2.54$，所以我们从 $12.67$ 个字符中进行选择。这比我们开始时的 65 个字符要好得多。让我们为我们的模型添加一个生成方法，这样我们就可以直观地看到模型的结果。 -->


<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">generate</span>(model: &amp;SimpleBrokenModel, vocab: &amp;Vocab, max_tokens: <span class="type">usize</span>) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;()&gt; &#123;</span><br><span class="line">    <span class="comment">// batch size 5, initial token = 0</span></span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">token_ids</span> = Tensor::<span class="title function_ invoke__">zeros</span>((<span class="number">5</span>, <span class="number">1</span>), DType::U32, &amp;Device::Cpu).<span class="title function_ invoke__">unwrap</span>();</span><br><span class="line">    <span class="keyword">for</span> <span class="variable">_</span> <span class="keyword">in</span> <span class="number">0</span>..max_tokens &#123;</span><br><span class="line">        <span class="keyword">let</span> (logits, _) = model.forward(&amp;token_ids, <span class="literal">None</span>)?;</span><br><span class="line">        <span class="built_in">assert!</span>(logits.<span class="title function_ invoke__">shape</span>().<span class="title function_ invoke__">dims</span>() == [token_ids.<span class="title function_ invoke__">dim</span>(<span class="number">0</span>)?, token_ids.<span class="title function_ invoke__">dim</span>(<span class="number">1</span>)?, <span class="number">65</span>]);</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">last_step_logits</span> = logits.<span class="title function_ invoke__">i</span>((.., logits.<span class="title function_ invoke__">dim</span>(<span class="number">1</span>)? - <span class="number">1</span>))?;</span><br><span class="line">        <span class="built_in">assert!</span>(last_step_logits.<span class="title function_ invoke__">shape</span>().<span class="title function_ invoke__">dims</span>() == [token_ids.<span class="title function_ invoke__">dim</span>(<span class="number">0</span>)?, <span class="number">65</span>]);</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">probs</span> = <span class="title function_ invoke__">softmax</span>(&amp;last_step_logits, last_step_logits.<span class="title function_ invoke__">dims</span>().<span class="title function_ invoke__">len</span>() - <span class="number">1</span>)?;</span><br><span class="line">        <span class="built_in">assert!</span>(probs.<span class="title function_ invoke__">shape</span>().<span class="title function_ invoke__">dims</span>() == [token_ids.<span class="title function_ invoke__">dim</span>(<span class="number">0</span>)?, <span class="number">65</span>]);</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">next_token</span> = probs.<span class="title function_ invoke__">argmax</span>(probs.<span class="title function_ invoke__">dims</span>().<span class="title function_ invoke__">len</span>() - <span class="number">1</span>)?;</span><br><span class="line">        <span class="built_in">assert!</span>(next_token.<span class="title function_ invoke__">shape</span>().<span class="title function_ invoke__">dims</span>() == [token_ids.<span class="title function_ invoke__">dim</span>(<span class="number">0</span>)?]);</span><br><span class="line">        token_ids = Tensor::<span class="title function_ invoke__">cat</span>(&amp;[token_ids, next_token.<span class="title function_ invoke__">reshape</span>(((), <span class="number">1</span>))?], <span class="number">1</span>)?;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">lines</span> = fs::<span class="title function_ invoke__">read_to_string</span>(<span class="string">&quot;./input.txt&quot;</span>).<span class="title function_ invoke__">expect</span>(<span class="string">&quot;Failed to read the file&quot;</span>);</span><br><span class="line">    <span class="keyword">for</span> <span class="variable">v</span> <span class="keyword">in</span> &amp;token_ids.<span class="title function_ invoke__">to_vec2</span>()? &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">text</span> = vocab.<span class="title function_ invoke__">decode</span>(v);</span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;&quot;</span>, text);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="title function_ invoke__">Ok</span>(())</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// fn in main</span></span><br><span class="line"><span class="title function_ invoke__">generate</span>(&amp;model, &amp;vocab, <span class="number">10</span>, device)?;</span><br></pre></td></tr></table></figure>




<pre><code>[&#39;\nFind!\nD:\nAr t,\nLis sthte o t l&#39;,
 &#39;\nAnd ronnot ar\nBE:\nKINRDYOrspr;&#39;,
 &#39;\nI t athe momyengthend thanswal&#39;,
 &#39;\nFis t bp he\nLacarn.\nA:\nYOMI wi&#39;,
 &#39;\nWh ly sck\nB-de pll t\nHERIns ou&#39;]
</code></pre>
<p>这还算不错，但也不算太好。不过现在我们有了一个可以训练到验证损失的工作模型。因此，我们将在此基础上迭代我们的模型，使其更接近 Llama。</p>
<h2 id="Llama-具体细节"><a href="#Llama-具体细节" class="headerlink" title="Llama 具体细节"></a>Llama 具体细节</h2><p>Llama 对原始 Transformer 进行了三项架构修改：</p>
<ol>
<li>用于预归一化的 RMSNorm</li>
<li>旋转嵌入 RoPE</li>
<li>SwiGLU 激活函数</li>
</ol>
<p>我们将逐一添加每个修改到我们的基础模型，并进行迭代。</p>
<h3 id="RMSNorm"><a href="#RMSNorm" class="headerlink" title="RMSNorm"></a>RMSNorm</h3><p>在 Vaswani 2017 中，原始的 Transformer 使用了 BatchNormalization。在 Llama 中，作者使用了 RMSNorm，这是一种在不进行中心化的情况下通过方差来缩放向量的方法。此外，虽然 Vaswani 将归一化应用于注意力层的输出（后归一化），但 Llama 将其应用于输入之前（前归一化）。</p>
<p><a target="_blank" rel="noopener" href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/general/nki/tutorials/rmsnorm.html">这篇文章</a>对于RMSNorm有一个很好的解释。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">RmsNorm</span> &#123;</span><br><span class="line">    scale: Tensor,</span><br><span class="line">    eps: <span class="type">f64</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">RmsNorm</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">new</span>(size: <span class="type">usize</span>, vb: VarBuilder) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;<span class="keyword">Self</span>&gt; &#123;</span><br><span class="line">        <span class="title function_ invoke__">Ok</span>(RmsNorm &#123;</span><br><span class="line">            scale: vb.<span class="title function_ invoke__">get_with_hints</span>(size, <span class="string">&quot;weight&quot;</span>, Init::<span class="title function_ invoke__">Const</span>(<span class="number">1</span>.))?,</span><br><span class="line">            eps: <span class="number">1e-6</span>,</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">forward</span>(&amp;<span class="keyword">self</span>, x: &amp;Tensor) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;Tensor&gt; &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">x_sqr</span> = x.<span class="title function_ invoke__">sqr</span>()?;</span><br><span class="line">        <span class="built_in">assert!</span>(x_sqr.<span class="title function_ invoke__">shape</span>().<span class="title function_ invoke__">dims</span>() == x.<span class="title function_ invoke__">shape</span>().<span class="title function_ invoke__">dims</span>());</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">norm_x</span> = (x.<span class="title function_ invoke__">mean</span>(D::Minus1)? + <span class="keyword">self</span>.eps)?.<span class="title function_ invoke__">sqrt</span>()?;</span><br><span class="line">        <span class="built_in">assert!</span>(norm_x.<span class="title function_ invoke__">shape</span>().<span class="title function_ invoke__">dims</span>() == [x.<span class="title function_ invoke__">shape</span>().<span class="title function_ invoke__">dim</span>(<span class="number">0</span>)?, x.<span class="title function_ invoke__">shape</span>().<span class="title function_ invoke__">dim</span>(<span class="number">1</span>)?]);</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">x_normed</span> = x.<span class="title function_ invoke__">broadcast_div</span>(&amp;norm_x.<span class="title function_ invoke__">reshape</span>((</span><br><span class="line">            norm_x.<span class="title function_ invoke__">shape</span>().<span class="title function_ invoke__">dim</span>(<span class="number">0</span>)?,</span><br><span class="line">            norm_x.<span class="title function_ invoke__">shape</span>().<span class="title function_ invoke__">dim</span>(<span class="number">1</span>)?,</span><br><span class="line">            (),</span><br><span class="line">        ))?)?;</span><br><span class="line">        <span class="built_in">assert!</span>(x_normed.<span class="title function_ invoke__">shape</span>().<span class="title function_ invoke__">dims</span>() == x.<span class="title function_ invoke__">shape</span>().<span class="title function_ invoke__">dims</span>());</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">x</span> = (x_normed.<span class="title function_ invoke__">broadcast_mul</span>(&amp;<span class="keyword">self</span>.scale))?;</span><br><span class="line">        <span class="title function_ invoke__">Ok</span>(x)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> <span class="variable">varmap</span> = candle_nn::VarMap::<span class="title function_ invoke__">new</span>();</span><br><span class="line"><span class="keyword">let</span> <span class="variable">vb</span> = candle_nn::VarBuilder::<span class="title function_ invoke__">from_varmap</span>(&amp;varmap, DType::F32, &amp;Device::Cpu);</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> <span class="variable">rms_norms</span> = RmsNorm::<span class="title function_ invoke__">new</span>(<span class="number">2</span>, vb)?;</span><br><span class="line"><span class="comment">// (2,3,2)</span></span><br><span class="line"><span class="keyword">let</span> <span class="variable">batch</span> = Tensor::<span class="title function_ invoke__">new</span>(</span><br><span class="line">    <span class="built_in">vec!</span>[</span><br><span class="line">        <span class="built_in">vec!</span>[<span class="built_in">vec!</span>[<span class="number">1f32</span>, <span class="number">1f32</span>], <span class="built_in">vec!</span>[<span class="number">1.2f32</span>, <span class="number">2f32</span>], <span class="built_in">vec!</span>[<span class="number">3f32</span>, <span class="number">3f32</span>]],</span><br><span class="line">        <span class="built_in">vec!</span>[<span class="built_in">vec!</span>[<span class="number">4f32</span>, <span class="number">43f32</span>], <span class="built_in">vec!</span>[<span class="number">5f32</span>, <span class="number">5f32</span>], <span class="built_in">vec!</span>[<span class="number">61f32</span>, <span class="number">6f32</span>]],</span><br><span class="line">    ],</span><br><span class="line">    &amp;Device::Cpu,</span><br><span class="line">)?;</span><br><span class="line"><span class="keyword">let</span> <span class="variable">vb</span> = candle_nn::VarBuilder::<span class="title function_ invoke__">from_varmap</span>(&amp;varmap, DType::F32, &amp;Device::Cpu);</span><br><span class="line"><span class="keyword">let</span> <span class="variable">out</span> = rms_norms.forward(&amp;batch)?;</span><br></pre></td></tr></table></figure>

<pre><code>Tensor[dims 2, 3, 2; f32]
</code></pre>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">SimpleBrokenModel</span> &#123;</span><br><span class="line">    embedding: Embedding,</span><br><span class="line">    mlp: Sequential,</span><br><span class="line">    rms_norm: RmsNorm,</span><br><span class="line">    config: ModelConfig,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">SimpleBrokenModel</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">forward</span>(&amp;<span class="keyword">self</span>, x: &amp;Tensor, targets: <span class="type">Option</span>&lt;&amp;Tensor&gt;) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;(Tensor, <span class="type">Option</span>&lt;Tensor&gt;)&gt; &#123;</span><br><span class="line">        <span class="comment">// Embedding</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">embeds</span> = <span class="keyword">self</span>.embedding.forward(x)?;</span><br><span class="line">        <span class="comment">// RMSNorm</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">normed_embeds</span> = <span class="keyword">self</span>.rms_norm.forward(&amp;embeds)?;</span><br><span class="line">        <span class="comment">// Linear layers and activation</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">logits</span> = <span class="keyword">self</span>.mlp.forward(&amp;normed_embeds)?;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Calculate loss if targets are provided</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Some</span>(targets) = targets &#123;</span><br><span class="line">            <span class="comment">// 负的似然函数</span></span><br><span class="line">            <span class="comment">// log(x) 越大，loss 越小</span></span><br><span class="line">            <span class="comment">// y =  [0, 0 , 0, 0, 1, ...,0,0]</span></span><br><span class="line">            <span class="comment">// y&#x27; = [4, 5,  6, 7, 8, ...,11,12 ]</span></span><br><span class="line">            <span class="comment">// 这个 cross_entropy 帮我们做了一个 log softmax</span></span><br><span class="line">            <span class="comment">// y&#x27; = [0.1, 0.12, 0.13, 0.64, ..., 0,0]</span></span><br><span class="line">            <span class="comment">// loss = -log(0.64)</span></span><br><span class="line">            <span class="comment">// -log(q) = 4.17 q = 0.015 大概 1/64,vocab_size = 65,所以基本是在瞎猜。</span></span><br><span class="line">            <span class="comment">// println!(&quot;&#123;:?&#125;&quot;, targets.shape());</span></span><br><span class="line">            <span class="comment">// println!(&quot;&#123;:?&#125;&quot;, logits.shape());</span></span><br><span class="line">            <span class="keyword">let</span> <span class="variable">loss</span> = loss::<span class="title function_ invoke__">cross_entropy</span>(</span><br><span class="line">                &amp;logits.<span class="title function_ invoke__">reshape</span>(((), <span class="keyword">self</span>.config.vocab_size))?,</span><br><span class="line">                &amp;targets.<span class="title function_ invoke__">reshape</span>(((),))?,</span><br><span class="line">            )?;</span><br><span class="line">            <span class="title function_ invoke__">Ok</span>((logits, <span class="title function_ invoke__">Some</span>(loss)))</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="title function_ invoke__">Ok</span>((logits, <span class="literal">None</span>))</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// VarBuilder是用来构建参数的。</span></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">load</span>(vb: VarBuilder, config: ModelConfig) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;(<span class="keyword">Self</span>)&gt; &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">embedding</span> = <span class="title function_ invoke__">embedding</span>(</span><br><span class="line">            config.vocab_size,</span><br><span class="line">            config.d_model,</span><br><span class="line">            vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;model.embed_tokens&quot;</span>),</span><br><span class="line">        )?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">rms_norm</span> = RmsNorm::<span class="title function_ invoke__">new</span>(config.d_model, vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;model.rms_norm&quot;</span>))?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">mlp</span> = sequential::<span class="title function_ invoke__">seq</span>()</span><br><span class="line">            .<span class="title function_ invoke__">add</span>(<span class="title function_ invoke__">linear</span>(</span><br><span class="line">                config.d_model,</span><br><span class="line">                config.d_model,</span><br><span class="line">                vb.<span class="title function_ invoke__">push_prefix</span>(<span class="string">&quot;model.fc1&quot;</span>),</span><br><span class="line">            )?)</span><br><span class="line">            .<span class="title function_ invoke__">add</span>(Activation::Relu)</span><br><span class="line">            .<span class="title function_ invoke__">add</span>(<span class="title function_ invoke__">linear</span>(</span><br><span class="line">                config.d_model,</span><br><span class="line">                config.vocab_size,</span><br><span class="line">                vb.<span class="title function_ invoke__">push_prefix</span>(<span class="string">&quot;model.fc2&quot;</span>),</span><br><span class="line">            )?);</span><br><span class="line">        <span class="title function_ invoke__">Ok</span>(<span class="keyword">Self</span> &#123;</span><br><span class="line">            embedding,</span><br><span class="line">            mlp,</span><br><span class="line">            config,</span><br><span class="line">            rms_norm,</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>Epoch: 10 | Loss: 4.1559505 | Time: 6.779387 | ETA in seconds 617
Epoch: 20 | Loss: 4.14648 | Time: 6.7727704 | ETA in seconds 549
Epoch: 30 | Loss: 4.1364665 | Time: 6.776428 | ETA in seconds 481
Epoch: 40 | Loss: 4.125594 | Time: 6.772582 | ETA in seconds 413
Epoch: 50 | Loss: 4.120083 | Time: 6.7661977 | ETA in seconds 345
Epoch: 60 | Loss: 4.1099877 | Time: 6.760399 | ETA in seconds 277
Epoch: 70 | Loss: 4.0996284 | Time: 6.7623253 | ETA in seconds 210
Epoch: 80 | Loss: 4.0902996 | Time: 6.761824 | ETA in seconds 142
Epoch: 90 | Loss: 4.0833025 | Time: 6.76845 | ETA in seconds 74
Epoch: 100 | Loss: 4.070025 | Time: 6.7624454 | ETA in seconds 7
Ok(&#123;&quot;train&quot;: 4.072861, &quot;val&quot;: 4.0711236&#125;)
</code></pre>
<p>从这里得到的结果来看，范化以后，模型的表现并没有提升，所以我们需要继续迭代，只是梯度的下降变得比较平滑了。</p>
<h3 id="Rotary-Embeddings"><a href="#Rotary-Embeddings" class="headerlink" title="Rotary Embeddings"></a>Rotary Embeddings</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2104.09864.pdf">RoPE</a> 是一种用于 Transformer 的位置编码方法。在《Attention is All You Need》中，作者提出了两种位置编码方法：学习的和固定的。在 RoPE 中，作者通过旋转嵌入来表示序列中标记的位置，并在每个位置使用不同的旋转角度。</p>
<p>其中的 cos 和 sin 值可以预先计算并缓存，避免重复计算，后续会统一存放在一个缓存结构中。</p>
<p>RoPE 将 <code>hidden_state</code> 中每两个 x 组成的向量与旋转矩阵相乘来实现位置编码。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[x0, x1, .... ,xn]</span><br><span class="line">y0 = x0 * <span class="title function_ invoke__">cos</span>(theta) - x1 * <span class="title function_ invoke__">sin</span>(theta)</span><br><span class="line">y1 = x0 * <span class="title function_ invoke__">sin</span>(theta) + x1 * <span class="title function_ invoke__">cos</span>(theta)</span><br><span class="line">[y0, y1, ...., yn]</span><br></pre></td></tr></table></figure>
<p><code>n</code> 是 <code>d_model</code> 的一半。<br><code>theta</code> 是一个根据位置得到的固定值，计算公式为：<br><code>theta = m / 10000^(2i/n)</code><br>其中，<code>m</code> 是在序列中的位置，<code>i</code> 是在 <code>d_model</code> 中的位置。</p>
<p>这个公式的含义是将特征向量中的 <code>x0</code> 和 <code>x1</code> 进行一个固定的旋转，这个旋转不是通过学习得到的，而是预先计算的。它可以用于表示相对位置信息。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">```Rust</span><br><span class="line">pos_index = 0, 中的 x0,x1</span><br><span class="line">pos_index = 1, 中的 x0,x1</span><br></pre></td></tr></table></figure>
<p>隔了一个恒定的调度旋转。</p>
<p>freq_cis缓存住提前算好的cos和sin的值，这部分不用重复计算。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Cache</span> &#123;</span><br><span class="line">    cos: Tensor,</span><br><span class="line">    sin: Tensor,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">Cache</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">new</span>(context_length: <span class="type">usize</span>, n_elem: <span class="type">usize</span>, vb: VarBuilder) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;Cache&gt; &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">theta</span>: <span class="type">Vec</span>&lt;_&gt; = (<span class="number">0</span>..n_elem)</span><br><span class="line">            .<span class="title function_ invoke__">step_by</span>(<span class="number">2</span>)</span><br><span class="line">            .<span class="title function_ invoke__">map</span>(|i| <span class="number">1f32</span> / <span class="number">10000f32</span>.<span class="title function_ invoke__">powf</span>(i <span class="keyword">as</span> <span class="type">f32</span> / n_elem <span class="keyword">as</span> <span class="type">f32</span>))</span><br><span class="line">            .<span class="title function_ invoke__">collect</span>();</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">theta</span> = Tensor::<span class="title function_ invoke__">new</span>(theta.<span class="title function_ invoke__">as_slice</span>(), vb.<span class="title function_ invoke__">device</span>())?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">idx_theta</span> = Tensor::<span class="title function_ invoke__">arange</span>(<span class="number">0</span>, context_length <span class="keyword">as</span> <span class="type">u32</span>, vb.<span class="title function_ invoke__">device</span>())?</span><br><span class="line">            .<span class="title function_ invoke__">to_dtype</span>(DType::F32)?</span><br><span class="line">            .<span class="title function_ invoke__">reshape</span>((context_length, <span class="number">1</span>))?</span><br><span class="line">            .<span class="title function_ invoke__">matmul</span>(&amp;theta.<span class="title function_ invoke__">reshape</span>((<span class="number">1</span>, theta.<span class="title function_ invoke__">elem_count</span>()))?)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">freq_cis_real</span> = idx_theta.<span class="title function_ invoke__">cos</span>()?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">freq_cis_imag</span> = idx_theta.<span class="title function_ invoke__">sin</span>()?;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">cos</span> = freq_cis_real.<span class="title function_ invoke__">reshape</span>((context_length, n_elem / <span class="number">2</span>, <span class="number">1</span>))?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">sin</span> = freq_cis_imag.<span class="title function_ invoke__">reshape</span>((context_length, n_elem / <span class="number">2</span>, <span class="number">1</span>))?;</span><br><span class="line">        <span class="title function_ invoke__">Ok</span>(Cache &#123; cos, sin&#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>rope计算的时候</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">apply_rotary_emb</span>(&amp;<span class="keyword">self</span>, x: &amp;Tensor, cache: &amp;Cache) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;Tensor&gt; &#123;</span><br><span class="line">    <span class="keyword">let</span> (b_sz, seq_len, n_embd) = x.<span class="title function_ invoke__">dims3</span>()?;</span><br><span class="line">    <span class="comment">// println!(&quot;shape of cache.cos &#123;:?&#125;&quot;, cache.cos.shape());</span></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">cos</span> = cache.cos.<span class="title function_ invoke__">i</span>(..seq_len)?;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">sin</span> = cache.sin.<span class="title function_ invoke__">i</span>(..seq_len)?;</span><br><span class="line">    <span class="comment">// println!(&quot;cos shape &#123;:?&#125;&quot;, cos.shape());</span></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">cos</span> = cos.<span class="title function_ invoke__">broadcast_as</span>((b_sz, seq_len, n_embd / <span class="number">2</span>, <span class="number">1</span>))?;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">sin</span> = sin.<span class="title function_ invoke__">broadcast_as</span>((b_sz, seq_len, n_embd / <span class="number">2</span>, <span class="number">1</span>))?;</span><br><span class="line">    <span class="comment">// println!(&quot;broadcast cos shape &#123;:?&#125;&quot;, cos.shape());</span></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">x</span> = x.<span class="title function_ invoke__">reshape</span>((b_sz, seq_len, n_embd / <span class="number">2</span>, <span class="number">2</span>))?;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">x0</span> = x.<span class="title function_ invoke__">narrow</span>(D::Minus1, <span class="number">0</span>, <span class="number">1</span>)?;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">x1</span> = x.<span class="title function_ invoke__">narrow</span>(D::Minus1, <span class="number">1</span>, <span class="number">1</span>)?;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">dst0</span> = (x0.<span class="title function_ invoke__">broadcast_mul</span>(&amp;cos)? - x1.<span class="title function_ invoke__">broadcast_mul</span>(&amp;sin)?)?;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">dst1</span> = (x0.<span class="title function_ invoke__">broadcast_mul</span>(&amp;sin)? + x1.<span class="title function_ invoke__">broadcast_mul</span>(&amp;cos)?)?;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">rope</span> = Tensor::<span class="title function_ invoke__">cat</span>(&amp;[&amp;dst0, &amp;dst1], D::Minus1)?.<span class="title function_ invoke__">reshape</span>((b_sz, seq_len, n_embd))?;</span><br><span class="line">    <span class="title function_ invoke__">Ok</span>(rope)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self Attention"></a>Self Attention</h3><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">AttentionModel</span> &#123;</span><br><span class="line">    embedding: Embedding,</span><br><span class="line">    mlp: Sequential,</span><br><span class="line">    rms_norm: RmsNorm,</span><br><span class="line">    config: ModelConfig,</span><br><span class="line">    self_attention: SelfAttention,</span><br><span class="line">    cache: Cache,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">AttentionModel</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">forward</span>(&amp;<span class="keyword">self</span>, x: &amp;Tensor, targets: <span class="type">Option</span>&lt;&amp;Tensor&gt;) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;(Tensor, <span class="type">Option</span>&lt;Tensor&gt;)&gt; &#123;</span><br><span class="line">        <span class="comment">// 嵌入层</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">embeds</span> = <span class="keyword">self</span>.embedding.forward(x)?;</span><br><span class="line">        <span class="comment">// 范化层</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">normed_embeds</span> = <span class="keyword">self</span>.rms_norm.forward(&amp;embeds)?;</span><br><span class="line">        <span class="comment">// 自注意力层</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">y</span> = <span class="keyword">self</span>.self_attention.forward(&amp;normed_embeds, &amp;<span class="keyword">self</span>.cache)?;</span><br><span class="line">        <span class="comment">// 线性和激活层</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">logits</span> = <span class="keyword">self</span>.mlp.forward(&amp;normed_embeds)?;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Some</span>(targets) = targets &#123;</span><br><span class="line">            <span class="comment">// 负的似然函数</span></span><br><span class="line">            <span class="comment">// -log(x) 越大，loss 越小</span></span><br><span class="line">            <span class="comment">// y =  [0, 0 , 0, 0, 1, ...,0,0]</span></span><br><span class="line">            <span class="comment">// y&#x27; = [4, 5,  6, 7, 8, ...,11,12 ]</span></span><br><span class="line">            <span class="comment">// 这个 cross_entropy 帮我们做了一个 log softmax</span></span><br><span class="line">            <span class="comment">// y&#x27; = [0.1, 0.12, 0.13, 0.64, ..., 0,0]</span></span><br><span class="line">            <span class="comment">// loss = -log(0.64)</span></span><br><span class="line">            <span class="comment">// 例如 -log(q) = 4.17 q = 0.015 大概 1/64,vocab_size = 65,所以基本是在瞎猜。</span></span><br><span class="line">            <span class="keyword">let</span> <span class="variable">loss</span> = loss::<span class="title function_ invoke__">cross_entropy</span>(</span><br><span class="line">                &amp;logits.<span class="title function_ invoke__">reshape</span>(((), <span class="keyword">self</span>.config.vocab_size))?,</span><br><span class="line">                &amp;targets.<span class="title function_ invoke__">reshape</span>(((),))?,</span><br><span class="line">            )?;</span><br><span class="line">            <span class="title function_ invoke__">Ok</span>((logits, <span class="title function_ invoke__">Some</span>(loss)))</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="title function_ invoke__">Ok</span>((logits, <span class="literal">None</span>))</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">load</span>(vb: VarBuilder, config: ModelConfig) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;(<span class="keyword">Self</span>)&gt; &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">embedding</span> = <span class="title function_ invoke__">embedding</span>(</span><br><span class="line">            config.vocab_size,</span><br><span class="line">            config.d_model,</span><br><span class="line">            vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;model.embed_tokens&quot;</span>),</span><br><span class="line">        )?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">rms_norm</span> = RmsNorm::<span class="title function_ invoke__">new</span>(config.d_model, vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;model.rms_norm&quot;</span>))?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">self_attention</span> = SelfAttention::<span class="title function_ invoke__">load</span>(vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;model.self_attention&quot;</span>), config)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">mlp</span> = sequential::<span class="title function_ invoke__">seq</span>()</span><br><span class="line">            .<span class="title function_ invoke__">add</span>(<span class="title function_ invoke__">linear</span>(</span><br><span class="line">                config.d_model,</span><br><span class="line">                config.d_model,</span><br><span class="line">                vb.<span class="title function_ invoke__">push_prefix</span>(<span class="string">&quot;model.fc1&quot;</span>),</span><br><span class="line">            )?)</span><br><span class="line">            .<span class="title function_ invoke__">add</span>(Activation::Relu)</span><br><span class="line">            .<span class="title function_ invoke__">add</span>(<span class="title function_ invoke__">linear</span>(</span><br><span class="line">                config.d_model,</span><br><span class="line">                config.vocab_size,</span><br><span class="line">                vb.<span class="title function_ invoke__">push_prefix</span>(<span class="string">&quot;model.fc2&quot;</span>),</span><br><span class="line">            )?);</span><br><span class="line">        <span class="title function_ invoke__">Ok</span>(<span class="keyword">Self</span> &#123;</span><br><span class="line">            embedding,</span><br><span class="line">            mlp,</span><br><span class="line">            config,</span><br><span class="line">            rms_norm,</span><br><span class="line">            self_attention,</span><br><span class="line">            cache: Cache::<span class="title function_ invoke__">new</span>(config.context_length, config.d_model, vb)?,</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>提示：了解训练时张量维度与推理时张量维度的区别。</p>
</blockquote>
<p>虽然在训练时，你可以期望张量维度与模型参数紧密匹配，例如 <code>batch.shape = (config[&#39;batch_size&#39;], config[&#39;context_window&#39;], config[&#39;d_model&#39;])</code>，但在推理时，你可能需要处理单个示例，例如 <code>batch.shape = (1, 1, config[&#39;d_model&#39;])</code>。因此，你需要确保在 <code>forward</code> 传递中进行索引时，使用从输入派生的形状，而不一定是模型参数。</p>
<h3 id="MultiHeadRopeAttention"><a href="#MultiHeadRopeAttention" class="headerlink" title="MultiHeadRopeAttention"></a>MultiHeadRopeAttention</h3><p>让我们为这个单一的注意力头设置一个多头注意力层，看看训练时会发生什么。</p>
<p>这里实现的是GQA的注意力头。<code>n_kv_head=1</code>时就是MQA，<code>n_kv_head&gt;1</code>且<code>n_kv_head&lt;n_head</code>时就是GQA，<code>n_kv_head=n_head</code>时就是原本的MHA。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">MultiHeadAttention</span> &#123;</span><br><span class="line">    q_proj: Linear,</span><br><span class="line">    k_proj: Linear,</span><br><span class="line">    v_proj: Linear,</span><br><span class="line">    o_proj: Linear,</span><br><span class="line">    n_head: <span class="type">usize</span>,</span><br><span class="line">    n_kv_head: <span class="type">usize</span>,</span><br><span class="line">    head_dim: <span class="type">usize</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">MultiHeadAttention</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">load</span>(vb: VarBuilder, config: ModelConfig) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;<span class="keyword">Self</span>&gt; &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">q_proj</span> = <span class="title function_ invoke__">linear</span>(config.d_model, config.d_model, vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;model.q_proj&quot;</span>))?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">k_proj</span> = <span class="title function_ invoke__">linear</span>(</span><br><span class="line">            config.d_model,</span><br><span class="line">            (config.d_model / config.n_head) * config.n_kv_head,</span><br><span class="line">            vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;model.k_proj&quot;</span>),</span><br><span class="line">        )?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">v_proj</span> = <span class="title function_ invoke__">linear</span>(</span><br><span class="line">            config.d_model,</span><br><span class="line">            (config.d_model / config.n_head) * config.n_kv_head,</span><br><span class="line">            vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;model.v_proj&quot;</span>),</span><br><span class="line">        )?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">o_proj</span> = <span class="title function_ invoke__">linear</span>(config.d_model, config.d_model, vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;model.o_proj&quot;</span>))?;</span><br><span class="line">        <span class="built_in">println!</span>(</span><br><span class="line">            <span class="string">&quot;MHA config n_head &#123;&#125; n_kv_head &#123;&#125;&quot;</span>,</span><br><span class="line">            config.n_head, config.n_kv_head</span><br><span class="line">        );</span><br><span class="line">        <span class="title function_ invoke__">Ok</span>(<span class="keyword">Self</span> &#123;</span><br><span class="line">            q_proj,</span><br><span class="line">            k_proj,</span><br><span class="line">            v_proj,</span><br><span class="line">            o_proj,</span><br><span class="line">            n_head: config.n_head,</span><br><span class="line">            n_kv_head: config.n_kv_head,</span><br><span class="line">            head_dim: config.d_model / config.n_head,</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">apply_rotary_emb</span>(&amp;<span class="keyword">self</span>, x: &amp;Tensor, cache: &amp;Cache) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;Tensor&gt; &#123;</span><br><span class="line">        <span class="keyword">let</span> (b_sz, seq_len, h, n_embd) = x.<span class="title function_ invoke__">dims4</span>()?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">cos</span> = cache.cos.<span class="title function_ invoke__">i</span>(..seq_len)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">sin</span> = cache.sin.<span class="title function_ invoke__">i</span>(..seq_len)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">cos</span> = cos.<span class="title function_ invoke__">unsqueeze</span>(<span class="number">1</span>)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">sin</span> = sin.<span class="title function_ invoke__">unsqueeze</span>(<span class="number">1</span>)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">cos</span> = cos.<span class="title function_ invoke__">broadcast_as</span>((b_sz, seq_len, <span class="number">1</span>, n_embd / <span class="number">2</span>, <span class="number">1</span>))?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">sin</span> = sin.<span class="title function_ invoke__">broadcast_as</span>((b_sz, seq_len, <span class="number">1</span>, n_embd / <span class="number">2</span>, <span class="number">1</span>))?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">x</span> = x.<span class="title function_ invoke__">reshape</span>((b_sz, seq_len, h, n_embd / <span class="number">2</span>, <span class="number">2</span>))?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">x0</span> = x.<span class="title function_ invoke__">narrow</span>(D::Minus1, <span class="number">0</span>, <span class="number">1</span>)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">x1</span> = x.<span class="title function_ invoke__">narrow</span>(D::Minus1, <span class="number">1</span>, <span class="number">1</span>)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">dst0</span> = (x0.<span class="title function_ invoke__">broadcast_mul</span>(&amp;cos)? - x1.<span class="title function_ invoke__">broadcast_mul</span>(&amp;sin)?)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">dst1</span> = (x0.<span class="title function_ invoke__">broadcast_mul</span>(&amp;sin)? + x1.<span class="title function_ invoke__">broadcast_mul</span>(&amp;cos)?)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">rope</span> = Tensor::<span class="title function_ invoke__">cat</span>(&amp;[&amp;dst0, &amp;dst1], D::Minus1)?.<span class="title function_ invoke__">reshape</span>((b_sz, seq_len, h, n_embd))?;</span><br><span class="line">        <span class="title function_ invoke__">Ok</span>(rope)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">forward</span>(&amp;<span class="keyword">self</span>, x: &amp;Tensor, cache: &amp;Cache) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;Tensor&gt; &#123;</span><br><span class="line">        <span class="keyword">let</span> (b_sz, seq_len, n_embd) = x.<span class="title function_ invoke__">dims3</span>()?;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 计算 q k v</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">q</span> = <span class="keyword">self</span>.q_proj.forward(x)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">k</span> = <span class="keyword">self</span>.k_proj.forward(x)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">v</span> = <span class="keyword">self</span>.v_proj.forward(x)?;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">assert!</span>(n_embd == <span class="keyword">self</span>.n_head * <span class="keyword">self</span>.head_dim);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">q</span> = q.<span class="title function_ invoke__">reshape</span>((b_sz, seq_len, <span class="keyword">self</span>.n_head, <span class="keyword">self</span>.head_dim))?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">k</span> = k.<span class="title function_ invoke__">reshape</span>((b_sz, seq_len, <span class="keyword">self</span>.n_kv_head, <span class="keyword">self</span>.head_dim))?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">v</span> = v.<span class="title function_ invoke__">reshape</span>((b_sz, seq_len, <span class="keyword">self</span>.n_kv_head, <span class="keyword">self</span>.head_dim))?;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 对  q  和 k 做位置编码</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">q</span> = <span class="keyword">self</span>.<span class="title function_ invoke__">apply_rotary_emb</span>(&amp;q, cache)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">k</span> = <span class="keyword">self</span>.<span class="title function_ invoke__">apply_rotary_emb</span>(&amp;k, cache)?;</span><br><span class="line">        <span class="comment">// 复制成 n_head / n_kv_head 份</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">k</span> = <span class="keyword">self</span>.<span class="title function_ invoke__">repeat_kv</span>(k)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">v</span> = <span class="keyword">self</span>.<span class="title function_ invoke__">repeat_kv</span>(v)?;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 把 seq_len 和 n_head 交换</span></span><br><span class="line">        <span class="comment">// 这转换一下是为了做一个 cat single head 的简单操作</span></span><br><span class="line">        <span class="comment">// 相当于 n_head 个的seq_len*seq_len的注意力。</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">q</span> = q.<span class="title function_ invoke__">transpose</span>(<span class="number">1</span>, <span class="number">2</span>)?.<span class="title function_ invoke__">contiguous</span>()?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">k</span> = k.<span class="title function_ invoke__">transpose</span>(<span class="number">1</span>, <span class="number">2</span>)?.<span class="title function_ invoke__">contiguous</span>()?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">v</span> = v.<span class="title function_ invoke__">transpose</span>(<span class="number">1</span>, <span class="number">2</span>)?.<span class="title function_ invoke__">contiguous</span>()?;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// q*k^T / sqrt(d_k) d_k = d_model</span></span><br><span class="line">        <span class="comment">// 这里是 (bs,n_head) 个 (seq_len, seq_len) 的注意力</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">attn</span> = (q.<span class="title function_ invoke__">matmul</span>(&amp;k.<span class="title function_ invoke__">t</span>()?)? / (<span class="keyword">self</span>.head_dim <span class="keyword">as</span> <span class="type">f64</span>).<span class="title function_ invoke__">sqrt</span>())?;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 这里是头内的softmax (seq_len,seq_len)的行总和为1</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">attn</span> = <span class="title function_ invoke__">softmax</span>(&amp;attn, D::Minus1)?;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 再乘 * (bs, n_head, seq_len, head_dim) 得到 (bs, n_head）个注意力头对应的加权的v</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">y</span> = attn.<span class="title function_ invoke__">matmul</span>(&amp;v)?;</span><br><span class="line">        <span class="comment">// 把 n_head 和 seq_len 交换回来，得到 (bs, seq_len, n_head, head_dim) 然后reshape以后</span></span><br><span class="line">        <span class="comment">// 得到 (bs, seq_len, n_head * head_dim) 把头给cat到一起。</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">y</span> = y.<span class="title function_ invoke__">transpose</span>(<span class="number">1</span>, <span class="number">2</span>)?.<span class="title function_ invoke__">reshape</span>(&amp;[b_sz, seq_len, n_embd])?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">y</span> = <span class="keyword">self</span>.o_proj.forward(&amp;y)?;</span><br><span class="line">        <span class="title function_ invoke__">Ok</span>(y)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">repeat_kv</span>(&amp;<span class="keyword">self</span>, x: Tensor) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;Tensor&gt; &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">n_rep</span> = <span class="keyword">self</span>.n_head / <span class="keyword">self</span>.n_kv_head;</span><br><span class="line">        <span class="keyword">if</span> n_rep == <span class="number">1</span> &#123;</span><br><span class="line">            <span class="title function_ invoke__">Ok</span>(x)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">let</span> (b_sz, seq_len, n_kv_head, head_dim) = x.<span class="title function_ invoke__">dims4</span>()?;</span><br><span class="line">            <span class="keyword">let</span> <span class="variable">x</span> = x</span><br><span class="line">                .<span class="title function_ invoke__">unsqueeze</span>(<span class="number">3</span>)?</span><br><span class="line">                .<span class="title function_ invoke__">expand</span>((b_sz, seq_len, n_kv_head, n_rep, head_dim))?</span><br><span class="line">                .<span class="title function_ invoke__">reshape</span>((b_sz, seq_len, n_kv_head * n_rep, head_dim))?;</span><br><span class="line">            <span class="title function_ invoke__">Ok</span>(x)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>完整模型</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">AttentionModel</span> &#123;</span><br><span class="line">    embedding: Embedding,</span><br><span class="line">    mlp: Sequential,</span><br><span class="line">    rms_norm: RmsNorm,</span><br><span class="line">    config: ModelConfig,</span><br><span class="line">    self_attention: MultiHeadAttention,</span><br><span class="line">    cache: Cache,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">AttentionModel</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">forward</span>(&amp;<span class="keyword">self</span>, x: &amp;Tensor, targets: <span class="type">Option</span>&lt;&amp;Tensor&gt;) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;(Tensor, <span class="type">Option</span>&lt;Tensor&gt;)&gt; &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">embeds</span> = <span class="keyword">self</span>.embedding.forward(x)?;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">normed_embeds</span> = <span class="keyword">self</span>.rms_norm.forward(&amp;embeds)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">y</span> = <span class="keyword">self</span>.self_attention.forward(&amp;normed_embeds, &amp;<span class="keyword">self</span>.cache)?;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">logits</span> = <span class="keyword">self</span>.mlp.forward(&amp;y)?;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Some</span>(targets) = targets &#123;</span><br><span class="line">            <span class="keyword">let</span> <span class="variable">loss</span> = loss::<span class="title function_ invoke__">cross_entropy</span>(</span><br><span class="line">                &amp;logits.<span class="title function_ invoke__">reshape</span>(((), <span class="keyword">self</span>.config.vocab_size))?,</span><br><span class="line">                &amp;targets.<span class="title function_ invoke__">reshape</span>(((),))?,</span><br><span class="line">            )?;</span><br><span class="line">            <span class="title function_ invoke__">Ok</span>((logits, <span class="title function_ invoke__">Some</span>(loss)))</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="title function_ invoke__">Ok</span>((logits, <span class="literal">None</span>))</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">load</span>(vb: VarBuilder, config: ModelConfig) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;(<span class="keyword">Self</span>)&gt; &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">embedding</span> = <span class="title function_ invoke__">embedding</span>(</span><br><span class="line">            config.vocab_size,</span><br><span class="line">            config.d_model,</span><br><span class="line">            vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;model.embed_tokens&quot;</span>),</span><br><span class="line">        )?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">rms_norm</span> = RmsNorm::<span class="title function_ invoke__">new</span>(config.d_model, vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;model.rms_norm&quot;</span>))?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">self_attention</span> = MultiHeadAttention::<span class="title function_ invoke__">load</span>(vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;model.multi_head_attention&quot;</span>), config)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">mlp</span> = sequential::<span class="title function_ invoke__">seq</span>()</span><br><span class="line">            .<span class="title function_ invoke__">add</span>(<span class="title function_ invoke__">linear</span>(</span><br><span class="line">                config.d_model,</span><br><span class="line">                config.d_model,</span><br><span class="line">                vb.<span class="title function_ invoke__">push_prefix</span>(<span class="string">&quot;model.fc1&quot;</span>),</span><br><span class="line">            )?)</span><br><span class="line">            .<span class="title function_ invoke__">add</span>(Activation::Relu)</span><br><span class="line">            .<span class="title function_ invoke__">add</span>(<span class="title function_ invoke__">linear</span>(</span><br><span class="line">                config.d_model,</span><br><span class="line">                config.vocab_size,</span><br><span class="line">                vb.<span class="title function_ invoke__">push_prefix</span>(<span class="string">&quot;model.fc2&quot;</span>),</span><br><span class="line">            )?);</span><br><span class="line">        <span class="title function_ invoke__">Ok</span>(<span class="keyword">Self</span> &#123;</span><br><span class="line">            embedding,</span><br><span class="line">            mlp,</span><br><span class="line">            config,</span><br><span class="line">            rms_norm,</span><br><span class="line">            self_attention,</span><br><span class="line">            cache: Cache::<span class="title function_ invoke__">new</span>(config.context_length, config.d_model/config.n_head, vb)?,</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="title function_ invoke__">generate</span>(&amp;model, &amp;vocab, <span class="number">10</span>, device)?;</span><br></pre></td></tr></table></figure>




<pre><code>[&#39;\n\n\n\n\n\n\n\nI\n\nOOOOOOOOOFOOtOOOOOOO&#39;,
 &#39;\nIIIIII IIIIIIIIIIIIIIIIIIIIIII&#39;,
 &#39;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&#39;,
 &#39;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\naaame&#39;,
 &#39;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&#39;]
</code></pre>
<p>所以看起来很糟糕。这里发生了什么？让我们通过查看注意力来开始调试。</p>
<p>目前的注意力是没有masked的，任何位置的字符都在关注任何其他位置的字符。<br>这有什么不好呢？我们试图仅基于之前的标记来预测下一个标记，但这里我们看到模型正在关注之后的标记。<br>换句话说，模型在作弊，或者从未来泄露信息。这是一个问题，这就是为什么我们需要使用因果掩码。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">Cache</span> &#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="comment">// mask 也可以 cached</span></span><br><span class="line">    mask: Tensor,</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">Cache</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">new</span>(context_length: <span class="type">usize</span>, n_elem: <span class="type">usize</span>, vb: VarBuilder) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;Cache&gt; &#123;</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">        <span class="comment">// _ 表示类型由编译器推断，</span></span><br><span class="line">        <span class="comment">// 默认的collect 是 [_]，但是这个大小是不可变的要编译期间决定</span></span><br><span class="line">        <span class="comment">// 所以这里还是要提示编译器要 collect 成 vec.</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">mask</span>: <span class="type">Vec</span>&lt;_&gt; = (<span class="number">0</span>..context_length)</span><br><span class="line">            .<span class="title function_ invoke__">flat_map</span>(|i| (<span class="number">0</span>..context_length).<span class="title function_ invoke__">map</span>(<span class="keyword">move</span> |j| <span class="type">u8</span>::<span class="title function_ invoke__">from</span>(j &gt; i)))</span><br><span class="line">            .<span class="title function_ invoke__">collect</span>();</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">mask</span> = Tensor::<span class="title function_ invoke__">from_slice</span>(&amp;mask, (context_length, context_length), vb.<span class="title function_ invoke__">device</span>())?;</span><br><span class="line">        <span class="title function_ invoke__">Ok</span>(Cache &#123; cos, sin, mask &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">MultiHeadAttention</span> &#123;</span><br><span class="line">    q_proj: Linear,</span><br><span class="line">    k_proj: Linear,</span><br><span class="line">    v_proj: Linear,</span><br><span class="line">    o_proj: Linear,</span><br><span class="line">    n_head: <span class="type">usize</span>,</span><br><span class="line">    n_kv_head: <span class="type">usize</span>,</span><br><span class="line">    head_dim: <span class="type">usize</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">MultiHeadAttention</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">load</span>(vb: VarBuilder, config: ModelConfig) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;<span class="keyword">Self</span>&gt; &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">q_proj</span> = <span class="title function_ invoke__">linear</span>(config.d_model, config.d_model, vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;model.q_proj&quot;</span>))?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">k_proj</span> = <span class="title function_ invoke__">linear</span>(</span><br><span class="line">            config.d_model,</span><br><span class="line">            (config.d_model / config.n_head) * config.n_kv_head,</span><br><span class="line">            vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;model.k_proj&quot;</span>),</span><br><span class="line">        )?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">v_proj</span> = <span class="title function_ invoke__">linear</span>(</span><br><span class="line">            config.d_model,</span><br><span class="line">            (config.d_model / config.n_head) * config.n_kv_head,</span><br><span class="line">            vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;model.v_proj&quot;</span>),</span><br><span class="line">        )?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">o_proj</span> = <span class="title function_ invoke__">linear</span>(config.d_model, config.d_model, vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;model.o_proj&quot;</span>))?;</span><br><span class="line">        <span class="built_in">println!</span>(</span><br><span class="line">            <span class="string">&quot;MHA config n_head &#123;&#125; n_kv_head &#123;&#125;&quot;</span>,</span><br><span class="line">            config.n_head, config.n_kv_head</span><br><span class="line">        );</span><br><span class="line">        <span class="title function_ invoke__">Ok</span>(<span class="keyword">Self</span> &#123;</span><br><span class="line">            q_proj,</span><br><span class="line">            k_proj,</span><br><span class="line">            v_proj,</span><br><span class="line">            o_proj,</span><br><span class="line">            n_head: config.n_head,</span><br><span class="line">            n_kv_head: config.n_kv_head,</span><br><span class="line">            head_dim: config.d_model / config.n_head,</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">forward</span>(&amp;<span class="keyword">self</span>, x: &amp;Tensor, cache: &amp;Cache) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;Tensor&gt; &#123;</span><br><span class="line">        <span class="keyword">let</span> (b_sz, seq_len, n_embd) = x.<span class="title function_ invoke__">dims3</span>()?;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 计算 q k v</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">q</span> = <span class="keyword">self</span>.q_proj.forward(x)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">k</span> = <span class="keyword">self</span>.k_proj.forward(x)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">v</span> = <span class="keyword">self</span>.v_proj.forward(x)?;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">assert!</span>(n_embd == <span class="keyword">self</span>.n_head * <span class="keyword">self</span>.head_dim);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">q</span> = q.<span class="title function_ invoke__">reshape</span>((b_sz, seq_len, <span class="keyword">self</span>.n_head, <span class="keyword">self</span>.head_dim))?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">k</span> = k.<span class="title function_ invoke__">reshape</span>((b_sz, seq_len, <span class="keyword">self</span>.n_kv_head, <span class="keyword">self</span>.head_dim))?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">v</span> = v.<span class="title function_ invoke__">reshape</span>((b_sz, seq_len, <span class="keyword">self</span>.n_kv_head, <span class="keyword">self</span>.head_dim))?;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 对  q  和 k 做位置编码</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">q</span> = <span class="keyword">self</span>.<span class="title function_ invoke__">apply_rotary_emb</span>(&amp;q, cache)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">k</span> = <span class="keyword">self</span>.<span class="title function_ invoke__">apply_rotary_emb</span>(&amp;k, cache)?;</span><br><span class="line">        <span class="comment">// 复制成 n_head / n_kv_head 份</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">k</span> = <span class="keyword">self</span>.<span class="title function_ invoke__">repeat_kv</span>(k)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">v</span> = <span class="keyword">self</span>.<span class="title function_ invoke__">repeat_kv</span>(v)?;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// println!(&quot;q.shape &#123;:?&#125;&quot;, q.shape());</span></span><br><span class="line">        <span class="comment">// 把 seq_len 和 n_head 交换</span></span><br><span class="line">        <span class="comment">// 这转换一下是为了做一个 cat single head 的简单操作</span></span><br><span class="line">        <span class="comment">// 相当于 n_head 个的seq_len*seq_len的注意力。</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">q</span> = q.<span class="title function_ invoke__">transpose</span>(<span class="number">1</span>, <span class="number">2</span>)?.<span class="title function_ invoke__">contiguous</span>()?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">k</span> = k.<span class="title function_ invoke__">transpose</span>(<span class="number">1</span>, <span class="number">2</span>)?.<span class="title function_ invoke__">contiguous</span>()?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">v</span> = v.<span class="title function_ invoke__">transpose</span>(<span class="number">1</span>, <span class="number">2</span>)?.<span class="title function_ invoke__">contiguous</span>()?;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// let tmp = q.matmul(&amp;k.t()?)?;</span></span><br><span class="line">        <span class="comment">// 这个结果是有负数的，但是注意力层不会有负数。</span></span><br><span class="line">        <span class="comment">// 计算结果出了很多 NaN，感觉应该是范化没做好。</span></span><br><span class="line">        <span class="comment">// 后面发现是没有用 sqrt 用了开方，导致负数变成了NaN。</span></span><br><span class="line">        <span class="comment">// q*k^T / sqrt(d_k) d_k = d_model</span></span><br><span class="line">        <span class="comment">// 这里是 (bs,n_head) 个 (seq_len, seq_len) 的注意力</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">attn</span> = (q.<span class="title function_ invoke__">matmul</span>(&amp;k.<span class="title function_ invoke__">t</span>()?)? / (<span class="keyword">self</span>.head_dim <span class="keyword">as</span> <span class="type">f64</span>).<span class="title function_ invoke__">sqrt</span>())?;</span><br><span class="line">        <span class="comment">// 在 softmax 之前，把未来的token位置变为负无穷，这样在softmax之后，这些位置的概率就会变为0</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">mask</span> = cache</span><br><span class="line">            .mask</span><br><span class="line">            .<span class="title function_ invoke__">i</span>((..seq_len, ..seq_len))?</span><br><span class="line">            .<span class="title function_ invoke__">unsqueeze</span>(<span class="number">0</span>)?</span><br><span class="line">            .<span class="title function_ invoke__">unsqueeze</span>(<span class="number">0</span>)?</span><br><span class="line">            .<span class="title function_ invoke__">broadcast_as</span>(attn.<span class="title function_ invoke__">shape</span>())?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">on_true</span> =</span><br><span class="line">            Tensor::<span class="title function_ invoke__">new</span>(<span class="type">f32</span>::NEG_INFINITY, attn.<span class="title function_ invoke__">device</span>())?.<span class="title function_ invoke__">broadcast_as</span>(mask.<span class="title function_ invoke__">shape</span>().<span class="title function_ invoke__">dims</span>())?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">attn</span> = mask.<span class="title function_ invoke__">where_cond</span>(&amp;on_true, &amp;attn)?;</span><br><span class="line">        <span class="comment">// 取一个例子</span></span><br><span class="line">        <span class="comment">// 这里是头内的softmax (seq_len,seq_len)的每行 (seq_len) 总和为1</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">attn</span> = <span class="title function_ invoke__">softmax</span>(&amp;attn, D::Minus1)?;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 再乘 * (bs, n_head, seq_len, head_dim) 得到 (bs, n_head）个注意力头对应的加权的v</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">y</span> = attn.<span class="title function_ invoke__">matmul</span>(&amp;v)?;</span><br><span class="line">        <span class="comment">// 把 n_head 和 seq_len 交换回来，得到 (bs, seq_len, n_head, head_dim) 然后reshape以后</span></span><br><span class="line">        <span class="comment">// 得到 (bs, seq_len, n_head * head_dim) 把头给cat到一起。</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">y</span> = y.<span class="title function_ invoke__">transpose</span>(<span class="number">1</span>, <span class="number">2</span>)?.<span class="title function_ invoke__">reshape</span>(&amp;[b_sz, seq_len, n_embd])?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">y</span> = <span class="keyword">self</span>.o_proj.forward(&amp;y)?;</span><br><span class="line">        <span class="title function_ invoke__">Ok</span>(y)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">repeat_kv</span>(&amp;<span class="keyword">self</span>, x: Tensor) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;Tensor&gt; &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">n_rep</span> = <span class="keyword">self</span>.n_head / <span class="keyword">self</span>.n_kv_head;</span><br><span class="line">        <span class="keyword">if</span> n_rep == <span class="number">1</span> &#123;</span><br><span class="line">            <span class="title function_ invoke__">Ok</span>(x)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">let</span> (b_sz, seq_len, n_kv_head, head_dim) = x.<span class="title function_ invoke__">dims4</span>()?;</span><br><span class="line">            <span class="keyword">let</span> <span class="variable">x</span> = x</span><br><span class="line">                .<span class="title function_ invoke__">unsqueeze</span>(<span class="number">3</span>)?</span><br><span class="line">                .<span class="title function_ invoke__">expand</span>((b_sz, seq_len, n_kv_head, n_rep, head_dim))?</span><br><span class="line">                .<span class="title function_ invoke__">reshape</span>((b_sz, seq_len, n_kv_head * n_rep, head_dim))?;</span><br><span class="line">            <span class="title function_ invoke__">Ok</span>(x)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>现在，我们可以让注意力激活的上三角部分（对应未来的部分）几乎被归零了。让我们看看训练时会发生什么。</p>
<h3 id="SwiGLU"><a href="#SwiGLU" class="headerlink" title="SwiGLU"></a>SwiGLU</h3><p>正如论文中所述，“我们用SwiGLU激活函数替换了ReLU非线性函数……我们使用$\frac{2}{3} 4d$的维度，而不是PaLM中的$4d$。” SwiGLU定义为：<br>$$<br>\text{SwiGLU}(x) = \text{Swish}_\beta (xW + b) \otimes (xV + c)<br>$$<br>其中$\otimes$是逐元素乘积。Swish函数定义为：<br>$$<br>\text{Swish}_\beta(x) = x \sigma(\beta x)<br>$$<br>其中$\beta$是一个可学习的参数。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">silu</span>(xs: &amp;Tensor) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;Tensor&gt; &#123;</span><br><span class="line">    xs / (xs.<span class="title function_ invoke__">neg</span>()?.<span class="title function_ invoke__">exp</span>()? + <span class="number">1.0</span>)?</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">SwiGLU</span> &#123;</span><br><span class="line">    c_fc1: Linear,</span><br><span class="line">    c_fc2: Linear,</span><br><span class="line">    c_proj: Linear,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 新的 mlp 是三层的带gate</span></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">SwiGLU</span> &#123;</span><br><span class="line">    <span class="comment">// silu 的特征是允许有一点点的负数</span></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">forward</span>(&amp;<span class="keyword">self</span>, x: &amp;Tensor) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;Tensor&gt; &#123;</span><br><span class="line">        <span class="comment">// 这里就是 SwiGLU SiLU(W_1 * x) * (W_2 * x) 是 element wise 的，这个可以作为gate门信号</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">x</span> = (<span class="title function_ invoke__">silu</span>(&amp;<span class="keyword">self</span>.c_fc1.forward(x)?)? * <span class="keyword">self</span>.c_fc2.forward(x)?)?;</span><br><span class="line">        <span class="keyword">self</span>.c_proj.forward(&amp;x)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">load</span>(vb: VarBuilder, cfg: ModelConfig) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;<span class="keyword">Self</span>&gt; &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">h_size</span> = cfg.d_model;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">i_size</span> = cfg.hidden_dim;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">c_fc1</span> = <span class="title function_ invoke__">linear</span>(h_size, i_size, vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;gate_proj&quot;</span>))?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">c_fc2</span> = <span class="title function_ invoke__">linear</span>(h_size, i_size, vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;up_proj&quot;</span>))?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">c_proj</span> = <span class="title function_ invoke__">linear</span>(i_size, h_size, vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;down_proj&quot;</span>))?;</span><br><span class="line">        <span class="title function_ invoke__">Ok</span>(<span class="keyword">Self</span> &#123;</span><br><span class="line">            c_fc1,</span><br><span class="line">            c_fc2,</span><br><span class="line">            c_proj,</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>一个llama block res 两次，一次在attention之前，一次在swiglu之前。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Block</span> &#123;</span><br><span class="line">    rms_1: RmsNorm,</span><br><span class="line">    attn: MultiHeadAttention,</span><br><span class="line">    rms_2: RmsNorm,</span><br><span class="line">    swiglu: SwiGLU,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">Block</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">forward</span>(&amp;<span class="keyword">self</span>, x: &amp;Tensor, cache: &amp;Cache) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;Tensor&gt; &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">residual</span> = x;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">x</span> = <span class="keyword">self</span>.rms_1.forward(x)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">x</span> = (<span class="keyword">self</span>.attn.forward(&amp;x, cache)? + residual)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">residual</span> = &amp;x;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">x</span> = (<span class="keyword">self</span>.swiglu.forward(&amp;<span class="keyword">self</span>.rms_2.forward(&amp;x)?)? + residual)?;</span><br><span class="line">        <span class="title function_ invoke__">Ok</span>(x)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">load</span>(vb: VarBuilder, cfg: ModelConfig) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;<span class="keyword">Self</span>&gt; &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">attn</span> = MultiHeadAttention::<span class="title function_ invoke__">load</span>(vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;self_attn&quot;</span>), cfg)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">swiglu</span> = SwiGLU::<span class="title function_ invoke__">load</span>(vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;mlp&quot;</span>), cfg)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">rms_1</span> = RmsNorm::<span class="title function_ invoke__">new</span>(cfg.d_model, vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;input_layernorm&quot;</span>))?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">rms_2</span> = RmsNorm::<span class="title function_ invoke__">new</span>(cfg.d_model, vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;post_attention_layernorm&quot;</span>))?;</span><br><span class="line">        <span class="title function_ invoke__">Ok</span>(<span class="keyword">Self</span> &#123;</span><br><span class="line">            rms_1,</span><br><span class="line">            attn,</span><br><span class="line">            rms_2,</span><br><span class="line">            swiglu,</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>现在，让我们通过创建块来添加多个层的最后完整的模型。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Llama</span> &#123;</span><br><span class="line">    embedding: Embedding,</span><br><span class="line">    blocks: <span class="type">Vec</span>&lt;Block&gt;,</span><br><span class="line">    ln_f: RmsNorm,</span><br><span class="line">    lm_head: Linear,</span><br><span class="line">    cache: Cache,</span><br><span class="line">    config: ModelConfig,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">Llama</span> &#123;</span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">forward</span>(</span><br><span class="line">        &amp;<span class="keyword">self</span>,</span><br><span class="line">        x: &amp;Tensor,</span><br><span class="line">        targets: <span class="type">Option</span>&lt;&amp;Tensor&gt;,</span><br><span class="line">    ) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;(Tensor, <span class="type">Option</span>&lt;Tensor&gt;)&gt; &#123;</span><br><span class="line">        <span class="keyword">let</span> (_b_sz, _seq_len) = x.<span class="title function_ invoke__">dims2</span>()?;</span><br><span class="line">        <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">x</span> = <span class="keyword">self</span>.embedding.forward(x)?;</span><br><span class="line">        <span class="keyword">for</span> <span class="variable">block</span> <span class="keyword">in</span> &amp;<span class="keyword">self</span>.blocks &#123;</span><br><span class="line">            x = block.forward(&amp;x, &amp;<span class="keyword">self</span>.cache)?;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">x</span> = <span class="keyword">self</span>.ln_f.forward(&amp;x)?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">logits</span> = <span class="keyword">self</span>.lm_head.forward(&amp;x)?;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Some</span>(targets) = targets &#123;</span><br><span class="line">            <span class="keyword">let</span> <span class="variable">loss</span> = loss::<span class="title function_ invoke__">cross_entropy</span>(</span><br><span class="line">                &amp;logits.<span class="title function_ invoke__">reshape</span>(((), <span class="keyword">self</span>.config.vocab_size))?,</span><br><span class="line">                &amp;targets.<span class="title function_ invoke__">reshape</span>(((),))?,</span><br><span class="line">            )?;</span><br><span class="line">            <span class="title function_ invoke__">Ok</span>((logits, <span class="title function_ invoke__">Some</span>(loss)))</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="title function_ invoke__">Ok</span>((logits, <span class="literal">None</span>))</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">load</span>(vb: VarBuilder, config: ModelConfig) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;<span class="keyword">Self</span>&gt; &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">embed_layer</span> = <span class="title function_ invoke__">embedding</span>(</span><br><span class="line">            config.vocab_size,</span><br><span class="line">            config.d_model,</span><br><span class="line">            vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;model.embed_tokens&quot;</span>),</span><br><span class="line">        )?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">lm_head</span> = <span class="title function_ invoke__">linear</span>(config.d_model, config.vocab_size, vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;lm_head&quot;</span>))?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">ln_f</span> = RmsNorm::<span class="title function_ invoke__">new</span>(config.d_model, vb.<span class="title function_ invoke__">pp</span>(<span class="string">&quot;model.norm&quot;</span>))?;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">blocks</span>: <span class="type">Vec</span>&lt;_&gt; = (<span class="number">0</span>..config.n_layers)</span><br><span class="line">            .<span class="title function_ invoke__">map</span>(|i| Block::<span class="title function_ invoke__">load</span>(vb.<span class="title function_ invoke__">pp</span>(<span class="built_in">format!</span>(<span class="string">&quot;model.layers.&#123;i&#125;&quot;</span>)), config).<span class="title function_ invoke__">unwrap</span>())</span><br><span class="line">            .<span class="title function_ invoke__">collect</span>();</span><br><span class="line">        <span class="title function_ invoke__">Ok</span>(<span class="keyword">Self</span> &#123;</span><br><span class="line">            embedding: embed_layer,</span><br><span class="line">            blocks,</span><br><span class="line">            ln_f,</span><br><span class="line">            lm_head,</span><br><span class="line">            config,</span><br><span class="line">            cache: Cache::<span class="title function_ invoke__">new</span>(config.context_length, config.d_model / config.n_head, vb)?,</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><p>这里主要是训练的部分，在推理的过程中还涉及到一个比较重要的kv cache。<br>kv cache主要是缓存自回归过程中的kv，这个kv是不变的，因为这个k 和 v 只和之前的token有关系，所以可以缓存下来，<br>这样在推理的时候就不用重复计算了。<br>围绕着prompt产生第一个Token的prefill的阶段和计算完prompt之后的decode阶段也是目前业界比较关注的推理优化的方向。<br>源代码在<a target="_blank" rel="noopener" href="https://github.com/ggaaooppeenngg/rust-llama-from-scratch">这里</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ggaaooppeenngg.github.io/zh-CN/2024/12/13/vLLM-%E5%88%86%E6%9E%90-3-%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ggaaooppeenngg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ggaaooppeenngg">
      <meta itemprop="description" content="为什么计算机科学是无限的但生命是有限的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ggaaooppeenngg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/zh-CN/2024/12/13/vLLM-%E5%88%86%E6%9E%90-3-%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/" class="post-title-link" itemprop="url">vLLM 分析 3 推理优化</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-12-13 17:14:56" itemprop="dateCreated datePublished" datetime="2024-12-13T17:14:56+08:00">2024-12-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-28 18:39:05" itemprop="dateModified" datetime="2025-03-28T18:39:05+08:00">2025-03-28</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/zh-CN/2024/12/13/vLLM-%E5%88%86%E6%9E%90-3-%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="zh-CN/2024/12/13/vLLM-分析-3-推理优化/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>这篇文章主要基于vLLM中做推理的优化做一个总结。</p>
<h2 id="PagedAttention"><a href="#PagedAttention" class="headerlink" title="PagedAttention"></a>PagedAttention</h2><p>从<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2309.06180">原始论文来看</a>，显存的浪费主要有几种。</p>
<img data-src="/zh-CN/2024/12/13/vLLM-%E5%88%86%E6%9E%90-3-%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/memory_waste.jpeg" class="">

<p>这张图里面表示的是每个token对应的kvcache的slot。对于一个context长度中用不到的slots部分，有预留的slots和不同空隙之间的slots空隙。</p>
<p>vLLM参考了虚拟内存和内存页分配的逻辑构造了一个block table用于 kv cache block slots 和 token之间的关系。通过block表的管理<br>可以像操作系统一下减少内存碎片。<br>因为不同的sequence中token是有位置信息的，所有他们对应的kv slot也不一定一样。下图展示了他们的关系。</p>
<img data-src="/zh-CN/2024/12/13/vLLM-%E5%88%86%E6%9E%90-3-%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/block_table.png" class="">

<h2 id="Continuous-Batching"><a href="#Continuous-Batching" class="headerlink" title="Continuous Batching"></a>Continuous Batching</h2><p>“连续批量处理”（Continuous Batching），也称为”动态批量处理”（Dynamic Batching）或”迭代级调度批量处理”（Batching with Iteration-Level Scheduling），是一种选择Batch行的技术，用于优化计算和资源利用率。<br>它的主要区别在于与静态批处理相比，它会在每次推理迭代过程中动态调整Batch中的序列，例如vLLM会抢占部分序列，将序列的prefill阶段和decode阶段分开，不在同一个batch中处理。</p>
<p>而HuggingFace的text-generation-inference的router<a target="_blank" rel="noopener" href="https://github.com/huggingface/text-generation-inference/blob/main/router/README.md">文档</a>中提到的：为了提高效率，特别是在文本生成和内存受限的LLM上，可以让客户端发送单个查询，然后路由器将这些查询合并或分离成批次，以最大限度地利用计算资源。这是因为在LLM中，运行模型的计算成本远远高于批处理的成本。当新请求到达时，当前正在<code>forward</code>的前向传播不中断，而是继续等待执行完毕。然后将当前正在处理的请求与新到的请求合并成一个批处理请求，再进行<code>forward</code>前向传播。在批处理请求中，任何一个请求完成（即模型产生了终止符或达到允许的最大长度），则从批处理请求中移除该请求，并释放相关资源。这种方法可以应用于多个请求，并且支持在不同参数下的处理（例如采样、不采样、温度控制等），因为每个请求在批处理中都可以独立进行处理。Anyscale 对这个过程有很好的<a target="_blank" rel="noopener" href="https://www.anyscale.com/blog/continuous-batching-llm-inference">解释</a>。</p>
<img data-src="/zh-CN/2024/12/13/vLLM-%E5%88%86%E6%9E%90-3-%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/continous_batching.png" class="">

<h3 id="Prefill-和-Decode"><a href="#Prefill-和-Decode" class="headerlink" title="Prefill 和 Decode"></a>Prefill 和 Decode</h3><p>在LLM推理过程中，一个Prompt的第一次执行（称为prefill）和后续的前向传播（称为decode）是不同的。Prefill阶段需要计算整个注意力矩阵并将其缓存到KV缓存中，计算规模较大，尤其是对于长度为10K或100K的提示词。而在decode阶段，只需计算新生成的token的注意力矩阵，计算规模较小。</p>
<p>从Kimi的<a target="_blank" rel="noopener" href="https://arxiv.org/html/2407.00079v2">Mooncake</a>论文中的图片来看：</p>
<img data-src="/zh-CN/2024/12/13/vLLM-%E5%88%86%E6%9E%90-3-%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/prefill_decode.png" class="">

<p>左图显示，当prompt长度增加时，计算时间呈平方级别增加。右图显示，decode阶段只生成一个token，计算规模比线性增长还要慢一点，但由于需要复用之前的KV缓存，因此显存开销较大。Mooncake的解决方案是将prefill和decode分开处理，prefill计算规模大，decode计算规模小，通过KV缓存共享机制传递KV缓存。论文还提到了一些关于缓存调度的细节，这里不再展开。</p>
<p>在Prefill阶段，所有的提示词（prompt）都是已知的，因此可以并行计算多个token，计算并行度较高。而在Decode阶段，只需根据新生成的token计算下一个token（之前的KV缓存已经保存了中间结果），因此计算规模较小。如果将Prefill和Decode放在同一个batch中计算，由于计算规模不对等，容易产生计算空隙（bubble）。</p>
<p>Prefill像是一个矩阵和矩阵的乘法，而Decode则是一个向量和矩阵的乘法。</p>
<h2 id="Chunked-Prefill"><a href="#Chunked-Prefill" class="headerlink" title="Chunked Prefill"></a>Chunked Prefill</h2><p>vLLM的<a target="_blank" rel="noopener" href="https://docs.google.com/document/d/1Z9TvqzzBPnh5WHcRwjvK2UEeFeq5zMZb5mFE8jR0HCs/edit?pli=1&tab=t.0">文档</a>很好的解释了prefill阶段和decode阶段的区别。</p>
<p>考虑到vLLM进行生成的序列“ABC”。当它到达时，KV缓存基于block size的预设值（这里是2）在内存中分配对应的block（B1，B2，B3，B4），但它是空的。<br>我们知道序列的内容（A，B，C），但我们没有token id到块索引的映射。</p>
<img data-src="/zh-CN/2024/12/13/vLLM-%E5%88%86%E6%9E%90-3-%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/prefill_1.png" class="">

<p>考虑到这种情况，下一步是为序列ABC进行prefill。在调度过程中，我们为序列中每个token块分配块索引（B3，B4），即（[A, B], [C, _]）。</p>
<img data-src="/zh-CN/2024/12/13/vLLM-%E5%88%86%E6%9E%90-3-%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/prefill_2.png" class="">

<p>一旦确定了块映射，我们就可以通过运行模型的前向传播。这会将ABC token的KV激活值写入KV缓存中的相应位置。此外，前向传播将导致新token “D” 被采样。D的KV值尚未知晓。</p>
<img data-src="/zh-CN/2024/12/13/vLLM-%E5%88%86%E6%9E%90-3-%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/prefill_3.png" class="">

<p>现在，序列已经完成了预填充。我们可以安排一个解码步骤。这涉及为新token “D” 分配块映射。然而，由于它适合现有的块映射，调度器不需要分配新的映射。</p>
<img data-src="/zh-CN/2024/12/13/vLLM-%E5%88%86%E6%9E%90-3-%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/prefill_4.png" class="">

<p>然后我们再次运行模型，计算并将“D”的KV写入KV缓存。这会生成一个新的token “E”。</p>
<img data-src="/zh-CN/2024/12/13/vLLM-%E5%88%86%E6%9E%90-3-%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/prefill_5.png" class="">

<p>这个过程会重复进行直到解码完成。请注意，后续的分配可能是不连续的。</p>
<img data-src="/zh-CN/2024/12/13/vLLM-%E5%88%86%E6%9E%90-3-%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/prefill_6.png" class="">


<h2 id="Speculative-Decoding"><a href="#Speculative-Decoding" class="headerlink" title="Speculative Decoding"></a>Speculative Decoding</h2><p>Speculative Decoding利用小型、快速的草案（draft）模型生成初始token（token是输入信息的基本单元）时的高效性，而在验证阶段则依赖更大的、更准确的大型语言模型（LLM）进行验证。</p>
<p>这个过程可以分为两步：</p>
<ol>
<li><strong>初始token生成</strong>：使用小型、快速的草案模型生成初始token。这一步骤快速生成token序列，使得下一步骤可以快速开始。</li>
<li><strong>验证</strong>：使用更大的、更准确的LLM对初始token进行验证。这一步骤确保生成的token序列是准确的和有效的。</li>
</ol>
<p>这种技术通过将任务分成两个阶段来实现高效性和准确性：快速生成初始token，然后验证这些token以确保准确性。</p>
<p>其实现方式如下：</p>
<ul>
<li>使用小模型进行多次decode，生成多个token序列。</li>
<li>将这些token序列传递给大模型进行验证。大模型会生成对应的logits，形状为<code>(batch, sequence, vocab_size)</code>，并进行softmax处理。</li>
<li>对于单步decode，logits的形状为<code>(batch, 1, vocab_size)</code>，其中的1表示最后一个token，在词汇表(vocab_size)上的概率分布。</li>
</ul>
<p>例如，将小模型生成的”abcd” token序列传递给大模型，得到”ABCD”的logits。A对应的是用于预测B的概率分布，在这个序列中就是预测第二个token的概率分布。将b对应的token id在A的<code>vocab_size</code>长度的log prob中的值取出，对应的可能是B token id的概率，也可能不是。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a | b | c | d</span><br><span class="line">    ^   ^   ^</span><br><span class="line">  | A | B | C | D </span><br></pre></td></tr></table></figure>

<p>最后，将b、c、d在大模型中对应的logits prob求和并取平均值。如果这个值大于一个阈值，就认为这个token是合理的，否则就拒绝。</p>
<p>这种方法通过结合小模型的快速生成能力和大模型的高准确性，实现了高效且准确的token生成过程。</p>
<p>根据论文[<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2406.14066]%E6%9D%A5%E8%AF%B4%EF%BC%8C%E5%9C%A8continus">https://arxiv.org/pdf/2406.14066]来说，在continus</a> batching的情况下，Speculative Decoding可以提高推理速度，减少计算资源的浪费。</p>
<img data-src="/zh-CN/2024/12/13/vLLM-%E5%88%86%E6%9E%90-3-%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/spd.png" class="">

<p>在Target模型验证完以后，还会多生成一个bonus token，也就是上面的那个D。</p>
<p>其中Decoding也产生了很多的方法，有基于模型的，也有model free的，才用大模型的一部分，或者直接从外部数据库来获取。</p>
<blockquote>
<p>结果表明，在低请求率下（具体来说，请求率为 4），提出 3 个或 5 个令牌会带来最显著的加速。然而，随着请求率的增加，提出更多令牌的优势迅速减弱：当请求率超过 12 时，提出 5 个令牌不再带来性能提升。同样，在请求率大于 16 时，提出 3 个令牌会导致性能下降。</p>
</blockquote>
<img data-src="/zh-CN/2024/12/13/vLLM-%E5%88%86%E6%9E%90-3-%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/p_l.png" class="">

<p>其中不同的颗粒度的猜测长度也会对性能有影响。</p>
<p>全局统一的长度；每个step所有request用一个长度；每个step每个request用不同的长度。</p>
<p>相较于吞吐，Goodput规定只有没被拒绝的token才计算，用来衡量最总的性能。</p>
<img data-src="/zh-CN/2024/12/13/vLLM-%E5%88%86%E6%9E%90-3-%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/pl_bs_gp_relation.png" class="">

<p>这张图展示了猜测长度和batch size对于Goodput的影响。</p>
<p>对于小批次，要多猜测（propose），小批次尺寸下每次请求需提议超 4 个 token 以实现最大有效吞吐量（goodput），且随着批次尺寸增大，最优猜测长度会降低；<br>对于大批次，则要少猜测，甚至不进行推测反而能获得更高有效吞吐量，因为大批次下推测失败成本显著增加，超过潜在收益。</p>
<p>除了朴素的猜测模型，里面也提到了Medusa风格的猜测模型。预测3个token就有三个head分别预测每个位置。<br>里面的例子head 1猜了三个，对了1个，head 2猜了2个对了一个，head3猜了3个全错了，然后加上LLM的bonus token。</p>
<img data-src="/zh-CN/2024/12/13/vLLM-%E5%88%86%E6%9E%90-3-%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/medusa.png" class="">

<p>SmartSpec 估算Goodput的方法就是根据成功率计算期望长度再乘上Request对应的时间。<br>然后根据不同的batch size计算Goodput，让Goodput最大化，得到最佳Goodput从而让吞吐最大化。</p>
<h2 id="Automatic-Prefix-Caching"><a href="#Automatic-Prefix-Caching" class="headerlink" title="Automatic Prefix Caching"></a>Automatic Prefix Caching</h2><p>一般的LLM请求的提示词会非常长，据说OpenAI的系统提示词已经有几K了，这个规模很适合做前缀缓存。<br>前缀缓存是指将提示词分成多个前缀，然后将这些前缀缓存到KV缓存中，这样在生成token的时候就可以直接使用KV缓存中的值，<br>而不需要重新计算。这样可以减少计算量，提高推理速度。<br>当然在vLLM中kv cache是分块的，所以prefix 也是分块的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">                    Block 1                  Block 2                  Block 3</span><br><span class="line">         [A gentle breeze stirred] [the leaves as children] [laughed in the distance]</span><br><span class="line">Block 1: |&lt;--- block tokens ----&gt;|</span><br><span class="line">Block 2: |&lt;------- prefix ------&gt;| |&lt;--- block tokens ---&gt;|</span><br><span class="line">Block 3: |&lt;------------------ prefix --------------------&gt;| |&lt;--- block tokens ----&gt;|</span><br></pre></td></tr></table></figure>
<h2 id="Multi-LoRA-Serving"><a href="#Multi-LoRA-Serving" class="headerlink" title="Multi-LoRA Serving"></a>Multi-LoRA Serving</h2><p>VLLM当中的LoRA Adaptor是可以动态加载的，因为他本身和基座模型保持独立。<br>这里要注意的一个点是，如果词汇表修改了，会影响最后的llm head，比如英文基座模型用中文词汇表，那么 vocab_size 就不一样了。<br>会导致llm head的输出维度不一样，这个时候就需要重新训练llm head。<br>所以要注意最后的llm head的输出维度。</p>
<h2 id="Tensor-Parallelism"><a href="#Tensor-Parallelism" class="headerlink" title="Tensor Parallelism"></a>Tensor Parallelism</h2><p>张量并行（Tensor Parallelism）是一种将大型模型的计算任务分解到多个GPU上并行执行的技术。它通过将模型的权重矩阵切分成多个子矩阵，并将这些子矩阵分配到不同的GPU上进行计算，从而实现并行计算。</p>
<p>在Transformer模型中，QKV（Query, Key, Value）矩阵乘法是计算量最大的部分之一。通过将QKV矩阵切分成更小的子矩阵，并将这些子矩阵分配到不同的GPU上，可以显著提高计算效率。</p>
<p>例如，对于一个具有<code>d_model</code>维度的QKV矩阵，可以将其切分成<code>n</code>个子矩阵，每个子矩阵的维度为<code>d_model / n</code>。然后，将这些子矩阵分配到<code>n</code>个GPU上进行并行计算。这样，每个GPU只需要计算一个较小的子矩阵，从而减少了计算时间。</p>
<p>张量并行的实现方式如下：</p>
<ol>
<li><strong>切分权重矩阵</strong>：将模型的权重矩阵切分成多个子矩阵。例如，对于一个<code>d_model x d_model</code>的权重矩阵，可以将其切分成<code>n</code>个<code>d_model x (d_model / n)</code>的子矩阵。</li>
<li><strong>分配子矩阵</strong>：将切分后的子矩阵分配到不同的GPU上。例如，将第一个子矩阵分配到GPU 0，第二个子矩阵分配到GPU 1，以此类推。</li>
<li><strong>并行计算</strong>：在每个GPU上并行执行矩阵乘法计算。例如，在GPU 0上计算输入矩阵与第一个子矩阵的乘积，在GPU 1上计算输入矩阵与第二个子矩阵的乘积，以此类推。</li>
<li><strong>聚合结果</strong>：将所有GPU上的计算结果聚合起来，得到最终的输出。例如，将所有子矩阵的乘积结果相加，得到最终的QKV矩阵乘积结果。</li>
</ol>
<p>通过张量并行，可以显著提高大型模型的计算效率，减少推理时间，从而提高模型的推理速度和性能。</p>
<h2 id="Pipeline-Parallelism"><a href="#Pipeline-Parallelism" class="headerlink" title="Pipeline Parallelism"></a>Pipeline Parallelism</h2><p>Pipeline Parallelism通过将模型的不同层分配到不同的GPU上来实现并行计算，特别是一些大型模型。这种方法可以提高计算效率，但也会引入一些挑战，例如在层之间传递数据时可能会产生延迟。此外，由于不同层的计算时间可能不一致，可能会导致某些GPU在等待其他GPU完成计算时处于空闲状态，从而产生计算空隙（bubble）。</p>
<p>为了减少这些计算空隙，可以使用Chunked Prefill技术。Chunked Prefill通过将计算任务分成更小的块，从而缩短每个计算任务的时间。这使得在流水线并行中可以更灵活地安排计算任务，从而尽可能地填满计算空隙，提高整体计算效率。</p>
<p>通过结合Pipeline Parallelism和Chunked Prefill，可以在保持高效计算的同时，最大限度地利用计算资源，减少计算空隙，提高模型推理的速度和效率。</p>
<p>在vLLM当中 TP=n 且 PP=m 时，vLLM 引擎总共会有 n*m + 1 个进程。即使使用单个 GPU，我们也会有 2 个进程。</p>
<h2 id="衡量LLM的服务指标"><a href="#衡量LLM的服务指标" class="headerlink" title="衡量LLM的服务指标"></a>衡量LLM的服务指标</h2><p>在衡量LLM服务性能时，Token相关的数据是一个重要的方面。以下是一些常见的Token相关指标：</p>
<h3 id="Token-Throughput"><a href="#Token-Throughput" class="headerlink" title="Token Throughput"></a>Token Throughput</h3><p>Token Throughput表示每秒生成的token数量。它是衡量模型生成速度的一个重要指标，通常以tokens per minute (TPM)为单位。</p>
<h3 id="Token-Latency"><a href="#Token-Latency" class="headerlink" title="Token Latency"></a>Token Latency</h3><p>Token Latency表示生成一个token所需的时间。它是衡量模型响应速度的一个重要指标，通常以毫秒(ms)为单位。Token Latency包括以下几个子指标：</p>
<ul>
<li>**TTFT (Time To First Token)**：从请求到第一个token生成的时间。例如，当prompt变长时，TTFT会变长；或者当kv cache不足时被抢占，TTFT也会变长。</li>
<li>**TBT (Time Between Tokens)**：生成两个token之间的时间。例如，当batch size变大时，TBT会变大。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ggaaooppeenngg.github.io/zh-CN/2024/12/10/vLLM-%E5%88%86%E6%9E%902-%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ggaaooppeenngg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ggaaooppeenngg">
      <meta itemprop="description" content="为什么计算机科学是无限的但生命是有限的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ggaaooppeenngg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/zh-CN/2024/12/10/vLLM-%E5%88%86%E6%9E%902-%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/" class="post-title-link" itemprop="url">vLLM 分析2 计算引擎</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-12-10 15:25:12" itemprop="dateCreated datePublished" datetime="2024-12-10T15:25:12+08:00">2024-12-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-28 18:39:05" itemprop="dateModified" datetime="2025-03-28T18:39:05+08:00">2025-03-28</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/zh-CN/2024/12/10/vLLM-%E5%88%86%E6%9E%902-%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="zh-CN/2024/12/10/vLLM-分析2-计算引擎/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>vLLM的一个主要贡献就是PagedAttention，可以实现更高效的推理。</p>
<p>高效的语言模型服务系统（LLM）需要批量处理多个请求。然而，现有系统存在以下问题：</p>
<ul>
<li>每个请求的key-value缓存（KV缓存）内存巨大，动态增长和减少。</li>
<li>容易因为碎片化和冗余复制导致内存浪费，限制了批量大小。</li>
</ul>
<p>为了解决这些问题，提出了PagedAttention，一个基于虚拟内存和分页技术的注意力算法。基于此，开发了vLLM，一个LLM服务系统，实现了以下两个目标：</p>
<ol>
<li>KV缓存显存的几乎零浪费，减少了显存碎片。</li>
<li>KV缓存在请求之间和请求内共享，进一步减少显存使用。</li>
</ol>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2309.06180">论文</a>包含了他早期设计。</p>
<p>一次调用的示例如<a target="_blank" rel="noopener" href="https://blog.vllm.ai/2023/06/20/vllm.html">博客</a>中展示的。</p>
<img data-src="/zh-CN/2024/12/10/vLLM-%E5%88%86%E6%9E%902-%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/annimation1.gif" class="">

<h2 id="AsyncLLM"><a href="#AsyncLLM" class="headerlink" title="AsyncLLM"></a>AsyncLLM</h2><p><code>generate</code>细节：</p>
<ul>
<li>如果引擎没有运行，启动后台循环，循环调用 <code>_run_output_handler</code> 方法来处理等待的请求。</li>
<li>从 <code>AsyncStream</code> 中等待请求输出并生成它们。</li>
</ul>
<p>engine会在启动之前profile一下，把剩余的显存分配给kv cache用。</p>
<p>AsyncStream 对 asyncio.Queue的封装，支持了终止的能力，当finish的时候会丢入一个STOP_ITERATION的exception，这样可以让调用者知道这个stream已经结束了。</p>
<p>每当有一个对话请求的时候调用<code>add_request</code>就会生成一个这样的AsycStream用于处理对话的输出，其中副作用就是判断backgroud loop没有启动的时候，启动backgroundloop。</p>
<p>AsyncEngine本身有一个<code>_new_request</code>的Queue用户保存request的AsyncStream。</p>
<p><code>generate</code>方法会不断从AsyncStream中yield出结果，直到遇到STOP_ITERATION。</p>
<p>loop的主体如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1) Pull EngineCoreOutput from the EngineCore.</span></span><br><span class="line">outputs = <span class="keyword">await</span> <span class="variable language_">self</span>.engine_core.get_output_async()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2) Detokenize based on the output.</span></span><br><span class="line">request_outputs, reqs_to_abort = <span class="variable language_">self</span>.detokenizer.step(outputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3) Put the RequestOutputs into the per-request AsyncStreams.</span></span><br><span class="line"><span class="variable language_">self</span>._process_request_outputs(request_outputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4) Abort any requests that finished due to stop strings.</span></span><br><span class="line"><span class="keyword">await</span> <span class="variable language_">self</span>.engine_core.abort_requests_async(reqs_to_abort)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5) Abort any requests due to client cancellations.</span></span><br><span class="line"><span class="keyword">await</span> <span class="variable language_">self</span>._process_cancellations()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<blockquote>
<p>When TP=n &amp; PP=m, vLLM engine will have n*m + 1 processes in total.<br>Corollary: even when using a single GPU, we will have 2 processes.</p>
</blockquote>
<h2 id="EngineCore"><a href="#EngineCore" class="headerlink" title="EngineCore"></a>EngineCore</h2><p>EngineCore主要是完成 schedule、execute 和 output 的循环。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">step</span>(<span class="params">self</span>) -&gt; <span class="type">List</span>[EngineCoreOutput]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Schedule, execute, and make output.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.scheduler.has_unfinished_requests():</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line">    scheduler_output = <span class="variable language_">self</span>.scheduler.schedule()</span><br><span class="line">    output = <span class="variable language_">self</span>.model_executor.execute_model(scheduler_output)</span><br><span class="line">    engine_core_outputs = <span class="variable language_">self</span>.scheduler.update_from_output(</span><br><span class="line">        scheduler_output, output)</span><br><span class="line">    <span class="keyword">return</span> engine_core_outputs</span><br></pre></td></tr></table></figure>
<h2 id="Request"><a href="#Request" class="headerlink" title="Request"></a>Request</h2><p>在具体分析之前，先看看 Request 的定义，这个数据结构串联了很多东西。</p>
<p>属性 <code>num_tokens</code> 代表的是 <code>prompt_tokens</code> 和 <code>output_tokens</code> 的总数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@property</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">num_tokens</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>._all_token_ids)</span><br></pre></td></tr></table></figure>

<p><code>num_output_tokens</code> 代表 output tokens 的数量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@property</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">num_output_tokens</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>._output_token_ids)</span><br></pre></td></tr></table></figure>

<p><code>append_output_token_ids</code> 会改变上述的两个属性。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">append_output_token_ids</span>(<span class="params"></span></span><br><span class="line"><span class="params">    self,</span></span><br><span class="line"><span class="params">    token_ids: <span class="type">Union</span>[<span class="built_in">int</span>, <span class="type">List</span>[<span class="built_in">int</span>]],</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(token_ids, <span class="built_in">int</span>):</span><br><span class="line">        token_ids = [token_ids]</span><br><span class="line">    <span class="variable language_">self</span>._output_token_ids.extend(token_ids)</span><br><span class="line">    <span class="variable language_">self</span>._all_token_ids.extend(token_ids)</span><br></pre></td></tr></table></figure>

<p>在 <code>__init__</code> 方法中，会设置 <code>num_prompt_tokens</code>，这个是不变的，<code>num_computed_tokens</code> 会初始化为 0。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.prompt = <span class="variable language_">self</span>.inputs.prompt</span><br><span class="line"><span class="variable language_">self</span>.prompt_token_ids = <span class="variable language_">self</span>.inputs.prompt_token_ids</span><br><span class="line"><span class="variable language_">self</span>.num_prompt_tokens = <span class="built_in">len</span>(<span class="variable language_">self</span>.prompt_token_ids)</span><br><span class="line"><span class="variable language_">self</span>.num_computed_tokens = <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>所以在最开始时，<code>num_tokens</code> 和 <code>num_prompt_tokens</code> 是相等的。当 <code>prefill</code> 以后，<code>num_computed_tokens</code> 会逐渐（逐渐的原因是 prefill 可能会被 chunked 掉）等于 <code>num_prompt_tokens</code>。<code>decode</code> 以后，<code>num_tokens</code> 会等于 <code>num_prompt_tokens</code> 加上 <code>num_output_tokens</code>。如果 <code>computed_tokens</code> 等于 <code>num_tokens</code>，说明已经开始 decode 了，要开始一个 token 一个 token 计算了。</p>
<p>在调度过程中没有直接用 <code>computed_tokens</code> 等于 <code>num_prompt_tokens</code> 的原因是：如果一个 request 被抢占掉，那么 <code>num_tokens</code> 在 request 恢复的时候其实应该是 <code>num_prompt_tokens</code> 加上 <code>num_output_tokens</code>，这里做了一个统一的判断。如果把preempted的request重新处理的话其实相当于多了一些output tokens的prompt的新request。</p>
<h2 id="Scheduler"><a href="#Scheduler" class="headerlink" title="Scheduler"></a>Scheduler</h2><p>从 EngineCore 的 step 方法来看，目前的调度是同步的 <code>schedule | execute model | update_from_output | schedule | execute model | update_from_output</code>，这样会导致计算和调度之间的时间差，这个时间差会导致计算的时间没有充分利用，从而导致资源的浪费。后面的版本应该会有优化。</p>
<p>Scheduler 的 V1 版本把一些 chunked prefill 还有 prefix caching 的内容拆离出去，做得比较通用。</p>
<p>vLLM 实现了一种所有或无（all-or-nothing）驱逐策略，即要么驱逐一个序列中的所有块，要么不驱逐任何块。</p>
<p>接下来看看来自 <code>v1/core/scheduler.py</code> 的 V1 版本的 <code>schedule</code> 实现。</p>
<p>Scheduler 有个 waiting list 和 running list（位置代表权重，是 FIFO 的）。</p>
<p>从 running list 中获取 request 然后通过 <code>kv_cache_manager</code> 执行 <code>append_slots</code> 把新的 block 追加到 request 的 block chain 当中。如果最后一个 block 的 slot 还够的话，就不会追加新的 block。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">new_blocks = <span class="variable language_">self</span>.kv_cache_manager.append_slots(</span><br><span class="line">    request, num_new_tokens)</span><br></pre></td></tr></table></figure>

<p>如果当前的 <code>kv_cache</code> 的 block table 满了，则会抢占一个 running list 中的 request（放入 waiting list 中）并且把他的 cache block 都 free 掉，这里的 free 是引用计数的形式，如果引用计数为 0 就会被释放，但如果多个 request 共享了一个 block 就还不会被真正释放。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> new_blocks <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="comment"># The request cannot be scheduled.</span></span><br><span class="line">    <span class="comment"># Preempt the lowest-priority request.</span></span><br><span class="line">    preempted_req = <span class="variable language_">self</span>.running.pop()</span><br><span class="line">    <span class="variable language_">self</span>.kv_cache_manager.free(preempted_req)</span><br><span class="line">    preempted_req.status = RequestStatus.PREEMPTED</span><br><span class="line">    <span class="variable language_">self</span>.waiting.appendleft(preempted_req)</span><br><span class="line">    preempted_reqs.append(preempted_req)</span><br></pre></td></tr></table></figure>

<p>加入到 <code>scheduled_running_reqs</code> 中，消耗这次调度的 token budget，这个 budget 用完以后就会停止调度了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scheduled_running_reqs.append(request)</span><br><span class="line">req_to_new_block_ids[request.request_id] = [</span><br><span class="line">    b.block_id <span class="keyword">for</span> b <span class="keyword">in</span> new_blocks</span><br><span class="line">]</span><br><span class="line">num_scheduled_tokens[request.request_id] = num_new_tokens</span><br><span class="line">token_budget -= num_new_tokens</span><br><span class="line">req_index += <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>如果没有抢占请求则说明还是比较富裕的，尝试从 waiting list 中获取 request，waiting list 可能有新请求也可能有之前被抢占的请求，然后执行一遍上面的代码，不同的是需要从 <code>kv_cache_manager</code> 计算 <code>computed_tokens</code>，因为被之前被抢占的或者一些有共同前缀的 kv cache block 是已经缓存过的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">request = <span class="variable language_">self</span>.waiting[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># Get already-cached tokens.</span></span><br><span class="line">computed_blocks = <span class="variable language_">self</span>.kv_cache_manager.get_computed_blocks(</span><br><span class="line">    request)</span><br><span class="line"><span class="comment"># NOTE(woosuk): Since incomplete blocks are not eligible for</span></span><br><span class="line"><span class="comment"># sharing, `num_computed_tokens` is always a multiple of</span></span><br><span class="line"><span class="comment"># `block_size`.</span></span><br><span class="line">num_computed_tokens = <span class="built_in">len</span>(computed_blocks) * <span class="variable language_">self</span>.block_size</span><br></pre></td></tr></table></figure>

<p>最后把每个 request 分配到的 tokens 数量记录到 <code>SchedulerOutput</code> 当中。</p>
<p><code>update_from_output</code> 接受 <code>SchedulerOutput</code> 和 <code>ModelExecutorOutput</code>，更新 request 的状态，例如更新已经计算的 token 数量，更新 kv cache 的 block 等。对于每个请求都会检查 <code>request.num_computed_tokens == request.num_tokens</code> 从而判断是否已经开始 decode 的部分了。然后构造 <code>EngineCoreOutput</code>，并且检查是否需要停止这个 request。<code>_check_stop</code> 方法会检查是否已经生成了 eos token 或者已经达到了最大长度，并且 free 掉对应的 request。所有没有 stop 的 request 会重新加入到 running 队列中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> request.num_computed_tokens == request.num_tokens:</span><br><span class="line">    req_index = model_runner_output.req_id_to_index[req_id]</span><br><span class="line">    <span class="comment"># NOTE(woosuk): Currently, we assume that each request</span></span><br><span class="line">    <span class="comment"># generates at most one token at each step.</span></span><br><span class="line">    token_id = sampled_token_ids[req_index]</span><br><span class="line">    request.append_output_token_ids(token_id)</span><br><span class="line">    num_new_tokens = <span class="number">1</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Update the KV cache manager for prefix caching.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Check for stop and update request state.</span></span><br><span class="line">    <span class="comment"># This must be called before me make the EngineCoreOutput.</span></span><br><span class="line">    stopped = <span class="variable language_">self</span>._check_stop(request)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Add EngineCoreOutput for this Request.</span></span><br><span class="line">    output = EngineCoreOutput(</span><br><span class="line">        request_id=req_id,</span><br><span class="line">        new_token_ids=request.output_token_ids[-num_new_tokens:],</span><br><span class="line">        finished=request.is_finished(),</span><br><span class="line">        finish_reason=request.get_finished_reason(),</span><br><span class="line">        stop_reason=request.stop_reason)</span><br><span class="line">    engine_core_outputs.append(output)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Breakout of the loop.</span></span><br><span class="line">    <span class="keyword">if</span> stopped:</span><br><span class="line">        <span class="keyword">continue</span></span><br></pre></td></tr></table></figure>

<h3 id="SchedulerOutput"><a href="#SchedulerOutput" class="headerlink" title="SchedulerOutput"></a>SchedulerOutput</h3><p>该类包含了调度器的输出信息。以下是各个字段的作用：</p>
<ul>
<li><p><strong>scheduled_new_reqs: List[NewRequestData]</strong></p>
<ul>
<li>作用：存储新请求的数据列表，这些请求是刚刚被调度的。</li>
</ul>
</li>
<li><p><strong>scheduled_resumed_reqs: List[ResumedRequestData]</strong></p>
<ul>
<li>作用：存储恢复请求的数据列表，这些请求是之前被暂停，现在重新被调度的。</li>
</ul>
</li>
<li><p><strong>scheduled_running_reqs: List[RunningRequestData]</strong></p>
<ul>
<li>作用：存储正在运行请求的数据列表，这些请求在当前调度周期内继续运行。</li>
</ul>
</li>
<li><p><strong>num_scheduled_tokens: Dict[str, int]</strong></p>
<ul>
<li>作用：存储每个请求调度的token数量，键是请求的ID，值是对应的token数量。</li>
</ul>
</li>
<li><p><strong>total_num_scheduled_tokens: int</strong></p>
<ul>
<li>作用：存储所有请求调度的token总数。</li>
</ul>
</li>
<li><p><strong>scheduled_encoder_inputs: Dict[str, List[int]]</strong></p>
<ul>
<li>作用：存储每个请求的编码器输入，键是请求的ID，值是对应的编码器输入列表。</li>
</ul>
</li>
<li><p><strong>preempted_req_ids: Set[str]</strong></p>
<ul>
<li>作用：存储被抢占的请求ID集合，这些请求在当前调度周期内被暂停。</li>
</ul>
</li>
<li><p><strong>finished_req_ids: Set[str]</strong></p>
<ul>
<li>作用：存储已完成的请求ID集合，这些请求在当前调度周期内完成。</li>
</ul>
</li>
<li><p><strong>free_encoder_input_ids: List[Tuple[str, int]]</strong></p>
<ul>
<li>作用：存储空闲的编码器输入ID列表，每个元素是一个元组，包含请求ID和对应的编码器输入ID。</li>
</ul>
</li>
</ul>
<p>这些字段共同描述了调度器在一个调度周期内的所有操作和状态变化。</p>
<h2 id="KVCacheManager"><a href="#KVCacheManager" class="headerlink" title="KVCacheManager"></a>KVCacheManager</h2><p>来自<code>v1/core/kv_cache_manager.py</code>，这是v1版本的实现。</p>
<p>kv cache比较简单，<br>这个<a target="_blank" rel="noopener" href="https://medium.com/my-musings-with-llms/understanding-kv-cache-and-paged-attention-in-llms-a-deep-dive-into-efficient-inference-62fa372432ce">博客</a>中的图片很好地阐述了kvcache的作用。</p>
<img data-src="/zh-CN/2024/12/10/vLLM-%E5%88%86%E6%9E%902-%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/kvcache.gif" class="" title="KV Cache">

<p>但涉及PagedAttention的实现，就需要管理block。这类似于操作系统中的虚拟地址、页表和物理页的关系。</p>
<p>PagedAttention的主要思想是基于操作系统中分页（paging）的经典概念。传统的注意力算法通常要求keys和values在内存空间中连续存储，<br>而PagedAttention则允许在非连续的内存空间中存储keys和values。</p>
<p>PagedAttention将每个序列（sequence）的KV缓存（KV cache）分成固定大小的块（block）。<br>每个块包含一个固定数量的token的key和value向量。这意味着，即使keys和values不连续存储，也可以有效地访问和操作它们。</p>
<p>block的管理会有一个类似于页表的结构，用于映射block的逻辑地址到物理地址。</p>
<img data-src="/zh-CN/2024/12/10/vLLM-%E5%88%86%E6%9E%902-%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/block_table.png" class="">

<p>论文中的这个图很好的表示了他们的关系，如果新生成的token填满了当前block就会分配一个新的block用于新token的生成。</p>
<p>共享的prefix cache指的是提示词的前缀一样的情况，他们的位置编码也不变的情况下可以在不同的sequence之间共享。<br>例如对于一个英语到法语翻译的提示词，前面有很多事可以共享的，对于跨请求的kv cache来说可以基于这个前缀来共享kv cache的block。</p>
<table>
<thead>
<tr>
<th>序列</th>
<th>前缀 (Prefix)</th>
<th>输入任务 (Task Input)</th>
<th>完整提示 (Complete Prompt)</th>
<th>LLM 输出 (LLM Output)</th>
<th>输出任务 (Task Output)</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Sequence A</strong></td>
<td>Translate English to French: <br> “sea otter” =&gt; “loutre de mer” <br> “peppermint” =&gt; “menthe poivrée” <br> “plush giraffe” =&gt; “girafe en peluche”</td>
<td>“cheese” =&gt;</td>
<td>Translate English to French: <br> “sea otter” =&gt; “loutre de mer” <br> “peppermint” =&gt; “menthe poivrée” <br> “plush giraffe” =&gt; “girafe en peluche” <br> “cheese” =&gt;</td>
<td>fromage</td>
<td>fromage</td>
</tr>
<tr>
<td><strong>Sequence B</strong></td>
<td>Translate English to French: <br> “sea otter” =&gt; “loutre de mer” <br> “peppermint” =&gt; “menthe poivrée” <br> “plush giraffe” =&gt; “girafe en peluche”</td>
<td>“I love you” =&gt;</td>
<td>Translate English to French: <br> “sea otter” =&gt; “loutre de mer” <br> “peppermint” =&gt; “menthe poivrée” <br> “plush giraffe” =&gt; “girafe en peluche” <br> “I love you” =&gt;</td>
<td>Je t’aime</td>
<td>Je t’aime</td>
</tr>
</tbody></table>
<p><code>free_block_queue</code>是一个链表，用于分配block，初始化时将<code>block_pool</code>中的所有blocks串起来。它通过链表实现对<code>KVCacheBlock</code>的管理，删除操作是O(1)的，没有使用标准库中的dequeue。</p>
<p><code>KVCacheBlock</code>除了prev和next指针，还有<code>ref_count</code>和<code>_block_hash</code>，用于prefix caching的计算。其key是父block的hash和当前block的tokens ids的hash。</p>
<p><code>block_pool</code>代表物理block的映射关系，例如<code>0 -&gt; 第一块block</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># A Block pool of all kv-cache blocks.</span></span><br><span class="line"><span class="variable language_">self</span>.block_pool: <span class="type">List</span>[KVCacheBlock] = [</span><br><span class="line">    KVCacheBlock(idx) <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(num_gpu_blocks)</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p><code>cached_block_hash_to_block</code> 保存的数据结构是 <code>&#123;block_hash: &#123;block ID: block&#125;&#125;</code></p>
<p><code>req_to_blocks</code> 保存了 request到 block列表的映射关系，<code>&#123;request ID: [block ID]&#125;</code></p>
<p>block的eviction的定义，<code>eviction candidate == in free queue and ref_cnt == 0</code>。</p>
<h3 id="get-computed-blocks方法"><a href="#get-computed-blocks方法" class="headerlink" title="get_computed_blocks方法"></a><code>get_computed_blocks</code>方法</h3><p>根据request获取已经计算过（缓存过）的block，获取kv cache blocks的方式是通过block hash 从<code>cached_block_hash_to_block</code>寻找的。<br>hash的计算是之前的block hash加上当前token ids做一次hash，第一个block则没有父block只用当前自己的token ids做hash。</p>
<h3 id="append-slots方法"><a href="#append-slots方法" class="headerlink" title="append_slots方法"></a><code>append_slots</code>方法</h3><p>会为需要新计算的token ids分配block（如果现有的block不够的话）。</p>
<h2 id="Worker"><a href="#Worker" class="headerlink" title="Worker"></a>Worker</h2><h3 id="GPUModelRunner"><a href="#GPUModelRunner" class="headerlink" title="GPUModelRunner"></a>GPUModelRunner</h3><p><code>v1/worker</code>中的<code>gpu_runner.py</code>v1版本的实现。</p>
<p>首先依赖一个大的config参数<code>vllm_config</code>，包含了<code>model_config</code>，<code>cache_config</code>，<code>scheduler_config</code>，<code>device_config</code>等。</p>
<p>初始化kv cache的dtype，对照表如下，half就是fp16，float就是fp32，默认是和模型的dtype一样。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">STR_DTYPE_TO_TORCH_DTYPE = &#123;</span><br><span class="line">    <span class="string">&quot;half&quot;</span>: torch.half,</span><br><span class="line">    <span class="string">&quot;bfloat16&quot;</span>: torch.bfloat16,</span><br><span class="line">    <span class="string">&quot;float&quot;</span>: torch.<span class="built_in">float</span>,</span><br><span class="line">    <span class="string">&quot;fp8&quot;</span>: torch.uint8,</span><br><span class="line">    <span class="string">&quot;fp8_e4m3&quot;</span>: torch.uint8,</span><br><span class="line">    <span class="string">&quot;fp8_e5m2&quot;</span>: torch.uint8,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>初始化<code>sliding_window</code>的配置，这个东西在Qwen里面才用到。</p>
<p>初始化<code>block_size</code>，决定了kv cache中连续保存的token的数量，也就是PagedAttention中的那个block的大小，Prefix cache也是以block为维度的。</p>
<p>初始化<code>kv_heads</code>，这个决定了kv head的数量，如果指定了 <code>tensor_parallel_size</code>，会根据这个参数平均分给每个GPU。</p>
<p>初始化<code>head_size</code>，基于model config，是model config里面的<code>head_dim</code>。</p>
<p>初始化<code>hidden_size</code>，就是model config里面的<code>hidden_size</code>，就是<code>d_model</code>或者<code>embed_dim</code>，代表同一个长度。</p>
<p>初始化<code>kv_cache</code>。</p>
<p>初始化<code>encoder_cache</code> encoder结果的缓存。</p>
<p>初始化<code>input_registry</code> 和多模态的支持有关系。</p>
<p>初始化<code>requests</code> dict用于request的状态保存，这里的request就是一个文本的sequence。</p>
<p>初始化<code>InputBatch</code>，<code>max_num_seq</code>决定了batch的宽度，<code>max_model_len</code>决定了batch的长度。这个Batch对象负责管理在用于前向传播的batch当中的request的插入和删除。</p>
<p>初始化<code>use_cuda_graph</code> 这个由 enforce_eager 决定，默认是会加载整个计算图。</p>
<p>初始化<code>positions</code>: <code>torch.zeros(self.max_num_tokens, dtype=torch.int64, device=self.device)</code>。</p>
<p>初始化<code>input_embeds</code>，可以看到，宽度是<code>max_num_tokens</code>，长度是<code>hidden_size</code>，这个是用来存储输入的embedding的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.inputs_embeds = torch.zeros(</span><br><span class="line">    (<span class="variable language_">self</span>.max_num_tokens, <span class="variable language_">self</span>.hidden_size),</span><br><span class="line">    dtype=<span class="variable language_">self</span>.dtype,</span><br><span class="line">    device=<span class="variable language_">self</span>.device)</span><br></pre></td></tr></table></figure>

<h3 id="InputBatch"><a href="#InputBatch" class="headerlink" title="InputBatch"></a>InputBatch</h3><p>InputBatch在整个工程中负责管理和处理批量输入请求，确保请求的高效处理和管理。</p>
<h3 id="execute-model-方法"><a href="#execute-model-方法" class="headerlink" title="execute_model 方法"></a><code>execute_model</code> 方法</h3><p><code>execute_model</code>是整个<code>schedule | compute | update</code>循环中的核心部分，负责执行模型的前向传播。</p>
<h4 id="update-states方法"><a href="#update-states方法" class="headerlink" title="_update_states方法"></a><code>_update_states</code>方法</h4><p>在每次运行一个 batch 时，会根据调度器（scheduler）的要求调整每个 batch 中请求的优先级。调度器会更新请求的状态缓存 <code>id -&gt; CachedRequestState</code> 和 <code>input_batch</code> 的缓存，移除被抢占和停止的请求，并将新加入的请求放入 batch 中。因此，runner 只负责执行，具体的策略由调度器决定。</p>
<p><code>CachedRequestState</code> 记录了请求 ID、使用的缓存块 ID 以及已计算的 token 数量。</p>
<h4 id="excute-encoder方法"><a href="#excute-encoder方法" class="headerlink" title="_excute_encoder方法"></a><code>_excute_encoder</code>方法</h4><p>执行多模态中的encoder，对于新的多模态的encode，调用<code>model.process_mm_inputs</code>存入到encoder_cache当中。</p>
<p><code>self.model.compute_logits</code>使用<br><code>vllm/model_executor/layers/logits_processor.py</code>中的<code>LogitsProcessor</code>，从<code>hidden_states</code>计算<code>logits</code>。</p>
<p><code>self.model.sample</code>使用<code>vllm/model_executor/layers/sampler.py</code>中的sampler进行sample。</p>
<p>最终得到<code>sampled_token_ids = sampler_output.sampled_token_ids</code>。</p>
<h4 id="gather-encoder-outputs-方法"><a href="#gather-encoder-outputs-方法" class="headerlink" title="_gather_encoder_outputs 方法"></a><code>_gather_encoder_outputs</code> 方法</h4><p>从<code>encoder_cache</code>中获取当前batch需要用到的encoder的输出。</p>
<h4 id="prepare-inputs方法"><a href="#prepare-inputs方法" class="headerlink" title="_prepare_inputs方法"></a><code>_prepare_inputs</code>方法</h4><p><code>input_batch.block_table</code> 在 GPU 上，而 <code>input_batch.block_table_cpu_tensor</code> 在 CPU 上。<br>前面提到 batch 的整理是在 CPU 上进行的，这里是将要推理的部分拷贝到 GPU 上的 <code>block_table</code> 中。由于使用了 PagedAttention，因此所有的序列都是按 block 为粒度进行切分的。</p>
<p>获取<code>input_ids</code>，构造出传给FlashAttention的数据，例如<code>block_table</code>，和<code>query_start_loc</code>和<code>seq_start_loc</code>用于定位query和seq的位置。</p>
<p>input_ids, attn_metadata, logits_indices</p>
<h4 id="prepare-sampling方法"><a href="#prepare-sampling方法" class="headerlink" title="_prepare_sampling方法"></a><code>_prepare_sampling</code>方法</h4><p>构造出sampling的参数，获取每个request的<code>temperature</code>，<code>top_k</code>，<code>top_p</code>等参数。</p>
<h3 id="GPUWorker"><a href="#GPUWorker" class="headerlink" title="GPUWorker"></a>GPUWorker</h3><p><code>v1/worker</code>中的<code>gpu_worker.py</code>v1版本的实现。<br>初始化GPUModelRunner，如果开始了<code>VLLM_TORCH_PROFILER_DIR</code>就会调用<code>torch.profiler.profile</code>。</p>
<p><code>determine_num_available_blocks</code>会通过profile的方式决定可以使用的block数量。<br>然后根据block数量调用Runner的<code>initialize_kv_cache</code>。</p>
<p>做一些GPU的dtype支持检查，比如一些老的GPU是不支持bf16的。</p>
<p>FlashAttentionMetadata 包含了input的结构和对应的block table的映射。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ggaaooppeenngg.github.io/zh-CN/2024/12/03/FlashAttention-%E8%A7%A3%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ggaaooppeenngg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ggaaooppeenngg">
      <meta itemprop="description" content="为什么计算机科学是无限的但生命是有限的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ggaaooppeenngg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/zh-CN/2024/12/03/FlashAttention-%E8%A7%A3%E6%9E%90/" class="post-title-link" itemprop="url">FlashAttention 解析</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-12-03 16:40:50" itemprop="dateCreated datePublished" datetime="2024-12-03T16:40:50+08:00">2024-12-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-28 18:39:05" itemprop="dateModified" datetime="2025-03-28T18:39:05+08:00">2025-03-28</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/zh-CN/2024/12/03/FlashAttention-%E8%A7%A3%E6%9E%90/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="zh-CN/2024/12/03/FlashAttention-解析/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>FlashAttention是一种新型的注意力算法，它能够准确计算注意力，且只需进行远远少于传统方法的内存访问。这个算法的主要目标是尽可能避免内存的读取和写入，这是注意力机制性能瓶颈的一个关键因素。该论文提出了一个IO-aware的精确注意力算法，它使用tiling（贴瓷砖，代表数据分片）来减少GPU高带宽内存与低带宽内存之间的内存读取/写入次数。</p>
<p>该算法基于注意力矩阵通常稀疏这一观察结果：注意力矩阵只有少数元素非零。它通过将输入矩阵Q、K、V分成更小的块来实现，从而避免了计算全矩阵乘积Q*K^T的内存占用问题。通过块级别的处理，FlashAttention使得矩阵操作可以在现代GPU的内存限制下进行，并仅读取/写入每个切片的非零元素。这降低了需要的内存访问次数，使整个过程更快和更高效。</p>
<p>FlashAttention通过分“瓦片化”的方式计算能够更快的一个原因是将矩阵放入更高速的缓存当中，高速的叫SRAM，低速的叫HBM。</p>
<p>第一代 FlashAttention 只是把QK切片，这个只要把矩阵切分在SRAM，然后计算出结果再存回HBM，这个比较简单。</p>
<p>第二代 FlashAttention 把 softmax 的计算也放在了SRAM上。</p>
<p>源自<a target="_blank" rel="noopener" href="https://jrodthoughts.medium.com/understanding-flashattention-3-one-of-the-most-important-algortihms-to-make-transformers-fast-7d21b0f6e6a4">博客</a>描述的结构中可以看出。</p>
<img data-src="/zh-CN/2024/12/03/FlashAttention-%E8%A7%A3%E6%9E%90/qkv.webp" class="">

<p>他这里面标得感觉不是很清楚，其中的O_2应该是最终的结果O，里面的l_1/l_2 * A^1 / l_1 就还原出了最终结果的分母，也就是scale法则。</p>
<p>第三代 FlashAttention 减少了上面提到的scale，不再每一步做除法，而是放到最后再除。还有就是针对交叉注意力中的mask的优化，跳过了被mask的部分。还有就是CUDA Thread warps的优化提高了并行度。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>FlashAttention通过利用高速缓存和分块技术，显著减少了内存访问次数，提高了注意力计算的效率。第一代主要通过切分QK矩阵并利用SRAM缓存，第二代将softmax计算也放入SRAM，第三代则进一步优化了scale计算和mask处理，并提升了并行度。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ggaaooppeenngg.github.io/zh-CN/2024/12/02/vLLM-%E5%88%86%E6%9E%901-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ggaaooppeenngg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ggaaooppeenngg">
      <meta itemprop="description" content="为什么计算机科学是无限的但生命是有限的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ggaaooppeenngg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/zh-CN/2024/12/02/vLLM-%E5%88%86%E6%9E%901-1/" class="post-title-link" itemprop="url">vLLM 分析 1 提示词的前置处理和流式响应</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-12-02 15:03:50" itemprop="dateCreated datePublished" datetime="2024-12-02T15:03:50+08:00">2024-12-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-28 18:39:05" itemprop="dateModified" datetime="2025-03-28T18:39:05+08:00">2025-03-28</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/zh-CN/2024/12/02/vLLM-%E5%88%86%E6%9E%901-1/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="zh-CN/2024/12/02/vLLM-分析1-1/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>vLLM 基于 uvicorn + FastAPI 的异步 Web 框架构成。vLLM 的主体是 LLMEngine，它是一个单例类，负责管理所有的模型和数据。在异步 API 中使用的是一个 AsyncEngine。在分析 AsyncEngine 之前，我们先将 Web 部分单独拆出来看一下。</p>
<p>vLLM 的 CLI 入口是 <code>vllm/scripts.py</code>，其中 <code>serve</code> 的启动是通过 <code>uvloop.run</code> 的方式启动的。uvloop 是一个替代默认 asyncio 事件循环的库，它使用 libuv 作为事件循环的实现，从而提高性能。uvicorn 是一个基于 uvloop 的 ASGI 服务器，它可以将 ASGI 应用部署到 Web 服务器上。FastAPI 是一个基于 Starlette 的 Web 框架，它提供了许多便利的功能，比如自动文档生成、请求参数校验等。</p>
<p>参数经过解析以后会进入 <code>run_server</code>，通过 <code>uvloop.run(run_server(args))</code>。<code>run_server</code> 在 <code>entrypoints/openai/api_server.py</code> 下面。<code>AsyncEngineArgs.from_cli_args(args)</code> 使用命令行参数初始化 <code>AsyncEngineArgs</code>，如果要自行封装的话可以直接初始化 <code>AsyncEngineArgs</code>。<code>AsyncEngineArgs</code> 继承自 <code>EngineArgs</code>，其中的参数都是用来控制推断命令的。</p>
<p>比较常用的几个参数：</p>
<ul>
<li><p><strong>model</strong>: 模型的路径，可以是一个目录，也可以是 hf 上的一个 repo。</p>
</li>
<li><p><strong>model_name</strong>: 如果是目录的话，期望的模型名称，或者想要改个别名，对应的是 API 中指定模型的名称。</p>
</li>
<li><p><strong>tensor_parallel_size</strong>: tensor parallel 副本数，如果用多个 GPU 可以用到，会根据这个将 kv head 平分到不同的 GPU 上。</p>
</li>
<li><p><strong>pipeline_parallel_size</strong>: pipeline stages 数，如果用多个 GPU 可以用到，会根据这个将模型的前向计算的layers分成多个阶段，每个阶段在不同的 GPU 上计算。</p>
<p>  可以参考下面这个例子：</p>
<p>  假设我们有 8 个 GPU，分别表示为 g0 … g7，并且我们使用 2 个 GPU 来并行化模型张量，使用 4 个 GPU 来并行化模型流水线。当前函数将创建 4 个张量模型并行组和 2 个流水线模型并行组：</p>
<p>  4 个张量模型并行组：</p>
<ul>
<li>[g0, g1]</li>
<li>[g2, g3]</li>
<li>[g4, g5]</li>
<li>[g6, g7]</li>
</ul>
<p>  2 个流水线模型并行组：</p>
<ul>
<li>[g0, g2, g4, g6]</li>
<li>[g1, g3, g5, g7]</li>
</ul>
<p>  注意，为了提高效率，调用者应确保相邻的 rank 位于同一个 DGX 盒子上。例如，如果我们使用 2 个 DGX-1 盒子，总共有 16 个 GPU，rank 0 到 7 属于第一个盒子，rank 8 到 15 属于第二个盒子。</p>
</li>
<li><p><strong>num_seqs</strong>: 最大的序列数，其实就是 batch size，会翻倍得增加显存使用，这个貌似在启动之前的 profile 阶段可能会导致大量显存的占用。</p>
</li>
<li><p><strong>quantization</strong>: 量化的方法，可以是 bitsandbytes 等，可能需要和 <code>load_format</code> 结合使用。</p>
</li>
<li><p><strong>load_format</strong>: 加载模型的格式，可以是 pt, safetensors, bitsandbytes 等等，如果用到量化的模型基本要改成 bitsandbytes。</p>
</li>
<li><p><strong>dtype</strong>: 数据类型，fp32, fp16，bf16 等等，如果模型是 bf16 的话，他默认是 bf16 的模型用 bf16，有些显卡不支持 bf 浮点数所以要设置成 half 也就是 fp16。</p>
</li>
<li><p><strong>host</strong>: 监听地址。</p>
</li>
<li><p><strong>port</strong>: 监听端口。</p>
</li>
<li><p><strong>max_model_len</strong>: 上下文长度，适合显存不足的显卡，把默认的上下文长度改下一点。</p>
</li>
<li><p><strong>enforce_eager</strong>: 是否强制使用 eager 模式，如果显存不够的需要开启这个模式，不完全加载计算图的方式可以减少显存的使用。</p>
</li>
</ul>
<p><code>api_server</code> 中的 <code>build_app</code> 会使用 <code>APIRouter</code> 初始化路由，并通过 <code>app.include_router</code> 引入。</p>
<p>主要看 <code>@router.post(&quot;/v1/chat/completions&quot;)</code> 注册的 <code>async def create_chat_completion</code> 是最常用的函数调用。</p>
<p><code>init_app_state</code> 在 <code>app.state</code> 中保存了 <code>openai_serving_chat</code>，以及其他一些接口的状态，这取决于模型配置中是否包含这些功能。例如，文本嵌入等功能（通常都有）。当调用 <code>create_chat_completion</code> 时，会调用 <code>openai_serving_chat</code> 对应的 <code>OpenAIServingChat</code> 类的方法。因此，Serving 的主体可以通过查看这个对象的方法来理解其功能。</p>
<p>构建 AsyncEngine -&gt; 构建 app 对象。</p>
<h2 id="OpenAIServingChat-create-chat-completion-主体流程"><a href="#OpenAIServingChat-create-chat-completion-主体流程" class="headerlink" title="OpenAIServingChat.create_chat_completion 主体流程"></a><code>OpenAIServingChat.create_chat_completion</code> 主体流程</h2><ol>
<li><p><strong>检查模型</strong>：</p>
<ul>
<li>是否支持 model，model 是否是 rola，model 是否是 prompt adapter 等。<blockquote>
<p>vLLM 的 rola 不是和基座合并在一起的，是支持基座模型加多了个 lora 模型的形式。prompt adapter 看起是多模态架构中的 adaptor。</p>
</blockquote>
</li>
</ul>
</li>
<li><p><strong>从 Engine 中获取 Tokenizer</strong>：</p>
<ul>
<li>主要是基于 model path 获取对应的 tokenizer 文件，并初始化对应的 tokenizer。</li>
</ul>
</li>
<li><p><strong>_preprocess_call</strong>：对输入进行预处理 </p>
<ul>
<li><code>resolve_chat_template_content_format</code>：检查对话模板格式，因为每种大模型的用于生成文本的训练数据的格式有所不同，要确认对应的格式，LLAMA 有 LLAMA 的格式，可以参考下面的例子。</li>
<li><code>parse_chat_messages_futures</code>：解析输入的聊天消息，生成一个对话消息列表，变成有类型的对话消息。其中 <code>mm_tracker</code> 要处理 <code>image_url</code> 和 <code>audio_url</code> 的消息，会根据构造 <code>placeholder</code>，<code>placeholder</code> 是一个特殊的字符串，用来标记这个位置是一个占位符。<code>llama3.2</code> 用的是 <code>&lt;|image|&gt;</code>。</li>
<li><code>apply_&#123;hf,mistral&#125;_chat_template</code>：模板会给提示词添加提示词的开头和结束的标志，从而和实际训练的数据标注对齐，比如 <code>llama3</code> 用 <code>&lt;|eot_id|&gt;</code> 标记结束，<code>padding</code> 等。<code>request_prompt</code> 和 <code>engine_prompt</code> 包含 <code>token ids</code> 和多模态数据。<br>例如：</li>
</ul>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">chat = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>,</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: [</span><br><span class="line">            &#123;<span class="string">&quot;type&quot;</span>: <span class="string">&quot;image&quot;</span>&#125;,</span><br><span class="line">            &#123;<span class="string">&quot;type&quot;</span>: <span class="string">&quot;text&quot;</span>, <span class="string">&quot;text&quot;</span>: <span class="string">&quot;If I had to write a haiku for this one, it would be: &quot;</span>&#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p> 会变成 <code>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\n\n&lt;|image|&gt;If I had to write a haiku for this one, it would be: &lt;|eot_id|&gt;</code> 中，<code>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;</code> 标识 <code>header</code>（也就是 <code>role</code>），<code>&lt;|begin_of_text|&gt;</code> 标识上下文的开头，<code>&lt;|eot_id|&gt;</code> 标识一个消息的结束。除此之外，对于function call的处理，可以参考 <code>examples/tool_chat_template_llama3.2_json.jinja</code> 的一部分可以看出，会把对应工具的调用和提示词加入到用户对话前面，作为 user 的 text 的前缀中的内容形成提示词的一部分上下文。</p>
 <figure class="highlight jinja"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&#123;#- Custom tools are passed in a user message with some extra guidance #&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> tools_in_user_message and not tools is none %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span><span class="comment">&#123;#- Extract the first user message so we can plug it in here #&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> messages | length != 0 %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    </span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> messages[0][&#x27;content&#x27;] is string %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">        </span><span class="template-tag">&#123;%- <span class="name">set</span> first_user_message = messages[0][&#x27;content&#x27;]|trim %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    </span><span class="template-tag">&#123;%- <span class="name"><span class="name">else</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">        </span><span class="template-tag">&#123;%- <span class="name">set</span> first_user_message = messages[0][&#x27;content&#x27;] | selectattr(&#x27;type&#x27;, &#x27;equalto&#x27;, &#x27;text&#x27;) | map(attribute=&#x27;text&#x27;) | map(&#x27;trim&#x27;) | join(&#x27;\n&#x27;) %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    </span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    </span><span class="template-tag">&#123;%- <span class="name">set</span> messages = messages[1:] %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span><span class="template-tag">&#123;%- <span class="name"><span class="name">else</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    </span><span class="template-variable">&#123;&#123;- raise_exception(&quot;Cannot put tools in the first user message when there&#x27;s no first user message!&quot;) &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span><span class="template-variable">&#123;&#123;- &#x27;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\n\n&#x27; -&#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span><span class="template-variable">&#123;&#123;- &quot;Given the following functions, please respond with a JSON for a function call &quot; &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span><span class="template-variable">&#123;&#123;- &quot;with its proper arguments that best answers the given prompt.\n\n&quot; &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span><span class="template-variable">&#123;&#123;- &#x27;Respond in the format &#123;&quot;name&quot;: function name, &quot;parameters&quot;: dictionary of argument name and its value&#125;. &#x27; &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span><span class="template-variable">&#123;&#123;- &quot;Do not use variables.\n\n&quot; &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span><span class="template-tag">&#123;%- <span class="name"><span class="name">for</span></span> t <span class="keyword">in</span> tools %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    </span><span class="template-variable">&#123;&#123;- t | tojson(indent=4) &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    </span><span class="template-variable">&#123;&#123;- &quot;\n\n&quot; &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span><span class="template-tag">&#123;%- <span class="name"><span class="name">endfor</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span><span class="template-variable">&#123;&#123;- first_user_message + &quot;&lt;|eot_id|&gt;&quot;&#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>请求处理：生成请求的 id <code>request_id = f&quot;chatcmpl-&#123;request.request_id&#125;&quot;</code>，确定采样方法 <code>beam_search</code> 还是 <code>sampling</code>，调用 AsyncEngine 的 <code>beam_search</code> 和 <code>generate</code> 方法获得一个 generator。</p>
</li>
<li><p><code>chat_completion_stream_generator</code> 是基于 generator 处理响应，这里主要看 streaming 的部分，同步的请求会直接返回结果。流式响应的格式是多个基于 json 格式的 chunk，类型是 <code>chat.completion.chunk</code>。</p>
</li>
</ul>
 <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;chatcmpl-1eadb733adf64f5b90114307b2d4d718&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;choices&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;delta&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;function_call&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;refusal&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;tool_calls&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span> <span class="attr">&quot;finish_reason&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span> <span class="attr">&quot;logprobs&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span> <span class="attr">&quot;created&quot;</span><span class="punctuation">:</span> <span class="number">1732869116</span><span class="punctuation">,</span> <span class="attr">&quot;model&quot;</span><span class="punctuation">:</span> <span class="string">&quot;llama3.2&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;object&quot;</span><span class="punctuation">:</span> <span class="string">&quot;chat.completion.chunk&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;service_tier&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;system_fingerprint&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;usage&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

 <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;chatcmpl-1eadb733adf64f5b90114307b2d4d718&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;choices&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;delta&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;AI&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;function_call&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;refusal&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;tool_calls&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span> <span class="attr">&quot;finish_reason&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span> <span class="attr">&quot;logprobs&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span> <span class="attr">&quot;created&quot;</span><span class="punctuation">:</span> <span class="number">1732869116</span><span class="punctuation">,</span> <span class="attr">&quot;model&quot;</span><span class="punctuation">:</span> <span class="string">&quot;llama3.2&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;object&quot;</span><span class="punctuation">:</span> <span class="string">&quot;chat.completion.chunk&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;service_tier&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;system_fingerprint&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;usage&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

 <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;chatcmpl-1eadb733adf64f5b90114307b2d4d718&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;choices&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;delta&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot; assistant&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;function_call&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;refusal&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;tool_calls&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span> <span class="attr">&quot;finish_reason&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span> <span class="attr">&quot;logprobs&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span> <span class="attr">&quot;created&quot;</span><span class="punctuation">:</span> <span class="number">1732869116</span><span class="punctuation">,</span> <span class="attr">&quot;model&quot;</span><span class="punctuation">:</span> <span class="string">&quot;llama3.2&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;object&quot;</span><span class="punctuation">:</span> <span class="string">&quot;chat.completion.chunk&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;service_tier&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;system_fingerprint&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;usage&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

 <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;chatcmpl-1eadb733adf64f5b90114307b2d4d718&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;choices&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;delta&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;function_call&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;refusal&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;tool_calls&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span> <span class="attr">&quot;finish_reason&quot;</span><span class="punctuation">:</span> <span class="string">&quot;stop&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span> <span class="attr">&quot;logprobs&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span> <span class="attr">&quot;created&quot;</span><span class="punctuation">:</span> <span class="number">1732869116</span><span class="punctuation">,</span> <span class="attr">&quot;model&quot;</span><span class="punctuation">:</span> <span class="string">&quot;llama3.2&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;object&quot;</span><span class="punctuation">:</span> <span class="string">&quot;chat.completion.chunk&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;service_tier&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;system_fingerprint&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;usage&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p> AsyncEngine Client 的 generate 会返回一个异步生成器，result_generator，通过 <code>async for</code> 遍历这个生成器 result，而 result 又是一个 output 的生成器。<code>num_cached_tokens</code> 表示前缀匹配的 kv cache 命中的 token 数量。<code>request.n</code> 代表要生成的选择的数量，一般是 1，如果大于 1 就会生成多个选择的分支，而 <code>response</code> 中的 index 就会代表不同的分支的序号。result 生成器对应的就是多个分支的结果，而 result 中的 output 就代表一个分支中的 chunk。处理过程中会把 output 转化成 <code>ChatCompletionStreamResponse</code>，输出成 <code>data: $json_dump</code> 的 SSE chunk 的形式。<code>stream_options.include_usage</code> 如果设置了的话会在 DONE 之前返回一个 usage stats 的 chunk。</p>
<ul>
<li><code>tool_parser</code>：解析工具描述。方法和对应的类在 <code>openai/tool_parsers</code> 下面，会根据传入的初始化参数决定对应的解析类。如果对应的 request 有 <code>tool_choice</code> 参数，就会使用到 <code>tool_parser</code>，tool_parser 主要用于处理响应中的 tool call 的文本内容。<code>tool_parser</code> 在 <code>tool_choice</code> 为 auto 的时候要调用对应的 <code>extract_tool_calls_streaming</code> 去解析函数调用的文本内容。例如 <code>pythonic_tool_parser</code> 会解释 <code>[func_name1(params_name1=params_value1, params_name2=params_value2...), func_name2(params)]</code> 这种类似 Python 的文本内容并转化为响应中的 <code>ToolCall</code> 对象。如果是 llama3.1 的 template 的话，参考上面的格式，会把输出 <code>&#123;&quot;name&quot;: function name, &quot;parameters&quot;: dictionary of argument name and its value&#125;</code> 转化为 <code>ToolCall</code> 对象。</li>
</ul>
</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>vLLM 的主体是 LLMEngine，它是一个单例类，负责管理所有的模型和数据。在基于FastAPI的异步Restful API 中使用的是一个 AsyncEngine。在交给Engine处理之前会对一些请求参数进行预处理，比如对话模板的格式化，对话消息的解析，模板中的函数调用等。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ggaaooppeenngg.github.io/zh-CN/2024/11/27/VLM%E7%9A%84%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B%E5%92%8C%E6%8E%A8%E6%96%AD%E4%B8%AD%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ggaaooppeenngg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ggaaooppeenngg">
      <meta itemprop="description" content="为什么计算机科学是无限的但生命是有限的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ggaaooppeenngg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/zh-CN/2024/11/27/VLM%E7%9A%84%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B%E5%92%8C%E6%8E%A8%E6%96%AD%E4%B8%AD%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F/" class="post-title-link" itemprop="url">VLM的计算过程和推断中的处理方式</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-11-27 17:54:04" itemprop="dateCreated datePublished" datetime="2024-11-27T17:54:04+08:00">2024-11-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-28 18:39:05" itemprop="dateModified" datetime="2025-03-28T18:39:05+08:00">2025-03-28</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/zh-CN/2024/11/27/VLM%E7%9A%84%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B%E5%92%8C%E6%8E%A8%E6%96%AD%E4%B8%AD%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="zh-CN/2024/11/27/VLM的计算过程和推断中的处理方式/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><a target="_blank" rel="noopener" href="https://towardsdatascience.com/an-introduction-to-vlms-the-future-of-computer-vision-models-5f5aeaafb282">这篇文章</a>对VLM的架构解释得非常清楚。</p>
<p>一种方法是使用适配器将图片转换为tokens，例如<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2304.08485">LLaVA</a>使用的prompt based适配器。这种方法类似于RAG的形式，将图片理解的内容补充在对话的上文中。这种适配器会占用LLM的上下文长度，因为图片的tokens会被放入LLM的上文中。目前来说性能会好一些。</p>
<p>另一种方法是基于交叉注意力的适配器，这种方法不会占用LLM的上下文长度，但需要大量参数来达到良好的质量。<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.21783">Llama3.2</a>就是这种结构。</p>
<blockquote>
<p>关于Llama3.2本身，它使用了GQA，将kv head分组，多头查询将原本的K和V头分成组并为每个组生成一个共享的Head，这样可以减少kv cache而不太丧失精度（相较于MQA这种只共享一个KV头的方法）。因此，分组多头查询在多头查询注意力和正常多头注意力之间维持了平衡，既考虑了速度，又考虑了输出质量。另一个优化是对一个上下文中的不同文档进行mask处理。由于大模型的上下文现在很长，会将多个文档放入一个上下文中进行训练，但为了避免文档之间的相互影响，需要在文档级别进行mask处理，即当前token不能看到之后的token，也不能看到同一上下文中其他文档的token。其他改动主要是训练规模的调整。</p>
</blockquote>
<p>根据Llama3.2的<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.21783">技术报告</a>，里面的image encoder用的是ViT架构。适配器在语言模型和图像编码器之间引入交叉注意力层（cross-attention layers），以提高模型的效率和准确性。交叉注意力层使用通用查询注意力（GQA）并在核心语言模型每四层之后应用。交叉注意力层增加了大量可训练参数，例如Llama 3 405B中约有100B个参数。</p>
<p>本质上，图片编码器的输出通过适配器后作为交叉注意力层的K，文本作为Q，V也来自图片适配器，从而计算文字和图片之间的注意力关系，然后与LLM的输出进行交叉注意力。在训练Llama3.2的适配器时，同时更新了图像编码器的参数，但刻意不更新语言模型的参数。这意味着在适配器训练过程中，Meta只关注图像编码器和适配器的学习，而不影响语言模型的预训练知识。<br>简而言之，这个适配器在功能上类似于最初的encoder-decoder Transformer中的encoder部分。</p>
<p>在具体的以vLLM推断过程的实现为例，对话的API中会包含<code>&#123;&quot;type&quot;:&quot;image&quot;,&quot;image_url&quot;:&quot;uri_of_the_image&quot;&#125;</code>，在应用对话模板以后会插入占位符，比如llama3.2用的就是<code>&lt;|image|&gt;</code>，原始的训练中的文本内容会变成类似<code>&quot;&lt;|image|&gt;If I had to write a haiku for this one&quot;</code>，以此标记图片的位置信息，实际上需要图片会通过<code>uri_of_the_image</code>被加载到encoder中并携带<code>&lt;|image|&gt;</code>所代表的位置信息编码。</p>
<p>总的来说，VLM的计算过程和推断中的处理方式通过引入适配器和交叉注意力层，实现了图片和文本的高效融合，为多模态任务提供了强大的支持。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ggaaooppeenngg.github.io/zh-CN/2024/11/25/%E7%94%A8Rust%E4%BB%8E%E9%9B%B6%E7%BC%96%E5%86%99LevelDB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ggaaooppeenngg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ggaaooppeenngg">
      <meta itemprop="description" content="为什么计算机科学是无限的但生命是有限的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ggaaooppeenngg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/zh-CN/2024/11/25/%E7%94%A8Rust%E4%BB%8E%E9%9B%B6%E7%BC%96%E5%86%99LevelDB/" class="post-title-link" itemprop="url">用Rust从零编写LevelDB</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-11-25 11:38:57" itemprop="dateCreated datePublished" datetime="2024-11-25T11:38:57+08:00">2024-11-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-28 18:39:05" itemprop="dateModified" datetime="2025-03-28T18:39:05+08:00">2025-03-28</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/zh-CN/2024/11/25/%E7%94%A8Rust%E4%BB%8E%E9%9B%B6%E7%BC%96%E5%86%99LevelDB/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="zh-CN/2024/11/25/用Rust从零编写LevelDB/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在现代数据驱动的世界中，对高效且可扩展的数据存储方案的需求前所未有地强烈。键值数据库因其简洁性和卓越性能而备受推崇。对于那些热爱Rust编程并希望构建自己的键值数据库的开发者来说，这本书将是您的理想起点。笔者将引导您一步一步，从零开始，使用Rust设计和实现一个键值数据库。</p>
<p>数据库领域既神秘又充满魅力。正如俗话所说，不亲手实践，就无法深刻理解。通过构建一个键值数据库，我们不仅能深入掌握这类数据库的设计哲学和实现细节，还能借此机会深化对Rust语言的理解和应用。</p>
<p>本书内容围绕一个基于LSM（Log-Structured Merge-tree）的键值数据库设计和实现展开，参考了LevelDB、RocksDB、PebbleDB、AgateDB和BadgerDB等多个成熟数据库的实现。全书示例代码均使用Rust编写，旨在通过实战演练加深读者对Rust特性的理解，同时探索数据库技术的精髓。</p>
<p>LevelDB相较于其他衍生品，虽然没有一些新的论文和工程实践带来的优化，但保留了最初的设计，其相对简单和完整。其他数据库或多或少都能找到LevelDB的影子。</p>
<p>与《Rust编程语言》一书不同，本书不旨在覆盖Rust语言的所有知识点。我们的目标是实现一个键值数据库，因此读者需要具备一定的系统编程基础，例如文件系统相关的读写调用和指针的使用（不仅在unsafe的情况下，有指针的基础也方便理解引用等概念）。这些知识点如果完全讲解清楚会占据很大的篇幅。本书将解释使用到的Rust语法和特性。即使您没有阅读过《Rust编程语言》，也能跟随本书学习Rust的语法。如果您在阅读本书的Rust语法部分遇到困难，可以参考《Rust编程语言》中的相关章节。笔者也是将《Rust编程语言》作为一本参考书反复阅读，并不需要一次性完全读完，书都是常看常新的。</p>
<p>Rust的设计初衷是确保内存安全，避免常见的程序错误，如空指针解引用。其显著特点包括独特的所有权系统、零成本抽象、可靠的错误处理机制以及完善的工具链，使其在系统编程领域尤为突出。</p>
<p>尽管LevelDB是用C++编写的，Rust在某些方面被视为C++的现代替代品。对于那些对C++有深入了解的开发者而言，转向学习Rust应该会相对轻松。然而，Rust提供了与C++不同的编程范式。例如，迭代器和闭包是Rust标准库和语法的一部分，作为语言的核心部分，引入了多种语法糖来支持这些功能，这可能会让熟悉Python的开发者感到亲切。</p>
<p>经典的内存错误包括使用已释放内存的指针、向量长度被修改但另一个引用仍保留原长度信息导致访问不确定内存地址等。Rust的所有权系统在编译阶段就能避免这些问题。</p>
<p>Rust借鉴了函数式编程的多种技巧，为开发者提供了一种既熟悉又新颖的编程体验，例如模式匹配、迭代器、闭包、泛型等。这些特性使得Rust在编写高效、安全和易维护的代码方面具有独特优势。</p>
<p>与有GC的语言相比，Rust可能让使用者感到不适应，许多在其他语言中理所当然的写法在Rust中行不通。Rust对指针的可变性有明确限制，并且只允许存在一个可变引用。这种所有权的检查使编译器变得非常严格，在一定程度上增加了编程的复杂性。然而，这也是Rust的优势之一，它能够在编译阶段发现许多潜在的错误。</p>
<p>相比暴露指针的语言，Rust对内存的解引用有严格的检查。尽管所有权系统有时会让代码显得冗长，但Rust提供了许多有趣的语法和特性，如模式匹配、错误处理宏、默认返回末端表达式等，使得编写Rust代码既轻便又高效。</p>
<p>Rust的性能非常出色，部分Linux内核驱动和Windows安全模块已经采用Rust实现。AWS也在许多地方使用Rust，飞书客户端的一部分代码也使用了Rust，这在一定程度上证明了Rust在系统编程领域的优异表现。如果需要选择一种新语言开发消息队列、数据库、文件系统等软件，Rust是一个非常不错的选择。这也是本书使用Rust实现的原因之一，以展示Rust在这些方面的优势。</p>
<p>在错误处理方面，Rust采用<code>?</code>问号宏简化了传统的错误处理流程，相比Go语言中显式处理错误的<code>if err != nil &#123;&#125;</code>模式是一种进步。这种简洁的错误处理方式不仅提高了代码的可读性，也加速了开发过程。</p>
<p>这些特色贯穿本书始终，在随后的章节中，您将探索到Rust的更多有趣特性。</p>
<p>笔者是一名Rust初学者，里面的很多实现可能存在不正确的写法，欢迎指正。</p>
<h3 id="本书面向的读者"><a href="#本书面向的读者" class="headerlink" title="本书面向的读者"></a>本书面向的读者</h3><ul>
<li>希望通过具体项目深入学习Rust，特别是在键值数据库方面的开发者。</li>
<li>对键值数据库的设计和实现感兴趣的初学者，希望通过实践学习相关内容。</li>
<li>想了解LevelDB架构和实现细节的读者，可以选择性地跳过实现部分进行阅读。</li>
</ul>
<h3 id="如何阅读和使用代码"><a href="#如何阅读和使用代码" class="headerlink" title="如何阅读和使用代码"></a>如何阅读和使用代码</h3><p>本书的第一章主要是讲基础概念例如一些基础的数据结构。第二章开始分部分讲解实现的细节。对于<br>对Rust比较熟悉的读者可以跳过第一章。</p>
<h2 id="第一章Rust"><a href="#第一章Rust" class="headerlink" title="第一章Rust"></a>第一章Rust</h2><p>完整讲解Rust的内容将要消耗大量篇幅，也不是本书的目的。本章节主要介绍在实现过程中会会涉及的一些的语法和特性，让读者在阅读代码的时候没有过多障碍。</p>
<h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h3><p>Rust 是一种静态类型的编程语言，其数据类型可以分为两大类：原始类型（Primitive Types）和复合类型（Compound Types）。以下是 Rust 中常见的数据类型：</p>
<h4 id="原始类型（Primitive-Types）"><a href="#原始类型（Primitive-Types）" class="headerlink" title="原始类型（Primitive Types）"></a>原始类型（Primitive Types）</h4><ul>
<li><p><strong>整数类型（Integer Types）</strong>：表示整数。有符号整数包括 <code>i8</code>、<code>i16</code>、<code>i32</code>、<code>i64</code>、<code>i128</code>，无符号整数包括 <code>u8</code>、<code>u16</code>、<code>u32</code>、<code>u64</code>、<code>u128</code>。</p>
  <figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">signed_integer</span>: <span class="type">i32</span> = -<span class="number">42</span>;</span><br><span class="line"><span class="keyword">let</span> <span class="variable">unsigned_integer</span>: <span class="type">u64</span> = <span class="number">42</span>;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>浮点数类型（Floating-Point Types）</strong>：表示小数。Rust 有两个浮点数类型：<code>f32</code> 和 <code>f64</code>。</p>
  <figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">float32</span>: <span class="type">f32</span> = <span class="number">3.14</span>;</span><br><span class="line"><span class="keyword">let</span> <span class="variable">float64</span>: <span class="type">f64</span> = <span class="number">3.14</span>;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>布尔类型（Boolean Type）</strong>：表示逻辑值，只有两个可能的值：<code>true</code> 和 <code>false</code>。</p>
  <figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">is_true</span>: <span class="type">bool</span> = <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">let</span> <span class="variable">is_false</span>: <span class="type">bool</span> = <span class="literal">false</span>;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>字符类型（Character Type）</strong>：表示单个字符。字符类型使用单引号 <code>&#39;</code>。</p>
  <figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">char_a</span>: <span class="type">char</span> = <span class="string">&#x27;a&#x27;</span>;</span><br><span class="line"><span class="keyword">let</span> <span class="variable">char_heart</span>: <span class="type">char</span> = <span class="string">&#x27;❤&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="复合类型（Compound-Types）"><a href="#复合类型（Compound-Types）" class="headerlink" title="复合类型（Compound Types）"></a>复合类型（Compound Types）</h4><ul>
<li><p><strong>数组类型（Array Type）</strong>：表示固定大小的数组。数组中的所有元素必须拥有相同的数据类型。</p>
  <figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">array</span>: [<span class="type">i32</span>; <span class="number">5</span>] = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>];</span><br></pre></td></tr></table></figure></li>
<li><p><strong>元组类型（Tuple Type）</strong>：表示具有不同数据类型的有序集合。元组的长度是固定的。</p>
  <figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">tuple</span>: (<span class="type">i32</span>, <span class="type">f64</span>, <span class="type">char</span>) = (<span class="number">42</span>, <span class="number">3.14</span>, <span class="string">&#x27;a&#x27;</span>);</span><br></pre></td></tr></table></figure></li>
<li><p><strong>切片类型（Slice Type）</strong>：表示对数组或其他集合的引用，但没有固定大小。切片是一种动态大小的视图。</p>
  <figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">array</span>: [<span class="type">i32</span>; <span class="number">5</span>] = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>];</span><br><span class="line"><span class="keyword">let</span> <span class="variable">slice</span>: &amp;[<span class="type">i32</span>] = &amp;array[<span class="number">1</span>..<span class="number">4</span>];</span><br></pre></td></tr></table></figure></li>
<li><p><strong>字符串类型（String Type）</strong>：表示动态可变的文本字符串。它由 <code>String</code> 类型表示。</p>
  <figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">my_string</span>: <span class="type">String</span> = <span class="type">String</span>::<span class="title function_ invoke__">from</span>(<span class="string">&quot;Hello, Rust!&quot;</span>);</span><br></pre></td></tr></table></figure></li>
<li><p><strong>引用类型（Reference Type）</strong>：表示对值的引用。引用在 Rust 中被广泛用于实现借用和所有权系统。</p>
  <figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">original_value</span>: <span class="type">i32</span> = <span class="number">42</span>;</span><br><span class="line"><span class="keyword">let</span> <span class="variable">reference</span>: &amp;<span class="type">i32</span> = &amp;original_value;</span><br></pre></td></tr></table></figure></li>
</ul>
<p>这些数据类型提供了灵活性和安全性，通过所有权、借用和生命周期等概念，Rust 的类型系统确保了内存安全和线程安全。在编写 Rust 代码时，正确使用这些数据类型有助于减少运行时错误并提高代码的可维护性。</p>
<h3 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h3><p><code>let</code>用于声明变量。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">x</span> = <span class="number">1</span>; <span class="comment">// 声明x并赋值为1。</span></span><br></pre></td></tr></table></figure>

<p>可以使用<code>:</code>显式指定变量类型：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">x</span>: <span class="type">i32</span> = <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<p><code>_</code>表示“存在但不关心”的变量，用于有意忽略某些处理：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 赋值给一个不需要使用的变量</span></span><br><span class="line"><span class="keyword">let</span> <span class="variable">_</span> = <span class="number">1</span>;</span><br><span class="line"><span class="comment">// 忽略函数的返回值</span></span><br><span class="line"><span class="keyword">let</span> <span class="variable">_</span> = <span class="title function_ invoke__">get_thing</span>();</span><br></pre></td></tr></table></figure>

<p>以<code>_</code>开头的变量表示暂时忽略以避免编译检查，适合在开发过程中使用：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">_x</span> = <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<p><code>let</code>可以“覆盖”变量，使之前相同名称的变量失效，且变量类型可以不同：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">x</span> = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">let</span> <span class="variable">x</span> = <span class="number">1</span> + <span class="number">2</span>;</span><br><span class="line"><span class="keyword">let</span> <span class="variable">x</span> = <span class="string">&quot;str&quot;</span>;</span><br></pre></td></tr></table></figure>

<p>Rust也有元组，相当于固定长度的“容器”可以容纳不同的类型，元组可以指定类型。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">pair</span> : (<span class="type">char</span>, <span class="type">i32</span>) = (<span class="string">&#x27;a&#x27;</span>, <span class="number">17</span>);</span><br><span class="line">pair.<span class="number">0</span>;</span><br><span class="line">pair.<span class="number">1</span>;</span><br></pre></td></tr></table></figure>
<p>元组适用于解构，下面的代码中<code>some_char</code>是<code>&#39;a&#39;</code>，<code>some_int</code>是17。结构也可以使用<code>_</code>忽略全部或者其中一部分。解构也适用于函数的返回值。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> (some_char, some_int) = (<span class="string">&#x27;a&#x27;</span>, <span class="number">17</span>);</span><br><span class="line"><span class="keyword">let</span> (_, some_int) = (<span class="string">&#x27;a&#x27;</span>, <span class="number">17</span>);</span><br><span class="line"><span class="keyword">let</span> (_, _) = (<span class="string">&#x27;a&#x27;</span>, <span class="number">17</span>);</span><br><span class="line"><span class="keyword">let</span> (left, right) = slice.<span class="title function_ invoke__">split_at</span>(middle);</span><br></pre></td></tr></table></figure>
<p><code>&#123;&#125;</code>可以划分作用域，如果使用之前的覆盖规则，可以在内部作用域覆盖外部作用域的变量。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">x</span> = <span class="string">&quot;out&quot;</span>;</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// x = &quot;in&quot; 覆盖了外面的&quot;out&quot;</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">x</span> = <span class="string">&quot;in&quot;</span>;</span><br><span class="line">        <span class="comment">// 这里会打印&quot;in&quot;</span></span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;&quot;</span>, x);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 这里会打印&quot;out&quot;</span></span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;&quot;</span>, x);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在Rust中，语块也是表达式。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">x</span> = <span class="number">42</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> <span class="variable">x</span> = &#123; <span class="number">42</span> &#125;;</span><br></pre></td></tr></table></figure>
<p>语块可以包含多个语句，最后一个不以分号结尾的语句是这个语块的值，否则默认等于<code>()</code>。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">x</span> = &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">y</span> = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">z</span> = <span class="number">2</span>;</span><br><span class="line">    y + z </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>函数中也有类似的写法。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">fair_dice_roll</span>() <span class="punctuation">-&gt;</span> <span class="type">i32</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">4</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">fair_dice_roll</span>() <span class="punctuation">-&gt;</span> <span class="type">i32</span> &#123;</span><br><span class="line">    <span class="number">4</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>if语句也是表达式。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">fair_dice_roll</span>() <span class="punctuation">-&gt;</span> <span class="type">i32</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> feeling_lucky &#123;</span><br><span class="line">        <span class="number">6</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="number">4</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>match语句也是表达式。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">fair_dice_roll</span>() <span class="punctuation">-&gt;</span> <span class="type">i32</span> &#123;</span><br><span class="line">    <span class="keyword">match</span> feeling_lucky &#123;</span><br><span class="line">        <span class="literal">true</span> =&gt; <span class="number">6</span>,</span><br><span class="line">        <span class="literal">false</span> =&gt; <span class="number">4</span>,</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>结构体是用 struct 关键字声明的：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Vec2</span> &#123;</span><br><span class="line">    x: <span class="type">f64</span>, <span class="comment">// 64位浮点数，即 &quot;double precision&quot;</span></span><br><span class="line">    y: <span class="type">f64</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>它们可以使用结构体字面量初始化，顺序不重要，只有名称重要。：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">v1</span> = Vec2 &#123; x: <span class="number">1.0</span>, y: <span class="number">3.0</span> &#125;;</span><br><span class="line"><span class="keyword">let</span> <span class="variable">v2</span> = Vec2 &#123; y: <span class="number">2.0</span>, x: <span class="number">4.0</span> &#125;;</span><br></pre></td></tr></table></figure>

<p>还有一种用于从另一个结构体初始化剩余字段的快捷方式，这称为“结构体更新语法”，只能出现在最后位置，并且不能以逗号结束：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">v3</span> = Vec2 &#123;</span><br><span class="line">    x: <span class="number">14.0</span>,</span><br><span class="line">    ..v2</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>剩余字段也可以是所有字段，这样就可以复制整个结构体，而不是改变所有权：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">v4</span> = Vec2 &#123; ..v3 &#125;;</span><br></pre></td></tr></table></figure>

<p>结构体，像元组一样，可以被解构：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">v</span> = Vec2 &#123; x: <span class="number">3.0</span>, y: <span class="number">6.0</span> &#125;;</span><br><span class="line"><span class="keyword">let</span> <span class="variable">Vec2</span> &#123; x, y &#125; = v;</span><br><span class="line"><span class="comment">// `x` 现在是 3.0，`y` 现在是 6.0</span></span><br></pre></td></tr></table></figure>

<p>下面这种形式可以通过<code>..</code>让<code>v.y</code>会被忽略掉：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">Vec2</span> &#123; x, .. &#125; = v;</span><br></pre></td></tr></table></figure>

<p><code>let</code>模式可以用作<code>if</code>中的条件：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Number</span> &#123;</span><br><span class="line">    odd: <span class="type">bool</span>,</span><br><span class="line">    value: <span class="type">i32</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">one</span> = Number &#123; odd: <span class="literal">true</span>, value: <span class="number">1</span> &#125;;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">two</span> = Number &#123; odd: <span class="literal">false</span>, value: <span class="number">2</span> &#125;;</span><br><span class="line">    <span class="title function_ invoke__">print_number</span>(one);</span><br><span class="line">    <span class="title function_ invoke__">print_number</span>(two);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">print_number</span>(n: Number) &#123;</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Number</span> &#123; odd: <span class="literal">true</span>, value &#125; = n &#123;</span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;Odd number: &#123;&#125;&quot;</span>, value);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Number</span> &#123; odd: <span class="literal">false</span>, value &#125; = n &#123;</span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;Even number: &#123;&#125;&quot;</span>, value);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>match</code> 也是一种模式匹配，就像 <code>if let</code> 一样：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">print_number</span>(n: Number) &#123;</span><br><span class="line">    <span class="keyword">match</span> n &#123;</span><br><span class="line">        Number &#123; odd: <span class="literal">true</span>, value &#125; =&gt; <span class="built_in">println!</span>(<span class="string">&quot;Odd number: &#123;&#125;&quot;</span>, value),</span><br><span class="line">        Number &#123; odd: <span class="literal">false</span>, value &#125; =&gt; <span class="built_in">println!</span>(<span class="string">&quot;Even number: &#123;&#125;&quot;</span>, value),</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>match</code> 必须是穷尽的：至少有一个分支需要匹配。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">print_number</span>(n: Number) &#123;</span><br><span class="line">    <span class="keyword">match</span> n &#123;</span><br><span class="line">        Number &#123; value: <span class="number">1</span>, .. &#125; =&gt; <span class="built_in">println!</span>(<span class="string">&quot;One&quot;</span>),</span><br><span class="line">        Number &#123; value: <span class="number">2</span>, .. &#125; =&gt; <span class="built_in">println!</span>(<span class="string">&quot;Two&quot;</span>),</span><br><span class="line">        Number &#123; value, .. &#125; =&gt; <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;&quot;</span>, value),</span><br><span class="line">        <span class="comment">// 如果最后一个分支不存在，我们会得到一个编译时错误</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果穷尽匹配很难满足，可以使用 <code>_</code> 作为 “通配符” 模式：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">print_number</span>(n: Number) &#123;</span><br><span class="line">    <span class="keyword">match</span> n.value &#123;</span><br><span class="line">        <span class="number">1</span> =&gt; <span class="built_in">println!</span>(<span class="string">&quot;One&quot;</span>),</span><br><span class="line">        <span class="number">2</span> =&gt; <span class="built_in">println!</span>(<span class="string">&quot;Two&quot;</span>),</span><br><span class="line">        _ =&gt; <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;&quot;</span>, n.value),</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以给类型声明方法。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Number</span> &#123;</span><br><span class="line">    odd: <span class="type">bool</span>,</span><br><span class="line">    value: <span class="type">i32</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">Number</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">is_strictly_positive</span>(<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">bool</span> &#123;</span><br><span class="line">        <span class="keyword">self</span>.value &gt; <span class="number">0</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>变量默认不可以改变。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">n</span> = Number &#123;</span><br><span class="line">        odd: <span class="literal">true</span>,</span><br><span class="line">        value: <span class="number">17</span>,</span><br><span class="line">    &#125;;</span><br><span class="line">    n.odd = <span class="literal">false</span>; <span class="comment">// 错误：不能对 `n.odd` 赋值，</span></span><br><span class="line">                   <span class="comment">// 因为 `n` 没有被声明为可变的</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>不能被重新赋值</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">n</span> = Number &#123;</span><br><span class="line">        odd: <span class="literal">true</span>,</span><br><span class="line">        value: <span class="number">17</span>,</span><br><span class="line">    &#125;;</span><br><span class="line">    n = Number &#123;</span><br><span class="line">        odd: <span class="literal">false</span>,</span><br><span class="line">        value: <span class="number">22</span>,</span><br><span class="line">    &#125;; <span class="comment">// 错误：不能对不可变变量 `n` 重新赋值</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以使用<code>mut</code>关键字来声明可变变量。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">n</span> = Number &#123;</span><br><span class="line">        odd: <span class="literal">true</span>,</span><br><span class="line">        value: <span class="number">17</span>,</span><br><span class="line">    &#125;;</span><br><span class="line">    n.odd = <span class="literal">false</span>; <span class="comment">// 没问题：`n` 是可变的</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>特征（Traits）在Rust中实现了类似其他语言中的多态功能：</p>
<p>特征定义了一组可以由多种类型共享的行为契约。其定义如下：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">trait</span> <span class="title class_">Signed</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">is_strictly_negative</span>(<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">bool</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>任何满足这些条件的类型都可以实现这个特征：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">impl</span> <span class="title class_">Signed</span> <span class="keyword">for</span> <span class="title class_">Number</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">is_strictly_negative</span>(<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">bool</span> &#123;</span><br><span class="line">        <span class="keyword">self</span>.value &lt; <span class="number">0</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这样，<code>Number</code> 类型就拥有了 <code>is_strictly_negative</code> 方法。特征也可以包含默认实现：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">trait</span> <span class="title class_">Signed</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">is_strictly_negative</span>(<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">bool</span> &#123;</span><br><span class="line">        <span class="keyword">self</span>.<span class="title function_ invoke__">value</span>() &lt; <span class="number">0</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">value</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">i32</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后，类型只需要提供那些没有默认实现的方法：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">impl</span> <span class="title class_">Signed</span> <span class="keyword">for</span> <span class="title class_">Number</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">value</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">i32</span> &#123;</span><br><span class="line">        <span class="keyword">self</span>.value</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Rust 的一个核心特征是 <code>Drop</code>，它允许你定义当值离开作用域时应该发生的事情：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">impl</span> <span class="title class_">Drop</span> <span class="keyword">for</span> <span class="title class_">Number</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">drop</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;Dropping &#123;&#125;&quot;</span>, <span class="keyword">self</span>.value);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当 <code>Number</code> 实例离开作用域时，Rust 会自动调用 <code>drop</code> 方法。</p>
<p>枚举（Enums）允许你定义一个类型，该类型可以是多个不同变体中的一个。这对于值可以有多种但数量有限的类型特别有用：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">WebEvent</span> &#123;</span><br><span class="line">    PageLoad,</span><br><span class="line">    PageUnload,</span><br><span class="line">    <span class="title function_ invoke__">KeyPress</span>(<span class="type">char</span>),</span><br><span class="line">    <span class="title function_ invoke__">Paste</span>(<span class="type">String</span>),</span><br><span class="line">    Click &#123; x: <span class="type">i64</span>, y: <span class="type">i64</span> &#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>与结构体一样，枚举的每个变体可以包含不同类型和数量的数据。你可以使用 <code>match</code> 表达式来操作枚举值：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">inspect</span>(event: WebEvent) &#123;</span><br><span class="line">    <span class="keyword">match</span> event &#123;</span><br><span class="line">        WebEvent::PageLoad =&gt; <span class="built_in">println!</span>(<span class="string">&quot;page loaded&quot;</span>),</span><br><span class="line">        WebEvent::PageUnload =&gt; <span class="built_in">println!</span>(<span class="string">&quot;page unloaded&quot;</span>),</span><br><span class="line">        WebEvent::<span class="title function_ invoke__">KeyPress</span>(c) =&gt; <span class="built_in">println!</span>(<span class="string">&quot;pressed &#x27;&#123;&#125;&#x27;&quot;</span>, c),</span><br><span class="line">        WebEvent::<span class="title function_ invoke__">Paste</span>(s) =&gt; <span class="built_in">println!</span>(<span class="string">&quot;pasted \&quot;&#123;&#125;\&quot;&quot;</span>, s),</span><br><span class="line">        WebEvent::Click &#123; x, y &#125; =&gt; <span class="built_in">println!</span>(<span class="string">&quot;clicked at x=&#123;&#125;, y=&#123;&#125;&quot;</span>, x, y),</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>枚举也可以有方法：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">impl</span> <span class="title class_">WebEvent</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">describe</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">String</span> &#123;</span><br><span class="line">        <span class="keyword">match</span> <span class="keyword">self</span> &#123;</span><br><span class="line">            WebEvent::PageLoad =&gt; <span class="type">String</span>::<span class="title function_ invoke__">from</span>(<span class="string">&quot;page loaded&quot;</span>),</span><br><span class="line">            WebEvent::PageUnload =&gt; <span class="type">String</span>::<span class="title function_ invoke__">from</span>(<span class="string">&quot;page unloaded&quot;</span>),</span><br><span class="line">            WebEvent::<span class="title function_ invoke__">KeyPress</span>(c) =&gt; <span class="built_in">format!</span>(<span class="string">&quot;pressed &#x27;&#123;&#125;&#x27;&quot;</span>, c),</span><br><span class="line">            WebEvent::<span class="title function_ invoke__">Paste</span>(s) =&gt; <span class="built_in">format!</span>(<span class="string">&quot;pasted \&quot;&#123;&#125;\&quot;&quot;</span>, s),</span><br><span class="line">            WebEvent::Click &#123; x, y &#125; =&gt; <span class="built_in">format!</span>(<span class="string">&quot;clicked at x=&#123;&#125;, y=&#123;&#125;&quot;</span>, x, y),</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>没有返回值的空函数：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">greet</span>() &#123;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;Hi there!&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>右箭头表示返回值类型：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">foo</span>() <span class="punctuation">-&gt;</span> <span class="type">i32</span> &#123;</span><br><span class="line">    <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="模块管理"><a href="#模块管理" class="headerlink" title="模块管理"></a>模块管理</h3><p>在Rust中，模块是用于组织代码、控制可见性以及支持代码重用的重要概念。Rust的模块系统是基于文件和目录组织的，这使得代码的组织变得清晰而灵活。下面是Rust模块管理的一些关键概念：</p>
<h4 id="模块定义"><a href="#模块定义" class="headerlink" title="模块定义"></a>模块定义</h4><p>模块通过<code>mod</code>关键字进行定义，可以在一个Rust文件中定义一个模块。例如：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在文件 mod_example.rs 中定义了一个模块</span></span><br><span class="line"><span class="keyword">mod</span> example &#123;</span><br><span class="line">    <span class="comment">// 模块的内容</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="模块路径"><a href="#模块路径" class="headerlink" title="模块路径"></a>模块路径</h4><p>模块路径用于指定模块的位置。Rust使用<code>::</code>来表示模块路径。例如：<code>mod_example::example</code>。</p>
<p>Rust的模块系统与文件系统有很强的映射关系。一个模块可以对应于一个文件，也可以对应于一个目录，包含多个文件。这使得项目的文件和目录结构能够与代码组织一致。</p>
<h4 id="pub关键字"><a href="#pub关键字" class="headerlink" title="pub关键字"></a><code>pub</code>关键字</h4><p>在Rust中，使用<code>pub</code>关键字来标识模块、结构体、枚举、函数等的可见性。只有被标记为<code>pub</code>的项才可以在其他模块中被访问。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在 example 模块中声明了一个公共的结构体</span></span><br><span class="line"><span class="keyword">mod</span> example &#123;</span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">MyStruct</span> &#123;</span><br><span class="line">        <span class="comment">// 结构体的字段</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 在其他模块中使用 example 模块中的 MyStruct</span></span><br><span class="line"><span class="keyword">use</span> example::MyStruct;</span><br></pre></td></tr></table></figure>

<h4 id="mod-rs文件"><a href="#mod-rs文件" class="headerlink" title="mod.rs文件"></a><code>mod.rs</code>文件</h4><p>文件本身是可以被作为模块引用的，这样可以更好地组织代码。<br>如果一个模块的内容比较复杂，可以在模块所在的目录中创建一个<code>mod.rs</code>文件，作为模块的“命名空间”，用于存放模块的具体实现。例如：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在 example 目录中创建 mod.rs 文件</span></span><br><span class="line"><span class="comment">// example/mod.rs</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">mod</span> sub_module;</span><br></pre></td></tr></table></figure>
<p>使用方式：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在其他模块中引用 example 模块</span></span><br><span class="line"><span class="keyword">use</span> example::sub_module;</span><br></pre></td></tr></table></figure>
<p>这个目录用于存放模块的具体实现。这有助于清晰地分离模块的定义和实现。</p>
<h4 id="crate-和-super"><a href="#crate-和-super" class="headerlink" title="crate 和 super"></a><code>crate</code> 和 <code>super</code></h4><p><code>crate</code>关键字用于表示当前crate的根模块，而<code>super</code>关键字用于表示当前模块的父模块。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在 crate 根模块中</span></span><br><span class="line"><span class="keyword">mod</span> my_module &#123;</span><br><span class="line">    <span class="comment">// 在 my_module 中</span></span><br><span class="line">    <span class="keyword">mod</span> sub_module &#123;</span><br><span class="line">        <span class="comment">// 在 sub_module 中，使用 super 表示 my_module</span></span><br><span class="line">        <span class="keyword">use</span> super::super::my_function; <span class="comment">// 调用父模块的函数</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">my_function</span>() &#123;</span><br><span class="line">    <span class="comment">// 函数实现</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="模块的可见性规则"><a href="#模块的可见性规则" class="headerlink" title="模块的可见性规则"></a>模块的可见性规则</h4><p>默认情况下，模块和其中的项对外部是不可见的。可以通过<code>pub</code>关键字调整可见性。Rust的模块系统强调了显式性，即除非明确指定为<code>pub</code>，否则默认情况下所有项都是私有的。</p>
<p><code>pub</code> 有多种用法，包括：</p>
<ul>
<li><code>pub</code>：在默认情况下，Rust 中的项是私有的，只能在定义它们的模块中访问。使用 <code>pub</code> 关键字可以将项声明为公共的，使其在整个 crate 中都可见。</li>
</ul>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">MyStruct</span> &#123;</span><br><span class="line">    <span class="keyword">pub</span> field: <span class="type">i32</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">my_function</span>() &#123;</span><br><span class="line">    <span class="comment">// 函数实现</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在这个例子中，<code>MyStruct</code> 和 <code>my_function</code> 都被声明为公共的，可以在 crate 的任何地方访问。</p>
<ul>
<li><code>pub(crate)</code>：限制了项的可见性仅在当前 crate 中。这使得项在 crate 外部是不可见的，但在同一个 crate 内的所有模块都可以访问。</li>
</ul>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">struct</span> <span class="title class_">InternalStruct</span> &#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">fn</span> <span class="title function_">internal_function</span>() &#123;</span><br><span class="line">    <span class="comment">// 函数实现</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在这个例子中，<code>InternalStruct</code> 和 <code>internal_function</code> 只能在定义它们的 crate 中的任何模块中访问。</p>
<ul>
<li><code>pub(super)</code>：限制了项的可见性仅在其父模块（即包含该项的模块）和其父模块的子模块中。</li>
</ul>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">mod</span> parent_module &#123;</span><br><span class="line">    <span class="title function_ invoke__">pub</span>(<span class="keyword">super</span>) <span class="keyword">struct</span> <span class="title class_">SuperStruct</span> &#123;</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">super_function</span>() &#123;</span><br><span class="line">        <span class="comment">// 函数实现</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">mod</span> child_module &#123;</span><br><span class="line">        <span class="keyword">fn</span> <span class="title function_">inner_function</span>() &#123;</span><br><span class="line">            <span class="comment">// 在子模块中可以访问 SuperStruct 和 super_function</span></span><br><span class="line">            <span class="keyword">let</span> <span class="variable">my_struct</span> = SuperStruct &#123; <span class="comment">/* ... */</span> &#125;;</span><br><span class="line">            <span class="title function_ invoke__">super_function</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在这个例子中，<code>SuperStruct</code> 和 <code>super_function</code> 在 <code>parent_module</code> 中可见，但在 crate 中的其他模块不可见。</p>
<ul>
<li><code>pub(self)</code>：限制了项的可见性仅在当前模块中。这使得项对于同一模块中的其他模块是不可见的。</li>
</ul>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">mod</span> my_module &#123;</span><br><span class="line">    <span class="title function_ invoke__">pub</span>(<span class="keyword">self</span>) <span class="keyword">struct</span> <span class="title class_">ModuleStruct</span> &#123;</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="title function_ invoke__">pub</span>(<span class="keyword">self</span>) <span class="keyword">fn</span> <span class="title function_">module_function</span>() &#123;</span><br><span class="line">        <span class="comment">// 函数实现</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">mod</span> submodule &#123;</span><br><span class="line">        <span class="keyword">fn</span> <span class="title function_">inner_function</span>() &#123;</span><br><span class="line">            <span class="comment">// 在子模块中不能访问 ModuleStruct 和 module_function</span></span><br><span class="line">            <span class="comment">// 这两个项对于同一模块中的其他模块是不可见的</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在这个例子中，<code>ModuleStruct</code> 和 <code>module_function</code> 只能在 <code>my_module</code> 中的任何模块中访问。</p>
<p>这些可见性修饰符允许 Rust 程序员精确地控制项的可见性，从而确保代码结构的封装和安全性。</p>
<h4 id="use指令"><a href="#use指令" class="headerlink" title="use指令"></a><code>use</code>指令</h4><p><code>use</code> 指令可用于将其他命名空间的名称 “引入作用域”：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> std::cmp::min;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> <span class="variable">least</span> = <span class="title function_ invoke__">min</span>(<span class="number">7</span>, <span class="number">1</span>); <span class="comment">// 1</span></span><br></pre></td></tr></table></figure>

<p>也可以用紧凑的写法：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 格子单独引入</span></span><br><span class="line"><span class="keyword">use</span> std::cmp::min;</span><br><span class="line"><span class="keyword">use</span> std::cmp::max;</span><br><span class="line"><span class="comment">// 从cmp分开</span></span><br><span class="line"><span class="keyword">use</span> std::cmp::&#123;min, max&#125;;</span><br><span class="line"><span class="comment">// 从std分开也可以</span></span><br><span class="line"><span class="keyword">use</span> std::&#123;cmp::min, cmp::max&#125;;</span><br></pre></td></tr></table></figure>

<p><code>*</code>可以通配引入：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> std::cmp::*;</span><br></pre></td></tr></table></figure>

<p>Rust的模块系统是一个强大的组织和抽象工具，支持创建清晰、可维护、可重用的代码结构。了解和熟练使用模块系统有助于提高代码的可读性和可维护性。</p>
<h3 id="错误类型和可选项"><a href="#错误类型和可选项" class="headerlink" title="错误类型和可选项"></a>错误类型和可选项</h3><p><code>Result</code> 和 <code>Option</code> 是 Rust 中用于错误处理和可选值的两个重要枚举类型。它们在处理不同类型的情况时非常有用。</p>
<h4 id="Option-枚举类型"><a href="#Option-枚举类型" class="headerlink" title="Option 枚举类型"></a><code>Option</code> 枚举类型</h4><p><code>Option</code> 类型用于表示一个值可能存在（<code>Some</code>）或不存在（<code>None</code>）。它通常用于返回一个可能为空的值。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">Option</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="title function_ invoke__">Some</span>(T),</span><br><span class="line">    <span class="literal">None</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">find_element</span>(vec: &amp;<span class="type">Vec</span>&lt;<span class="type">i32</span>&gt;, index: <span class="type">usize</span>) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;<span class="type">i32</span>&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> index &lt; vec.<span class="title function_ invoke__">len</span>() &#123;</span><br><span class="line">        <span class="title function_ invoke__">Some</span>(vec[index])</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="literal">None</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> <span class="variable">numbers</span> = <span class="built_in">vec!</span>[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>];</span><br><span class="line"><span class="keyword">match</span> <span class="title function_ invoke__">find_element</span>(&amp;numbers, <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="title function_ invoke__">Some</span>(value) =&gt; <span class="built_in">println!</span>(<span class="string">&quot;Found: &#123;&#125;&quot;</span>, value),</span><br><span class="line">    <span class="literal">None</span> =&gt; <span class="built_in">println!</span>(<span class="string">&quot;Not found&quot;</span>),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="Result-枚举类型"><a href="#Result-枚举类型" class="headerlink" title="Result 枚举类型"></a><code>Result</code> 枚举类型</h4><p><code>Result</code> 类型用于表示一个操作可能成功（<code>Ok</code>）或失败（<code>Err</code>）。它通常用于返回一个可能会出错的操作结果。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">Result</span>&lt;T, E&gt; &#123;</span><br><span class="line">    <span class="title function_ invoke__">Ok</span>(T),</span><br><span class="line">    <span class="title function_ invoke__">Err</span>(E),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">divide</span>(a: <span class="type">i32</span>, b: <span class="type">i32</span>) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;<span class="type">i32</span>, <span class="type">String</span>&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> b == <span class="number">0</span> &#123;</span><br><span class="line">        <span class="title function_ invoke__">Err</span>(<span class="type">String</span>::<span class="title function_ invoke__">from</span>(<span class="string">&quot;Division by zero&quot;</span>))</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="title function_ invoke__">Ok</span>(a / b)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">match</span> <span class="title function_ invoke__">divide</span>(<span class="number">4</span>, <span class="number">2</span>) &#123;</span><br><span class="line">    <span class="title function_ invoke__">Ok</span>(result) =&gt; <span class="built_in">println!</span>(<span class="string">&quot;Result: &#123;&#125;&quot;</span>, result),</span><br><span class="line">    <span class="title function_ invoke__">Err</span>(e) =&gt; <span class="built_in">println!</span>(<span class="string">&quot;Error: &#123;&#125;&quot;</span>, e),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="Result-和-Option-的关系"><a href="#Result-和-Option-的关系" class="headerlink" title="Result 和 Option 的关系"></a><code>Result</code> 和 <code>Option</code> 的关系</h4><ul>
<li><code>Option</code> 用于表示一个值可能存在或不存在，而不涉及错误信息。</li>
<li><code>Result</code> 用于表示一个操作可能成功或失败，并且可以携带错误信息。</li>
</ul>
<p>在某些情况下，可以将 <code>Option</code> 转换为 <code>Result</code>，例如在需要提供错误信息时：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">find_element</span>(vec: &amp;<span class="type">Vec</span>&lt;<span class="type">i32</span>&gt;, index: <span class="type">usize</span>) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;<span class="type">i32</span>, <span class="type">String</span>&gt; &#123;</span><br><span class="line">    <span class="keyword">match</span> vec.<span class="title function_ invoke__">get</span>(index) &#123;</span><br><span class="line">        <span class="title function_ invoke__">Some</span>(&amp;value) =&gt; <span class="title function_ invoke__">Ok</span>(value),</span><br><span class="line">        <span class="literal">None</span> =&gt; <span class="title function_ invoke__">Err</span>(<span class="type">String</span>::<span class="title function_ invoke__">from</span>(<span class="string">&quot;Index out of bounds&quot;</span>)),</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>通过这种方式，可以更灵活地处理错误和可选值。</p>
<h4 id="自定义错误类型"><a href="#自定义错误类型" class="headerlink" title="自定义错误类型"></a>自定义错误类型</h4><p>在 Rust 中，通常建议使用自定义的错误类型来更好地表达错误信息。可以通过枚举或结构体来定义自己的错误类型，并实现 <code>std::fmt::Debug</code> 和 <code>std::fmt::Display</code> trait 来提供可读的错误信息。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[derive(Debug)]</span></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">MyError</span> &#123;</span><br><span class="line">    DivisionByZero,</span><br><span class="line">    <span class="title function_ invoke__">CustomError</span>(<span class="type">String</span>),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">std</span>::fmt::Display <span class="keyword">for</span> <span class="title class_">MyError</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">fmt</span>(&amp;<span class="keyword">self</span>, f: &amp;<span class="keyword">mut</span> std::fmt::Formatter&lt;<span class="symbol">&#x27;_</span>&gt;) <span class="punctuation">-&gt;</span> std::fmt::<span class="type">Result</span> &#123;</span><br><span class="line">        <span class="keyword">match</span> <span class="keyword">self</span> &#123;</span><br><span class="line">            MyError::DivisionByZero =&gt; <span class="built_in">write!</span>(f, <span class="string">&quot;Cannot divide by zero&quot;</span>),</span><br><span class="line">            MyError::<span class="title function_ invoke__">CustomError</span>(msg) =&gt; <span class="built_in">write!</span>(f, <span class="string">&quot;Custom error: &#123;&#125;&quot;</span>, msg),</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">divide</span>(a: <span class="type">f64</span>, b: <span class="type">f64</span>) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;<span class="type">f64</span>, MyError&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> b == <span class="number">0.0</span> &#123;</span><br><span class="line">        <span class="title function_ invoke__">Err</span>(MyError::DivisionByZero)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="title function_ invoke__">Ok</span>(a / b)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">match</span> <span class="title function_ invoke__">divide</span>(<span class="number">10.0</span>, <span class="number">0.0</span>) &#123;</span><br><span class="line">        <span class="title function_ invoke__">Ok</span>(result) =&gt; <span class="built_in">println!</span>(<span class="string">&quot;Result: &#123;&#125;&quot;</span>, result),</span><br><span class="line">        <span class="title function_ invoke__">Err</span>(error) =&gt; <span class="built_in">println!</span>(<span class="string">&quot;Error: &#123;&#125;&quot;</span>, error),</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="使用-操作符"><a href="#使用-操作符" class="headerlink" title="使用 ? 操作符"></a>使用 <code>?</code> 操作符</h4><p>Rust 中的 <code>?</code> 操作符可以用于快速地将 <code>Result</code> 或 <code>Option</code> 的值传递给包含错误处理的函数。它简化了错误传播的代码。例如：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">operation1</span>() <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;<span class="type">i32</span>, &amp;<span class="symbol">&#x27;static</span> <span class="type">str</span>&gt; &#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="title function_ invoke__">Ok</span>(<span class="number">42</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">operation2</span>() <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;<span class="type">i32</span>, &amp;<span class="symbol">&#x27;static</span> <span class="type">str</span>&gt; &#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="title function_ invoke__">Ok</span>(<span class="number">10</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;(), &amp;<span class="symbol">&#x27;static</span> <span class="type">str</span>&gt; &#123;</span><br><span class="line">    <span class="title function_ invoke__">operation1</span>()?;</span><br><span class="line">    <span class="title function_ invoke__">operation2</span>()?;</span><br><span class="line">    <span class="title function_ invoke__">Ok</span>(())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="错误处理-thiserror-和-anyhow"><a href="#错误处理-thiserror-和-anyhow" class="headerlink" title="错误处理 thiserror 和 anyhow"></a>错误处理 thiserror 和 anyhow</h4><p><a target="_blank" rel="noopener" href="https://antoinerr.github.io/blog-website/2023/01/28/rust-anyhow.html">错误处理</a><br>anyhow提供了统一管理error的方式，任何error都可以存储在anyhow中。<br>thiserror提供了方便我们定义error的宏。</p>
<p>我们的Result类型都是<code>anyhow::Result</code>并且通过<code>thiserror</code>的宏来自定义错误。</p>
<h3 id="单元测试"><a href="#单元测试" class="headerlink" title="单元测试"></a>单元测试</h3><p>通过配置宏 <code>#[cfg(test)]</code>，我们可以指定某个模块为测试模块，并且可以为模块内的函数配置 <code>#[test]</code> 以指定某个函数为测试实例。在 Rust 中，习惯性地会创建一个与模块同级的名为 <code>tests</code> 的模块，然后在该模块中编写测试函数。这些测试代码一般位于与源代码相同的文件中（也可以分成独立的文件编写）。下面的示例代码演示了如何简单验证两个数的相加。在本书中，测试代码按照类似的格式提供，旨在验证实现的正确性，并一定程度上提供对应函数或方法的使用示例。<code>assert_eq!</code> 是一个宏函数，用来断言相等。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 源代码模块</span></span><br><span class="line"><span class="keyword">mod</span> my_module &#123;</span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">add</span>(a: <span class="type">i32</span>, b: <span class="type">i32</span>) <span class="punctuation">-&gt;</span> <span class="type">i32</span> &#123;</span><br><span class="line">        a + b</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 测试模块</span></span><br><span class="line"><span class="meta">#[cfg(test)]</span></span><br><span class="line"><span class="keyword">mod</span> tests &#123;</span><br><span class="line">    <span class="keyword">use</span> super::my_module;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 测试函数</span></span><br><span class="line">    <span class="meta">#[test]</span></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">test_add</span>() &#123;</span><br><span class="line">        <span class="built_in">assert_eq!</span>(my_module::<span class="title function_ invoke__">add</span>(<span class="number">2</span>, <span class="number">3</span>), <span class="number">5</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>本书的代码按章节模块化组织，每个章节都可以独立运行。使用 <code>cargo test</code> 命令，可以按章节前缀运行对应的单元测试（例如 <code>cargo test ch1</code>），也可以执行具体的测试函数（例如 <code>cargo test ch1::skiplist::tests::it_works</code>）。章节内容循序渐进，每章结束时会引入前面章节的模块。这种组织方式使读者能够逐步学习和理解每个模块的工作原理。每个章节相对独立，读者也可以跳跃式阅读。</p>
<p>读者可以根据需要修改每个独立模块，尝试理解其工作原理，或在自己实现过程中参考这些模块。这种结构旨在提供灵活性，使读者能够自由地使用和探索本书的代码。</p>
<h3 id="所有权和引用"><a href="#所有权和引用" class="headerlink" title="所有权和引用"></a>所有权和引用</h3><p>所有权是由编译器检查的，因此检查会非常严格。在Rust中，浅拷贝会移交所有权（move），而深拷贝（Copy）则会复制对象，从而避免所有权冲突。如果一个对象实现了Copy trait，也可以进行复制，不会与所有权产生冲突。在Rust中，只有copy和move两种操作。</p>
<p>引用不会获得所有权，因此也没有权利调用Drop。创建引用在Rust中被称为借用，因此借用和引用有时会混用。借用被视为一个动词，而引用被视为一个名词。如果希望在不产生Copy的情况下修改一个对象，可以使用可变引用。</p>
<p>Rust规定一个对象只能有一个可变引用，且不能同时存在其他的可变或不可变引用。</p>
<p>笔者推荐更详细的内容可以阅<a target="_blank" rel="noopener" href="https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html">Rust Book</a> 和<br><a target="_blank" rel="noopener" href="https://doc.rust-lang.org/nomicon/ownership.html">Rust nomicon</a>，这两本书都是比较全面且标准的Rust教程。</p>
<p>在本书的数据库实现中，我们主要使用字节向量和字节切片，分别用 <code>Vec&lt;u8&gt;</code> 和 <code>&amp;[u8]</code> 表示，代表具有所有权的字节块和对字节块的借用。由于所有权的关系，如果我们只需要读取数据，会使用借用；如果需要保存写入的数据，则会使用具有所有权的对象 <code>Vec&lt;u8&gt;</code>。<code>&amp;mut [u8]</code> 是可修改的借用，实际上也具有所有权，当我们需要修改连续内存的一部分时，可以使用这种类型。</p>
<p>如果我们不需要所有权，<code>as_ref</code> 和 <code>as_mut</code> 可以为我们提供相应的引用。</p>
<p>Rust约定的迭代器类型如下，注意 <code>IntoIter</code> 有些不同，如果是一个切片的 <code>IntoIter</code>，返回的仍然是引用。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">IntoIter - T</span><br><span class="line">IterMut - &amp;<span class="keyword">mut</span> T</span><br><span class="line">Iter - &amp;T</span><br></pre></td></tr></table></figure>

<p>而 <code>as_deref</code> 和 <code>as_deref_mut</code> 可以帮助我们自动解多层引用。</p>
<h3 id="避免盲目使用-clone-满足借用规则"><a href="#避免盲目使用-clone-满足借用规则" class="headerlink" title="避免盲目使用 .clone() 满足借用规则"></a>避免盲目使用 <code>.clone()</code> 满足借用规则</h3><p>借用检查器确保 Rust 用户在开发中不会产生不安全的代码。具体而言，它防止了两种情况：首先，只允许存在一个可变引用；其次，允许存在多个引用，但全部都是不可变引用。如果编写的代码不符合这些条件，当开发人员通过克隆变量来解决编译器错误时，就可能陷入这种反模式。</p>
<p>对于初学者而言，使用 <code>.clone()</code> 来解决借用检查器引起的混乱问题是很诱人的。然而，这样做会带来严重的后果。使用 <code>.clone()</code> 会导致数据的复制，两者之间的任何更改都不会同步，就像存在两个完全独立的变量一样。</p>
<p>有一些特殊情况，例如 <code>Rc&lt;T&gt;</code> 被设计成可以智能处理克隆。它在内部管理数据的精确一份拷贝，克隆它将只克隆引用。</p>
<p>还有 <code>Arc&lt;T&gt;</code>，它提供对在堆上分配的类型为 <code>T</code> 的值的共享所有权。在 <code>Arc</code> 上调用 <code>.clone()</code> 会产生一个新的 <code>Arc</code> 实例，它指向堆上与源 <code>Arc</code> 相同的分配，同时增加引用计数。</p>
<p>总的来说，克隆应该是经过深思熟虑的，要充分了解后果。如果使用克隆来消除借用检查器错误，这是可能正在使用这种反模式的一个很好的指示。</p>
<p>即使 <code>.clone()</code> 是一个糟糕模式的指示，有时写效率低下的代码也是可以接受的，比如：</p>
<ul>
<li>开发者仍然是个新手</li>
<li>代码没有很大的速度或内存约束（比如黑客马拉松项目或原型）</li>
<li>满足借用检查器真的很复杂，而你更愿意优化可读性而不是性能</li>
</ul>
<p>如果怀疑存在不必要的克隆，应该充分了解《Rust Book》关于所有权的章节，然后评估是否需要这个克隆。</p>
<p>同时，务必在项目中始终运行 <code>cargo clippy</code>，这个 lint 工具会帮你检查一些不必要的 <code>clone</code>。</p>
<h3 id="函数借用参数的选择"><a href="#函数借用参数的选择" class="headerlink" title="函数借用参数的选择"></a>函数借用参数的选择</h3><p>函数参数会用到大量的借用，因为借用不会产生拷贝，但在使用借用的时候尽量使用直接的借用类型 <code>&amp;str</code>、<code>&amp;[T]</code>、<code>&amp;T</code> 而不是 <code>&amp;String</code>、<code>&amp;Vec&lt;T&gt;</code>、<code>&amp;Box&lt;T&gt;</code>。在作为参数的时候，后面的拥有所有权的类型（智能指针）可以自动转换成前面的类型，而反过来则不可以。例如，下面这个函数如果把参数改成 <code>&amp;String</code> 是无法编译的。原因是直接的引用类型需要再分配一个对应的所有权类型才能和所有权类型的引用对齐，但是反过来进行一次解引用就可以获得直接引用。比如 <code>a = Box&lt;T&gt;</code>，其实相当于 <code>&amp;(*a)</code>，编译器自动进行了转化先解引用对应的直接类型然后直接引用。反过来的话 <code>a = &amp;T</code>，那就得 <code>&amp;Box::new(*a)</code>，需要多创建这个 <code>Box</code> 对象，编译器就直接拒绝了。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">demo</span>(word: &amp;<span class="type">str</span>) &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">ferris</span> = <span class="string">&quot;Ferris&quot;</span>;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">curious</span> = <span class="string">&quot;Curious&quot;</span>.<span class="title function_ invoke__">to_string</span>();</span><br><span class="line">    <span class="title function_ invoke__">demo</span>(ferris);</span><br><span class="line">    <span class="title function_ invoke__">demo</span>(&amp;curious);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="不可变引用和-Rc"><a href="#不可变引用和-Rc" class="headerlink" title="不可变引用和 Rc"></a>不可变引用和 Rc</h3><p>不可变引用的生命周期必须小于所有权的生命周期，但Rc不要求，只要最后一个引用离开生命周期则回收。</p>
<h3 id="临时的可变性"><a href="#临时的可变性" class="headerlink" title="临时的可变性"></a>临时的可变性</h3><p>可以将可修改对象重新赋值让可变性消失。这样做有一个好处就是如果你明确在之后不想修改该对象，而又人为（可能被合作者，或者两个月后的自己）错误地修改了，编译器就会帮你检查出来。我觉得更多的是在人的“阅读期”直观地明确代码的可变性。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">data</span> = &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">data</span> = <span class="title function_ invoke__">get_vec</span>();</span><br><span class="line">    data.<span class="title function_ invoke__">sort</span>();</span><br><span class="line">    data</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// data 是可变的。</span></span><br></pre></td></tr></table></figure>

<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">data</span> = <span class="title function_ invoke__">get_vec</span>();</span><br><span class="line">data.<span class="title function_ invoke__">sort</span>();</span><br><span class="line"><span class="keyword">let</span> <span class="variable">data</span> = data;</span><br><span class="line"></span><br><span class="line"><span class="comment">// data 是不可变的。</span></span><br></pre></td></tr></table></figure>

<h3 id="协同性"><a href="#协同性" class="headerlink" title="协同性"></a>协同性</h3><p>协同性是Rust里面最难的部分了。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//fn two_cell_refs&lt;&#x27;big: &#x27;small, &#x27;small&gt;(</span></span><br><span class="line"><span class="comment">//    // <span class="doctag">NOTE:</span> these two lines changed</span></span><br><span class="line"><span class="comment">//    big: Cell&lt;&amp;&#x27;big u32&gt;,</span></span><br><span class="line"><span class="comment">//    small: Cell&lt;&amp;&#x27;small u32&gt;,</span></span><br><span class="line"><span class="comment">//) &#123;</span></span><br><span class="line"><span class="comment">//    assign(big, small);</span></span><br><span class="line"><span class="comment">//&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//  如果让mut reference扩大生命周期就会导致垂悬指针。</span></span><br><span class="line"><span class="comment">//  Vec可以是因为Vec是有所有权的，所以不会出现垂悬指针。</span></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">two_refs</span>&lt;<span class="symbol">&#x27;big</span>: <span class="symbol">&#x27;small</span>, <span class="symbol">&#x27;small</span>&gt;(big: <span class="type">Vec</span>&lt;&amp;<span class="symbol">&#x27;big</span> <span class="type">u32</span>&gt;, small: <span class="type">Vec</span>&lt;&amp;<span class="symbol">&#x27;small</span> <span class="type">u32</span>&gt;) &#123;</span><br><span class="line">    <span class="title function_ invoke__">take_two</span>(big, small);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">take_two</span>&lt;T&gt;(_val1: T, _val2: T) &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#[cfg(test)]</span></span><br><span class="line"><span class="keyword">mod</span> tests &#123;</span><br><span class="line">    <span class="keyword">use</span> super::*;</span><br><span class="line"></span><br><span class="line">    <span class="meta">#[test]</span></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">it_works</span>() &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">skl</span> = SkipList &#123; head: <span class="literal">None</span> &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>NonNull本质是一个<code>*const T</code>，从而使得NonNull<T>可以与T协变，通过强制转换的方式让这个指针是可修改的。这是标准库中常用的一个对象，目的是让Vec<T>这样的类型使用起来与T具有协变性。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">NonNull</span>&lt;T&gt; &#123;</span><br><span class="line">    pointer: *<span class="keyword">const</span> T,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>具体的解释可以参考<a target="_blank" rel="noopener" href="https://doc.rust-lang.org/nightly/nomicon/subtyping.html">这里</a>，目前笔者也没有完全理解这个概念。</p>
<blockquote>
<p><code>Subtyping is the idea that one type can be used in place of another.</code></p>
</blockquote>
<h3 id="范型"><a href="#范型" class="headerlink" title="范型"></a>范型</h3><p>Rust 中的泛型是一种强大的特性，它允许你编写适用于多种数据类型的代码，同时保持类型安全。通过泛型，可以编写更加灵活、抽象和可重用的代码，同时保持 Rust 的内存安全和零成本抽象。</p>
<p>以下是 Rust 中泛型的一些关键概念和用法：</p>
<h4 id="泛型函数"><a href="#泛型函数" class="headerlink" title="泛型函数"></a>泛型函数</h4><p>在 Rust 中，你可以编写泛型函数，使其适用于多种类型。示例：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">print_twice</span>&lt;T&gt;(value: T) &#123;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;:?&#125;&quot;</span>, value);</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;:?&#125;&quot;</span>, value);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="title function_ invoke__">print_twice</span>(<span class="string">&quot;Hello, Rust!&quot;</span>);</span><br><span class="line">    <span class="title function_ invoke__">print_twice</span>(<span class="number">42</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在这个例子中，<code>print_twice</code> 是一个泛型函数，可以接受任意类型的参数，并执行相同的打印操作。</p>
<h4 id="泛型结构体"><a href="#泛型结构体" class="headerlink" title="泛型结构体"></a>泛型结构体</h4><p>可以为结构体定义泛型类型参数，以实现对不同类型的结构体的抽象。示例：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Point</span>&lt;T&gt; &#123;</span><br><span class="line">    x: T,</span><br><span class="line">    y: T,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">int_point</span> = Point &#123; x: <span class="number">1</span>, y: <span class="number">2</span> &#125;;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">float_point</span> = Point &#123; x: <span class="number">1.5</span>, y: <span class="number">2.5</span> &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在这个例子中，<code>Point</code> 结构体可以用于包含任何相同类型的坐标点。</p>
<h4 id="泛型枚举"><a href="#泛型枚举" class="headerlink" title="泛型枚举"></a>泛型枚举</h4><p>枚举也可以包含泛型类型参数，以增加其灵活性。示例：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">Result</span>&lt;T, E&gt; &#123;</span><br><span class="line">    <span class="title function_ invoke__">Ok</span>(T),</span><br><span class="line">    <span class="title function_ invoke__">Err</span>(E),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">success</span>: <span class="type">Result</span>&lt;<span class="type">i32</span>, &amp;<span class="type">str</span>&gt; = <span class="type">Result</span>::<span class="title function_ invoke__">Ok</span>(<span class="number">42</span>);</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">failure</span>: <span class="type">Result</span>&lt;<span class="type">i32</span>, &amp;<span class="type">str</span>&gt; = <span class="type">Result</span>::<span class="title function_ invoke__">Err</span>(<span class="string">&quot;Error message&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在这个例子中，<code>Result</code> 枚举表示可能包含成功结果（<code>Ok</code>）或错误信息（<code>Err</code>），并分别包含了两个泛型类型参数。</p>
<h4 id="泛型实现"><a href="#泛型实现" class="headerlink" title="泛型实现"></a>泛型实现</h4><p>可以对泛型类型实现 trait，以为多种类型提供相同的行为。示例：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">trait</span> <span class="title class_">Printable</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">print</span>(&amp;<span class="keyword">self</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;T: std::fmt::<span class="built_in">Debug</span>&gt; Printable <span class="keyword">for</span> <span class="title class_">T</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">print</span>(&amp;<span class="keyword">self</span>) &#123;</span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;&#123;:?&#125;&quot;</span>, <span class="keyword">self</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="string">&quot;Hello, Rust!&quot;</span>.<span class="title function_ invoke__">print</span>();</span><br><span class="line">    <span class="number">42</span>.<span class="title function_ invoke__">print</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在这个例子中，<code>Printable</code> trait 定义了一个 <code>print</code> 方法，然后对所有实现了 <code>Debug</code> trait 的类型实现了这个 trait。</p>
<p>Rust 的泛型提供了强大的抽象能力，帮助编写更加灵活和通用的代码。通过泛型，你能够在不失去类型安全的前提下，减少代码的冗余并提高代码的可维护性。</p>
<h3 id="Read-和-Write"><a href="#Read-和-Write" class="headerlink" title="Read 和 Write"></a>Read 和 Write</h3><p>在本书中用的 Trait 比较多的是 Read、Write 和 Seek。</p>
<p>在 Rust 中，Read、Write 和 Seek 是三个与 I/O 操作密切相关的 trait，它们为实现输入和输出操作提供了通用的接口。这三个 trait 可以用于文件、网络套接字等不同的数据源和目标。</p>
<p><strong>Read Trait</strong>：<br>Read trait 定义了用于从数据源读取字节的方法。它主要包含一个方法：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">read</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, buf: &amp;<span class="keyword">mut</span> [<span class="type">u8</span>]) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;<span class="type">usize</span>, Error&gt;;</span><br></pre></td></tr></table></figure>
<p>这个方法从实现 Read trait 的类型中读取字节，并将它们存储到提供的缓冲区 <code>buf</code> 中。方法返回一个 Result，其中 <code>Ok(n)</code> 表示成功读取了 <code>n</code> 个字节，<code>Err</code> 表示发生了错误。</p>
<p><strong>Write Trait</strong>：<br>Write trait 定义了用于将字节写入数据目标的方法。它主要包含一个方法：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">write</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, buf: &amp;[<span class="type">u8</span>]) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;<span class="type">usize</span>, Error&gt;;</span><br></pre></td></tr></table></figure>
<p>这个方法将提供的缓冲区 <code>buf</code> 中的字节写入到实现 Write trait 的类型中。方法同样返回一个 Result，其中 <code>Ok(n)</code> 表示成功写入了 <code>n</code> 个字节，<code>Err</code> 表示发生了错误。</p>
<p><strong>Seek Trait</strong>：<br>Seek trait 定义了用于在数据源中定位和移动读写指针的方法。它包含三个方法：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">seek</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, pos: SeekFrom) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;<span class="type">u64</span>, Error&gt;;</span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">stream_len</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;<span class="type">u64</span>, Error&gt;;</span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">stream_position</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;<span class="type">u64</span>, Error&gt;;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>seek</code> 方法通过给定的 SeekFrom 枚举类型，将读写指针移动到指定位置。</li>
<li><code>stream_len</code> 方法返回数据源的总长度。</li>
<li><code>stream_position</code> 方法返回当前读写指针的位置。</li>
</ul>
<p>SeekFrom 枚举有以下几种可能的值：</p>
<ul>
<li><code>SeekFrom::Start(n)</code>：将指针设置到数据源的起始位置加上 <code>n</code>。</li>
<li><code>SeekFrom::End(n)</code>：将指针设置到数据源的末尾位置加上 <code>n</code>。</li>
<li><code>SeekFrom::Current(n)</code>：将指针从当前位置移动 <code>n</code> 个字节。</li>
</ul>
<p>这些 trait 为实现了文件、内存缓冲区等不同类型的数据源和目标提供了通用的接口，使得可以方便地使用相同的 I/O 操作代码处理各种类型的输入输出。在标准库中，例如 <code>File</code> 和 <code>BufReader</code> 都实现了这些 trait，使得对文件和缓冲区的读写变得简单和灵活。</p>
<p>本书中会大量用到这些 Trait，因为 <code>Vec&lt;u8&gt;</code> 和 <code>fs::File</code> 都实现了这个接口。</p>
<h3 id="Iterator"><a href="#Iterator" class="headerlink" title="Iterator"></a>Iterator</h3><p><code>Iterator</code>用于不可变迭代，<code>IntoIterator</code>用于获取所有权并进行迭代，<code>MutIterator</code>用于可变迭代。<br>在每个示例中，我们都使用了不同的方法进行迭代，并根据需要进行所有权的转移或可变引用的修改。<br>Iterator的实现，多种iterator的惯例，<br>Rust要求所有的集合数据类型都要有如下的迭代器，会返回上述方法。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">iter</span>(&amp;<span class="symbol">&#x27;a</span> <span class="keyword">self</span>) <span class="punctuation">-&gt;</span> Items&lt;<span class="symbol">&#x27;a</span>&gt;;</span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">into_iter</span>(<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> ItemsMove;</span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">iter_mut</span>(&amp;<span class="symbol">&#x27;a</span> <span class="keyword">mut</span> <span class="keyword">self</span>) <span class="punctuation">-&gt;</span> ItemsMut&lt;<span class="symbol">&#x27;a</span>&gt;;</span><br></pre></td></tr></table></figure>
<p>Rust 的标准库为集合类型提供了一组通用的迭代方法，这些方法通常以 Iterator trait 的形式提供。这些方法通常分为三类，即标准的迭代方法 trio：</p>
<p><code>fn iter(&amp;&#39;a self) -&gt; Items&lt;&#39;a&gt;;</code> 用来遍历&amp;T。</p>
<p>这个方法返回一个不可变的迭代器，允许对集合中的元素进行只读的迭代。返回的 Items 类型是一个迭代器对象，其生命周期与集合本身相同，保证迭代器不会在集合被销毁前失效。</p>
<p><code>fn iter_mut(&amp;&#39;a mut self) -&gt; ItemsMut&lt;&#39;a&gt;;</code> 用来遍历&amp;mut T</p>
<p>这个方法返回一个可变的迭代器，允许对集合中的元素进行修改。返回的 ItemsMut 类型是一个可变迭代器对象，其生命周期与可变引用的生命周期相同，确保迭代器不会在可变引用结束后继续使用。</p>
<p><code>fn into_iter(self) -&gt; ItemsMove;</code> 用来遍历T，但如果T是一个引用类型其实和iter是类似的。</p>
<p>这个方法获取集合的所有权并返回一个拥有所有权的迭代器。这表示集合本身将不再可用，因为它的所有权已经转移到迭代器上。返回的 ItemsMove 类型是一个拥有所有权的迭代器对象。</p>
<p>为了提供更大的灵活性和符合 Rust 的所有权模型，这些方法还要求集合类型和对集合的（可变）引用都实现了 IntoIterator trait。这个 trait 提供了一个统一的方式，使得集合类型和引用都能够被用于 for 循环等需要迭代的上下文中。</p>
<p>这种设计使得 Rust 中的迭代更为一致和灵活，同时确保了在迭代过程中对所有权和可变性的严格控制。</p>
<p>两级迭代器（TwoLevelIterator）可以使用标准库的<code>flat_map</code>可以把两级迭代器展开成一个大的迭代器，适用于一些多层次迭代器的场景。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">data</span> = <span class="built_in">vec!</span>[<span class="built_in">vec!</span>[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], <span class="built_in">vec!</span>[<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], <span class="built_in">vec!</span>[<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">flat_iter</span> = data.<span class="title function_ invoke__">iter</span>().<span class="title function_ invoke__">flat_map</span>(|inner| inner.<span class="title function_ invoke__">iter</span>());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> &amp;num <span class="keyword">in</span> flat_iter &#123;</span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;&quot;</span>, num);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>归并迭代器可以实现两个有序迭代器的归并排序</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">MergeSortIterator</span>&lt;L, R&gt;</span><br><span class="line"><span class="keyword">where</span></span><br><span class="line">    L: <span class="built_in">Iterator</span>,</span><br><span class="line">    R: <span class="built_in">Iterator</span>&lt;Item = L::Item&gt;,</span><br><span class="line">&#123;</span><br><span class="line">    left: L,</span><br><span class="line">    right: R,</span><br><span class="line">    left_value: <span class="type">Option</span>&lt;L::Item&gt;,</span><br><span class="line">    right_value: <span class="type">Option</span>&lt;R::Item&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;L, R&gt; MergeSortIterator&lt;L, R&gt;</span><br><span class="line"><span class="keyword">where</span></span><br><span class="line">    L: <span class="built_in">Iterator</span>,</span><br><span class="line">    R: <span class="built_in">Iterator</span>&lt;Item = L::Item&gt;,</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">new</span>(left: L, right: R) <span class="punctuation">-&gt;</span> <span class="keyword">Self</span> &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">sorter</span> = MergeSortIterator &#123;</span><br><span class="line">            left,</span><br><span class="line">            right,</span><br><span class="line">            left_value: <span class="literal">None</span>,</span><br><span class="line">            right_value: <span class="literal">None</span>,</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        sorter.<span class="title function_ invoke__">fetch_values</span>();</span><br><span class="line">        sorter</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">fetch_values</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">        <span class="keyword">self</span>.left_value = <span class="keyword">self</span>.left.<span class="title function_ invoke__">next</span>();</span><br><span class="line">        <span class="keyword">self</span>.right_value = <span class="keyword">self</span>.right.<span class="title function_ invoke__">next</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;L, R&gt; <span class="built_in">Iterator</span> <span class="keyword">for</span> <span class="title class_">MergeSortIterator</span>&lt;L, R&gt;</span><br><span class="line"><span class="keyword">where</span></span><br><span class="line">    L: <span class="built_in">Iterator</span>,</span><br><span class="line">    R: <span class="built_in">Iterator</span>&lt;Item = L::Item&gt;,</span><br><span class="line">    L::Item: <span class="built_in">Ord</span>,</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">type</span> <span class="title class_">Item</span> = L::Item;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">next</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;<span class="keyword">Self</span>::Item&gt; &#123;</span><br><span class="line">        <span class="keyword">match</span> (<span class="keyword">self</span>.left_value.<span class="title function_ invoke__">take</span>(), <span class="keyword">self</span>.right_value.<span class="title function_ invoke__">take</span>()) &#123;</span><br><span class="line">            (<span class="title function_ invoke__">Some</span>(left), <span class="title function_ invoke__">Some</span>(right)) =&gt; &#123;</span><br><span class="line">                <span class="keyword">if</span> left &lt;= right &#123;</span><br><span class="line">                    <span class="keyword">self</span>.left_value = <span class="keyword">self</span>.left.<span class="title function_ invoke__">next</span>();</span><br><span class="line">                    <span class="keyword">self</span>.right_value = <span class="title function_ invoke__">Some</span>(right);</span><br><span class="line">                    <span class="title function_ invoke__">Some</span>(left)</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="keyword">self</span>.left_value = <span class="title function_ invoke__">Some</span>(left);</span><br><span class="line">                    <span class="keyword">self</span>.right_value = <span class="keyword">self</span>.right.<span class="title function_ invoke__">next</span>();</span><br><span class="line">                    <span class="title function_ invoke__">Some</span>(right)</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            (<span class="title function_ invoke__">Some</span>(left), <span class="literal">None</span>) =&gt; &#123;</span><br><span class="line">                <span class="keyword">self</span>.left_value = <span class="keyword">self</span>.left.<span class="title function_ invoke__">next</span>();</span><br><span class="line">                <span class="title function_ invoke__">Some</span>(left)</span><br><span class="line">            &#125;</span><br><span class="line">            (<span class="literal">None</span>, <span class="title function_ invoke__">Some</span>(right)) =&gt; &#123;</span><br><span class="line">                <span class="keyword">self</span>.right_value = <span class="keyword">self</span>.right.<span class="title function_ invoke__">next</span>();</span><br><span class="line">                <span class="title function_ invoke__">Some</span>(right)</span><br><span class="line">            &#125;</span><br><span class="line">            (<span class="literal">None</span>, <span class="literal">None</span>) =&gt; <span class="literal">None</span>,</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">iter1</span> = <span class="built_in">vec!</span>[<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>].<span class="title function_ invoke__">into_iter</span>();</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">iter2</span> = <span class="built_in">vec!</span>[<span class="number">10</span>,<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>].<span class="title function_ invoke__">into_iter</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">merge_iter</span> = MergeSortIterator::<span class="title function_ invoke__">new</span>(iter1, iter2);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> <span class="variable">item</span> <span class="keyword">in</span> merge_iter &#123;</span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;&quot;</span>, item);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="幽灵数据"><a href="#幽灵数据" class="headerlink" title="幽灵数据"></a>幽灵数据</h3><p>如果SkipIterator使用<code>&amp;&#39;a Link</code>很奇怪，因为Link本身就是个Rc<br>在引用为0的时候回收，不需要生命周期的标记，但如果不用的话编译器会报错。<br>我们希望持有SkipNode的引用，生命周期应该和SkipNode一致，所以引入<br>幽灵数据，标记我们逻辑上关联的对象，因为结构体中没法引用这个类型。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">SkipIterator</span>&lt;<span class="symbol">&#x27;a</span>&gt; &#123;  </span><br><span class="line">    head: Link,</span><br><span class="line">    marker: PhantomData&lt;&amp;<span class="symbol">&#x27;a</span> SkipNode&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;<span class="symbol">&#x27;a</span>&gt; <span class="built_in">Iterator</span> <span class="keyword">for</span> <span class="title class_">SkipIterator</span>&lt;<span class="symbol">&#x27;a</span>&gt; &#123;</span><br><span class="line">    <span class="keyword">type</span> <span class="title class_">Item</span> = &amp;<span class="symbol">&#x27;a</span> SkipNode;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">next</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;<span class="keyword">Self</span>::Item&gt; &#123;</span><br><span class="line">        <span class="literal">None</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="性能调优"><a href="#性能调优" class="headerlink" title="性能调优"></a>性能调优</h3><p>TODO</p>
<h4 id="perf-profile"><a href="#perf-profile" class="headerlink" title="perf profile"></a>perf profile</h4><h4 id="tracing"><a href="#tracing" class="headerlink" title="tracing"></a>tracing</h4><h2 id="第二章理解键值数据库"><a href="#第二章理解键值数据库" class="headerlink" title="第二章理解键值数据库"></a>第二章理解键值数据库</h2><h3 id="键值数据库的介绍"><a href="#键值数据库的介绍" class="headerlink" title="键值数据库的介绍"></a>键值数据库的介绍</h3><p>键值数据库（Key-Value Database）在NoSQL（非关系型数据库）范畴中占据重要地位，其采用简洁的键值的结构对数据对象进行存储和检索。<br>每个数据项由键（key）和关联的值（value）组成，类似于字典或哈希表的数据模型，其中键是唯一标识符，而值则是与之关联的数据。这种简单的键值对模型使得键值数据库在存储和检索简单数据时表现出色。</p>
<p>许多键值数据库支持分布式架构，能够在多个节点上存储数据，以提高性能和可靠性。亚马逊的DynamoDB是一个典型的例子，于1999年提出并成为高度可扩展的键值数据库系统，满足了亚马逊的分布式存储需求，其思想和设计对后来的键值数据库系统产生了深远的影响。</p>
<p>Redis是另一备受欢迎的键值数据库，由Salvatore Sanfilippo于2009年创建。它是一种开源的内存中数据结构存储系统，支持多种数据结构，包括字符串、哈希表和列表，因而成为广泛使用的键值数据库。</p>
<p>LevelDB是由Google开发的高性能键值数据库，采用LSM树（Log-Structured Merge Tree）的结构。在2012年，RocksDB发布，进一步优化了性能和存储效率，受到了广泛的应用。</p>
<p>键值数据库以其快速的读写性能而著称，尤其在需要快速检索特定键的情境下表现出众。它们通常具备横向可扩展性，能够通过添加更多节点来处理更大的负载。其对值的数据结构没有强制规定，因此可以灵活存储各种类型的数据。本书聚焦于单机键值数据库，不会涉及一些集群数据库相关的分布式能力和扩展能力。</p>
<h3 id="LSM"><a href="#LSM" class="headerlink" title="LSM"></a>LSM</h3><p>本书将会实现一个类似LevelDB的键值数据库，其核心数据结构是LSM（Log-Structured Merge Tree）。</p>
<p>LSM最早来源于1996年的一篇论文[^1]，而被广为人知的契机则是Google的BigTable[^2]论文，其中的文件格式基于LSM。Google开源了类似键值数据库的单机版本，即LevelDB[^3]。传统数据库通常使用B-Tree类的数据结构，它具有许多优点。随着LevelDB的诞生，基于LSM-Tree的数据结构也逐渐进入人们的视野。</p>
<p>LSM是一种用于存储和管理大规模键值对数据的数据结构，它在特定应用场景中非常有效，具有以下优势：</p>
<ul>
<li><p><strong>高写入吞吐量</strong>：LSM树通过将写入操作追加到顺序写的文件中，并使用内存和磁盘两级存储结构，实现了高效的写入吞吐量。写入操作可以在内存中迅速完成，然后异步地合并到磁盘上的存储文件中。</p>
</li>
<li><p><strong>压缩和合并</strong>：LSM树通过定期合并和压缩磁盘上的存储文件，提高了读取性能。这些合并操作使得数据在磁盘上以更为紧凑的形式存储，减少了读取时需要扫描的数据量。</p>
</li>
<li><p><strong>高吞吐读取</strong>：LSM树的结构使得范围查询更加高效，因为数据在磁盘上以顺序方式存储。这对于分析型工作负载非常有利。</p>
</li>
<li><p><strong>容错性</strong>：由于LSM树的写入操作是追加到预写日志文件中的，这提供了一种容错机制。即使在写入过程中出现故障，系统也可以通过重新应用日志来恢复。</p>
</li>
<li><p><strong>可扩展性</strong>：LSM树适用于大规模的分布式存储系统，支持数据的水平扩展。各个节点可以独立地执行写入和合并操作，从而提高了系统的可扩展性。</p>
</li>
<li><p><strong>减少随机I/O</strong>：LSM树的追加写入方式减少了磁盘上的随机I/O，有助于提高写入性能。这对于使用磁盘作为主要存储介质的系统尤为重要。</p>
</li>
</ul>
<p>[^1]: 《The Log-Structured Merge-Tree (LSM-Tree)》：这是LSM的原始论文。<br>[^2]: 《Bigtable: A Distributed Storage System for Structured Data》（作者：Fay Chang等）：这是Google的Bigtable论文，该文档介绍了Bigtable如何使用LSM树来管理大规模分布式数据存储。<br>[^3]: 《LevelDB: A Fast Persistent Key-Value Store》（作者：Jeff Dean, Sanjay Ghemawat）：这是Google开发的LevelDB的论文，该数据库使用了LSM树结构。论文提供了对LSM树及其在LevelDB中的应用的深入了解。</p>
<h3 id="HDD和SSD"><a href="#HDD和SSD" class="headerlink" title="HDD和SSD"></a>HDD和SSD</h3><p>LevelDB是为了针对HDD的追加写的特性而设计的，有很多优化是基于SSD的。<br>有一本书关于SSD的《深入浅出SSD》详细阐述了SSD的特性。</p>
<h2 id="第三章构建数据库引擎"><a href="#第三章构建数据库引擎" class="headerlink" title="第三章构建数据库引擎"></a>第三章构建数据库引擎</h2><h3 id="基本架构"><a href="#基本架构" class="headerlink" title="基本架构"></a>基本架构</h3><p>整个数据库的基本架构下图，一般来说，一个实现LSM键值存储接口所使用的对象是任意字节流。<br>作为搜索结构，所有数据会有序排列在存储中，常用的操作有插入、更新、获取、遍历和删除等。<br>为了利用追加写的特性，其中的删除一般是通过插入“墓碑”来代替而不会真正的删除，<br>而更新则是追加一个键的新版本，所以整个数据库只用到了追加写不使用随机写，充分利用<br>机械硬盘的追加写性能远远高于随机写的特性。机械硬盘在写之前需要进行磁片上的寻址操作，<br>这导致随机写相较于顺序写多了很多寻址操作，其之间的性能大致差了100倍。</p>
<img data-src="/zh-CN/2024/11/25/%E7%94%A8Rust%E4%BB%8E%E9%9B%B6%E7%BC%96%E5%86%99LevelDB/db_arch.svg" class="">

<p>用到这追加写的文件就是预写日志。可靠的单机数据库需要确保用户调用写入接口返回成功后，即使进程重启（甚至因机器宕机而中断）也不会导致数据丢失。<br>采用预写式日志是数据库中常见的一种手段，数据会按照先写内存再到日志的顺序进行更新。<br>由于数据已经持久保存在磁盘上，即使发生异常，内存数据丢失，也能够通过重放预写日志确保数据的完整性。<br>当前的预写式日志文件会在内存的形式一般叫MemTable。<br>很多数据库中<code>writer_buffer</code>相关的配置指的就是这个MemTable的大小，因为某种程度上它就是预写日志的内存缓存。</p>
<p>当MemTable达到容量上限（大多数数据库的默认设置为4KB），内存表的内容会被保存在持久化的文件存储中，接着日志文件可以安全删除。<br>这个表在文件系统上的形式是一个不可更改的搜索结构，一般会用SST（Static Sorted Table），顾名思义就是不可更改的、有序的文件结构。<br>该文件的不可更改的特性很像Rust变量默认的immutable。内存数据结构需要满足高效的查找和插入，其底层的数据结构一般用SkipList来实现。</p>
<!-- [critical path](https://chenju2k6.github.io/blog/2018/11/leveldb) -->

<p>数据库会对SSTable进行分层合并，由上层（或上上层）的SSTable合并成新的SSTable，并写入到下一层。<br>这个过程被称为major compact。因此，层数越小，数据越新，层数越大，数据越久远。</p>
<p>为了限制内存大小，当MemTable达到一定大小后，会转换为不可变内存表。<br>会作为整个数据库的第0层的SStable，是比较特殊的一层，这个合并过程称为minor compact。LevelDB的由来正是这种分层合并的结构。</p>
<p>当有新的文件产生时需要一个清单文件对这些文件进行记录，一般会使用一个叫MANIFEST的文件保存，用于记录各阶段文件集合信息。<br>为了更快速的查找，可能还会记录一些附加信息，例如文件大小、最大最小key等。这个文件相当于保存了所有在持久化存储上的SStable的元信息。</p>
<p>对于读操作，需要从内存表、不可变内存表、level-0 SSTable里查找，然后再从level 1中的文件开始查找。</p>
<h3 id="MemTable"><a href="#MemTable" class="headerlink" title="MemTable"></a>MemTable</h3><p>MemTable是一个内存中的数据结构，在数据被刷新到SST文件之前保存它们。它相当于一个读写的缓存——新的写总是将数据插入到MemTable中，而读必须在从SST文件读取之前查询MemTable，因为MemTable中的数据是较新的。一旦内存表被填满，它就变成不可变的，并被一个新的内存表所取代。一个后台线程将MemTable的内容刷新到一个SST文件中，之后MemTable就可以被销毁了。MemTable的大小一般是64MB。</p>
<h3 id="SkipList"><a href="#SkipList" class="headerlink" title="SkipList"></a>SkipList</h3><p>SkipList（跳表）是一种常用于实现有序存储的数据结构，通常用于构建内存表（MemTable）等应用场景。相比于平衡树等结构，SkipList 不需要复杂的旋转调整来保持平衡，其实现较为简单且易于理解。</p>
<p>SkipList 由一系列节点组成，每个节点包含键值对以及多个层级的指针。节点的高度由一个概率随机决定，这使得 SkipList 在期望上具有 O(log n) 的搜索复杂度。节点结构如下：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">SkipNode</span> &#123;</span><br><span class="line">    key: <span class="type">Vec</span>&lt;<span class="type">u8</span>&gt;,</span><br><span class="line">    value: <span class="type">Vec</span>&lt;<span class="type">u8</span>&gt;,</span><br><span class="line">    h: <span class="type">usize</span>,</span><br><span class="line">    next: <span class="type">Vec</span>&lt;Link&gt;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>SkipList的搜索操作是SkipList中的基本操作之一。从头节点开始，逐层向下搜索，如果找到等于目标键的节点，则返回对应值；如果找到大于目标键的节点，就下移一层继续搜索；如果找到小于目标键的节点，就向右移动。这样，通过多层级的指针，可以有效地减少搜索路径。<br>但是skip list的常数项相对小很多。skip list在空间上也比较节省。一个节点平均只需要1.333个指针（甚至更少），并且不需要存储保持平衡的变量。</p>
<p><img data-src="https://github.com/balloonwj/CppGuide/raw/master/articles/imgs/leveldb3.webp" alt="图示"><br>对于层级链表，每增加一层链表，节点的搜索路径就会减半，提高搜索效率。以下是一个示例，展示了如何通过层级链表来降低搜索时间复杂度。<br>对于一个链表来说，搜索的时间复杂度是O(n)的，搜索5需要5次（1，2，3，4，5）。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5 -&gt; 6 -&gt; 7 -&gt; 8</span><br></pre></td></tr></table></figure>
<p>这个搜索是线性的，但是如果再加一个链表，每隔一个结点取一次，可以节省一半的时间，从最高level的链表开始到小于后置节点时向下一个level搜索，这时5要搜索4次（1，3，5），找到4需要3次（1，3，4）。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1 - - - - 3 - - - - 5 - - - - 7</span><br><span class="line">1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5 -&gt; 6 -&gt; 7 -&gt; 8</span><br></pre></td></tr></table></figure>
<p>以此类推，再增加一个链表的话，此时5只要搜索2次（1，5），4则没变还是3次（1，3，4）。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1 - - - - - - - - - 5 - - - - - </span><br><span class="line">1 - - - - 3 - - - - 5 - - - - 7</span><br><span class="line">1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5 -&gt; 6 -&gt; 7 -&gt; 8</span><br></pre></td></tr></table></figure>
<p>这里每个节点的元素只需要存一次，但是每个节点的高度之内都要保存对应指针。</p>
<p>SkipList相较于一些有序数据结构比如平衡树来说不需要做一些旋转的调整来保持树的平衡，节点的高度是基于概率的，如果设置概率为1/2的话可以通俗的理解为“丢硬币，每次正面则这个节点的高度提高一层”，从期望上来说是可以被证明为log(n)的。因为SkipList和链表很接近，相较于平衡树来说手写更容易实现。但不巧的是链表在Rust里面是地狱难度的实现，本章的篇幅因此会比较长。</p>
<!-- 

匹配选项 { None => None, Some(x) => Some(y) } 是如此常见的惯用语，以至于它被称为映射（map）。映射采用一个函数，对 Some(x) 中的 x 执行操作以生成 Some(y) 中的 y。我们可以编写一个适当的函数并将其传递给映射，但我们更愿意内联编写要执行的操作。 -->


<p>首先我们通过<code>rand::Rng</code>生成一个<code>u32</code>的随机数，用最低位的连续1的数量作为高度，每次最低位为1时，高度加1，并且随机数右移，模仿丢硬币的过程。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> rand::Rng;</span><br><span class="line"><span class="comment">// 1/2的概率生成节点的高度</span></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">random_height</span>(total: <span class="type">usize</span>) <span class="punctuation">-&gt;</span> <span class="type">usize</span> &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">h</span> = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// 生成u32随机数</span></span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">r</span> = rand::random::&lt;<span class="type">u32</span>&gt;();</span><br><span class="line">    <span class="keyword">while</span> r &amp; <span class="number">1</span> == <span class="number">1</span> &amp;&amp; h &lt; total &#123;</span><br><span class="line">        h += <span class="number">1</span>;</span><br><span class="line">        r &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    h</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>首先我们定几个数据结构，Rc是引用计数，节点会被多个前置节点指向，所以我们需要使用Rc包裹我们的节点。<br><code>RefCell</code>是一个智能指针，可以将借用的规则推迟到运行时检查，通过<code>borrow_mut</code>方式及时对象没有使用mut声明<br>也可以获得可修改引用，RefCell会在内部记录可修改引用的唯一。<code>Option</code>用来表示空指针。所以组合起来我们构造了一个<code>Link</code>类型。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> std::cell::RefCell;</span><br><span class="line"><span class="keyword">use</span> std::rc::Rc;</span><br><span class="line"><span class="keyword">type</span> <span class="title class_">Link</span> = <span class="type">Option</span>&lt;Rc&lt;RefCell&lt;SkipNode&gt;&gt;&gt;;</span><br></pre></td></tr></table></figure>
<p>我们围绕的对象都是字节串，所以键值都用Vec<u8>来存储，为了突出代码的说明性质不引入过多的复杂性，这里没有使用范型。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> MAX_HEIGHT: <span class="type">usize</span> = <span class="number">32</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">SkipList</span> &#123;</span><br><span class="line">    head: Link, <span class="comment">// head 是一个辅助节点，不存储数据</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>下面两个函数都被包裹在<code>impl SkipList &#123;&#125;</code>中，为了阅读方便进行了省略，创建<code>SkipList</code>的时候会创建一个非None的key和value都为<code>vec![]</code>的占位节点。<br>从上向下寻找，遇到比自己大的值就下移一层继续寻找，如果遇到比自己小的值就向后移动。<br>实现链表有两个比较值得一看的文章：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://users.rust-lang.org/t/how-to-return-reference-to-value-in-rc-or-refcell/76729/23">为什么无法获取Rc包含的对象的引用</a></li>
<li><a target="_blank" rel="noopener" href="https://rust-unofficial.github.io/too-many-lists/fourth-peek.html">too many lists 中的说明</a></li>
</ul>
<p>搜索操作是 SkipList 中的基本操作之一。从头节点开始，逐层向下搜索，如果找到等于目标键的节点，则返回对应值；如果找到大于目标键的节点，就下移一层继续搜索；如果找到小于目标键的节点，就向右移动。这样，通过多层级的指针，可以有效地减少搜索路径。<br>我们的接口参照标准库中collections的形式，insert需要获取key value的所有权，get则返回引用。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">get</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, key: &amp;[<span class="type">u8</span>]) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;<span class="type">Vec</span>&lt;<span class="type">u8</span>&gt;&gt; &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">cur</span> = <span class="keyword">self</span>.head.<span class="title function_ invoke__">clone</span>();</span><br><span class="line">    <span class="keyword">for</span> <span class="variable">l</span> <span class="keyword">in</span> (<span class="number">0</span>..MAX_HEIGHT).<span class="title function_ invoke__">rev</span>() &#123;</span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">let</span> <span class="variable">Some</span>(next) = cur.<span class="title function_ invoke__">clone</span>().<span class="title function_ invoke__">unwrap</span>().<span class="title function_ invoke__">borrow</span>().next[l].<span class="title function_ invoke__">clone</span>() &#123;</span><br><span class="line">            <span class="keyword">if</span> &amp;next.<span class="title function_ invoke__">borrow</span>().key[..] &gt; key &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> &amp;next.<span class="title function_ invoke__">borrow</span>().key[..] &lt; key &#123;</span><br><span class="line">                cur = <span class="title function_ invoke__">Some</span>(next);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="title function_ invoke__">Some</span>(next.<span class="title function_ invoke__">borrow</span>().value.<span class="title function_ invoke__">clone</span>());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="literal">None</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果是ge的实现，则在level为0时选择大于的值返回。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">std::cmp::Ordering::Greater =&gt; &#123;</span><br><span class="line">    <span class="comment">// no equal key, just return the first greater key.</span></span><br><span class="line">    <span class="keyword">if</span> l == <span class="number">0</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="title function_ invoke__">Some</span>((next.<span class="title function_ invoke__">borrow</span>().key.<span class="title function_ invoke__">clone</span>(), next.<span class="title function_ invoke__">borrow</span>().value.<span class="title function_ invoke__">clone</span>()));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>插入和搜索类似，当找到下一项大于自己或者为None时将自己链接到当前节点之后，如果下一项小于自己则向后移动。插入操作也是 SkipList 中的关键操作。从头节点开始，逐层向下搜索，找到合适的位置插入新节点。为了保持 SkipList 的有序性，需要在每一层级中正确地插入节点。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">insert</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, key: &amp;[<span class="type">u8</span>], value: &amp;[<span class="type">u8</span>]) &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">h</span> = <span class="title function_ invoke__">random_height</span>(MAX_HEIGHT);</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">new_node</span> = Rc::<span class="title function_ invoke__">new</span>(RefCell::<span class="title function_ invoke__">new</span>(SkipNode &#123;</span><br><span class="line">        key: key.<span class="title function_ invoke__">to_vec</span>(),</span><br><span class="line">        value: value.<span class="title function_ invoke__">to_vec</span>(),</span><br><span class="line">        h,</span><br><span class="line">        next: <span class="built_in">vec!</span>[<span class="literal">None</span>; MAX_HEIGHT],</span><br><span class="line">    &#125;));</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">cur</span>: Link = <span class="keyword">self</span>.head.<span class="title function_ invoke__">clone</span>();</span><br><span class="line">    <span class="keyword">for</span> <span class="variable">l</span> <span class="keyword">in</span> (<span class="number">0</span>..h + <span class="number">1</span>).<span class="title function_ invoke__">rev</span>() &#123;</span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">let</span> <span class="variable">Some</span>(cur_node) = cur.<span class="title function_ invoke__">clone</span>() &#123;</span><br><span class="line">            <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">cur_node</span> = cur_node.<span class="title function_ invoke__">borrow_mut</span>();</span><br><span class="line">            <span class="keyword">match</span> cur_node.next[l].<span class="title function_ invoke__">clone</span>() &#123;</span><br><span class="line">                <span class="title function_ invoke__">Some</span>(next) =&gt; &#123;</span><br><span class="line">                    <span class="keyword">if</span> &amp;next.<span class="title function_ invoke__">borrow</span>().key[..] &lt; key &#123;</span><br><span class="line">                        <span class="comment">// move</span></span><br><span class="line">                        cur = <span class="title function_ invoke__">Some</span>(next);</span><br><span class="line">                    &#125; <span class="keyword">else</span> <span class="keyword">if</span> &amp;next.<span class="title function_ invoke__">borrow</span>().key[..] &gt; key &#123;</span><br><span class="line">                        cur_node.next[l] = <span class="title function_ invoke__">Some</span>(new_node.<span class="title function_ invoke__">clone</span>());</span><br><span class="line">                        new_node.<span class="title function_ invoke__">borrow_mut</span>().next[l] = <span class="title function_ invoke__">Some</span>(next.<span class="title function_ invoke__">clone</span>());</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        next.<span class="title function_ invoke__">borrow_mut</span>().value = value.<span class="title function_ invoke__">to_vec</span>();</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="literal">None</span> =&gt; &#123;</span><br><span class="line">                    cur_node.next[l] = <span class="title function_ invoke__">Some</span>(new_node.<span class="title function_ invoke__">clone</span>());</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>链表这类数据结构是Rust中地狱级难度，如果要实现一个通用的链表类的数据结构涉及到协同性(Covariance)，标准库中用到了很多unsafe的实现，通过指针的方式简化了代码，例如我们要实现双向链表的话Rc就不适用了，因为指向时成环的。</p>
<p>我们在实现链表的时候是无法依赖编译器帮我们自动释放空间的，因为编译器默认的行为会是一个递归调用Drop。<br>Box调用Drop以后Node占用的内存被释放，Node中的next的Box就无法被调用Drop了，这在别的语言里面很好实现，只要暂存next就好了。<br>但是，Box是一个有所有权的指针，显然Rust的所有权系统不允许让自己在“死亡”以后还被别人获取了所有权。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">impl</span> <span class="title class_">Drop</span> <span class="keyword">for</span> <span class="title class_">Box</span>&lt;Node&gt; &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">drop</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">        <span class="keyword">self</span>.ptr.<span class="title function_ invoke__">drop</span>(); <span class="comment">// 先释放指向的对象再释放自己</span></span><br><span class="line">	<span class="title function_ invoke__">deallocate</span>(<span class="keyword">self</span>.ptr);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>所以链表我们要手动实现Drop函数，这里面把box替换出来变成Empty，这样在“死亡”时就可以避免调用next了（毕竟next已经为空了不会有递归调用）。</p>
<p>我们不可以move一个可变引用即使move给了自己，理论上这不算错误，所以需要<code>mem::replace</code>，如果想要实现move就得通过replace的方法。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Buffer</span>&lt;T&gt; &#123; buf: <span class="type">Vec</span>&lt;T&gt; &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;T&gt; Buffer&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">replace_index</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, i: <span class="type">usize</span>, v: T) <span class="punctuation">-&gt;</span> T &#123;</span><br><span class="line">        <span class="comment">// error: cannot move out of dereference of `&amp;mut`-pointer</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">t</span> = <span class="keyword">self</span>.buf[i];</span><br><span class="line">        <span class="keyword">self</span>.buf[i] = v;</span><br><span class="line">        t</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">impl</span> <span class="title class_">Drop</span> <span class="keyword">for</span> <span class="title class_">List</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">drop</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">cur_link</span> = mem::<span class="title function_ invoke__">replace</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>.head, Link::Empty);</span><br><span class="line">        <span class="comment">// `while let` == &quot;do this thing until this pattern doesn&#x27;t match&quot;</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">let</span> <span class="variable">Link</span>::<span class="title function_ invoke__">More</span>(<span class="keyword">mut</span> boxed_node) = cur_link &#123;</span><br><span class="line">            cur_link = mem::<span class="title function_ invoke__">replace</span>(&amp;<span class="keyword">mut</span> boxed_node.next, Link::Empty);</span><br><span class="line">            <span class="comment">// boxed_node goes out of scope and gets dropped here;</span></span><br><span class="line">            <span class="comment">// but its Node&#x27;s `next` field has been set to Link::Empty</span></span><br><span class="line">            <span class="comment">// so no unbounded recursion occurs.</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>[并发写入] todo!() </p>
<p>[插入提示] todo!()</p>
<h3 id="预写日志"><a href="#预写日志" class="headerlink" title="预写日志"></a>预写日志</h3><p>下面我们展开讲解预习日志的相关知识和实现方式，日志文件切分成了大小为32KB的连续block块，block由连续的log record组成。<br>预写日志每次追加写都以一个record为单位，record的负载不作具体的规定可以是任意内容。</p>
<h4 id="Record"><a href="#Record" class="headerlink" title="Record"></a>Record</h4><p>Record的格式如下，首先是一个4个字节的CRC校验值紧跟着一个两个字节的u16表示长度，然后是一个字节表示类型，最后是实际的负载。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">+---------+-----------+-----------+--- ... ---+</span><br><span class="line">|CRC (4B) | Size (2B) | Type (1B) | Payload   |</span><br><span class="line">+---------+-----------+-----------+--- ... ---+</span><br></pre></td></tr></table></figure>

<p>如果我们使用u64保存长度是可以存储很大的数据的，RocksDB的一篇数据库键值规模的分析[^4]中提到一般的键是几十个字节，<br>值是十几KB的量级，u64显得太长了，当大量小对象存在的时候会比较多余，所以u16是比较合适的，但我们希望这个record又是可以扩展保存更长的<br>数据的，所以如果负载超过限制的32KB的话就会分成多个record存储。<br>后面会提到批量原子写的相关内容，如果多个key需要同时写入的话这个payload就会比较大了。</p>
<p>[^4]: 《Characterizing, Modeling, and Benchmarking RocksDB Key-Value Workloads at Facebook》</p>
<h5 id="负载长度的扩展"><a href="#负载长度的扩展" class="headerlink" title="负载长度的扩展"></a>负载长度的扩展</h5><p>我们按照LevelDB的格式使用Type表示记录的连续性，Log Type有4种：FULL = 1、FIRST = 2、MIDDLE = 3、LAST = 4。FULL类型表明该log record包含了完整的用户数据，用户数据可能比较大，超过了当前block的剩余大小，就需要分成几条log record，第一条类型为FIRST，中间的为MIDDLE，最后一条为LAST。也就是：</p>
<ul>
<li><strong>FULL</strong>，说明该log record包含一个完整的用户数据；</li>
<li><strong>FIRST</strong>，说明是log record的第一条用户数据；</li>
<li><strong>MIDDLE</strong>，说明是log record中间的用户数据；</li>
<li><strong>LAST</strong>，说明是log record最后的一条用户数据。<br>参考LevelDB文档中的例子，考虑到如下序列的用户数据：</li>
</ul>
<ol>
<li>A: length 1000</li>
<li>B: length 97270</li>
<li>C: length 8000</li>
</ol>
<p>A作为FULL类型的record存储在第一个block中； B将被拆分成3条log record，分别存储在第1、2、3个block中，这时block3还剩6byte，将被填充为0； C将作为FULL类型的record存储在block 4中。</p>
<p>由于一条log record长度最短为7（4个字节的CRC加2个字节的Size加1一个字节的Type），如果一个block的剩余空间小于等于6个字节，那么将<strong>被填充为</strong>空字符串，长度为7的log record是不包括任何用户数据的空记录。</p>
<p>LevelDB将WAL文件按块划分还有一个好处是能够按块进行切分。对于一些类似MapReduce的处理程序来说比较友好，<br>按照block读取record直到碰到FULL或者FRIST就可以作为一个分片的边界了。</p>
<h4 id="大小端"><a href="#大小端" class="headerlink" title="大小端"></a>大小端</h4><p>大小端（Endian）是计算机体系结构中的一个重要概念，用于描述多字节数据在内存中的存储方式。<br>它分为两种类型：大端序（Big-Endian）和小端序（Little-Endian），它们的区别在于多字节数据的字节排列顺序。</p>
<p>大端序（Big-Endian）：在大端序中，最高有效字节（Most Significant Byte，MSB）位于最低内存地址，而最低有效字节（Least Significant Byte，LSB）位于最高内存地址。这意味着数据的各个部分从高位到低位依次存储。举例来说，十进制数值513在大端序下会以两个字节0x02(512)和0x01(1)的顺序存储。</p>
<p>小端序（Little-Endian）：相反，小端序中，最低有效字节（LSB）位于最低内存地址，而最高有效字节（MSB）位于最高内存地址。这意味着数据的各个部分从低位到高位依次存储。以相同的例子，十进制数值513在小端序下会以两个字节0x01和0x02的顺序存储。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Convert to little-endian bytes</span></span><br><span class="line"><span class="keyword">let</span> <span class="variable">le_bytes</span> = <span class="number">513u16</span>.<span class="title function_ invoke__">to_le_bytes</span>();</span><br><span class="line"><span class="built_in">println!</span>(<span class="string">&quot;Little-endian bytes: &#123;:?&#125;&quot;</span>, le_bytes);</span><br><span class="line"><span class="comment">// Output: Little-endian bytes: [1, 2]</span></span><br><span class="line"><span class="comment">// Convert to big-endian bytes</span></span><br><span class="line"><span class="keyword">let</span> <span class="variable">be_bytes</span> = <span class="number">513u16</span>.<span class="title function_ invoke__">to_be_bytes</span>();</span><br><span class="line"><span class="built_in">println!</span>(<span class="string">&quot;Big-endian bytes: &#123;:?&#125;&quot;</span>, be_bytes);</span><br><span class="line"><span class="comment">// Output: Big-endian bytes: [2, 1]</span></span><br></pre></td></tr></table></figure>
<p>这两种字节序的差异可能在跨平台数据交换或者数据解释方面引发问题。例如，当你从一个大端序计算机向一个小端序计算机传输数据时，需要进行字节序转换，以确保数据正确解释。这样的差异在网络通信、文件存储、数据传输等领域都有广泛的应用。</p>
<p>计算机体系结构、操作系统和编程语言通常会规定默认的字节序，但程序员和开发人员需要了解大小端的概念，以确保数据在不同系统之间正确传递和解释。在考虑兼容性的情况下，我们可以选择固定一种大小端的方式。在本书中，我们选择小端编码，这也是X86的CPU的模式。</p>
<h4 id="CRC"><a href="#CRC" class="headerlink" title="CRC"></a>CRC</h4><p>CRC（Cyclic Redundancy Check，循环冗余校验）是一种高效的检错码，用于数据的校验。它基于模二除法进行计算，通过计算结果的余数来生成校验值。模二除法相当于是一种不借位的减法，因为0减1在模二运算后仍为1。在二进制领域，模二运算等效于异或操作，因此CRC可以通过位移和异或的方式进行快速计算。</p>
<p>CRC32是一种广泛使用的CRC类型，其余数为32位，对应的除数是33位的多项式。该多项式表示为：X^{32}+X^{26}+X^{23}+X^{22}+X^{16}+X^{12}+X^{11}+X^{10}+X^8+X^7+X^5+X^4+X^2+X^1+X^0 ，用二进制表示为0x4c11db7。在具体实现中，这个多项式的概念并不直接涉及，而是专注于基于二进制的计算过程。CRC32常用于键值数据库，以4字节大小保存校验和。</p>
<p>CRC的数据开头添加0不影响结果，所以会预设置一个余数初始值0XFFFFFFFF，和结果异或值0XFFFFFFFF，这个值在其他CRC类型中可能是别的值。<br>余数初始值就是余数的一个初始值，结果异或值就是在计算完余数之后要再用结果异或值进行一次异或运算。</p>
<p>CRC一般的实现有一个反向bit顺序，这个和一些硬件的传输顺序有关系，有些硬件设备是把最低位的bit先进行传输，同时在软件层面代码的实现上会更简单一点，相当于我们把最低位当成了最高位，在一些教科书中可能不会明确这个具体实现上的差异。逆向计算的时候，0x4c11db7的逆向表示是0xedb88320。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">crc32</span>(data: &amp;[<span class="type">u8</span>]) <span class="punctuation">-&gt;</span> <span class="type">u32</span> &#123;</span><br><span class="line">    <span class="comment">// 余数预设值</span></span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">crc</span>: <span class="type">u32</span> = <span class="number">0xffffffff</span>;</span><br><span class="line">    <span class="keyword">for</span> <span class="variable">byte</span> <span class="keyword">in</span> data &#123;</span><br><span class="line">        crc ^= <span class="type">u32</span>::<span class="title function_ invoke__">from</span>(*byte);</span><br><span class="line">        <span class="keyword">for</span> <span class="variable">_</span> <span class="keyword">in</span> <span class="number">0</span>..<span class="number">8</span> &#123;</span><br><span class="line">            <span class="comment">// 如果高位是1则进行模二除法（异或）</span></span><br><span class="line">            <span class="keyword">if</span> crc &amp; <span class="number">1</span> == <span class="number">1</span> &#123;</span><br><span class="line">                crc = (crc &gt;&gt; <span class="number">1</span>) ^ <span class="number">0xedb88320</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">               <span class="comment">//如果高位是0则进行</span></span><br><span class="line">                crc &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 余数异或值</span></span><br><span class="line">    crc ^ <span class="number">0xffffffff</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<!-- > 编写Rust计算crc的函数，不使用查表法。 -->

<p>当然这个实现是最简单的版本，每次只进行1bit的位移。</p>
<p>CRC32有一个查表法的快速计算方法。CRC32的查表法是一种用于加速计算的优化方式，通过预计算并存储查表，可以显著提高CRC的计算速度。这种优化的核心思想是将CRC的计算过程中的每个字节或更小颗粒度的数据提前计算并存储在一个查表中，以便在实际计算中直接查表获取结果，而不需要逐位进行运算。<br>如果是一个字节则要保存一张256大小的除法表。</p>
<p>在实际应用中，可以按照字节、4位或16位的颗粒度进行预计算并存成表。这样，每次计算CRC时，只需按颗粒度查表，从而大幅减少了计算的复杂度，提高了效率。</p>
<p>除了查表法，CRC32的另一种优化方式是通过指令级优化，主要依赖于SSE（Streaming SIMD Extensions）和PCLMULQDQ指令集。</p>
<p>SSE指令集：SSE是Intel引入的一组指令，用于执行单指令多数据（SIMD）操作。通过使用SSE指令，可以同时对多个数据进行相同的操作，从而提高并行计算能力，加速CRC32的计算过程。</p>
<p>PCLMULQDQ指令集：PCLMULQDQ指令集是Intel和AMD的x86-64架构中的一组指令，用于执行多项式乘法。CRC32的计算可以看作是多项式乘法，因此使用PCLMULQDQ指令集可以更高效地执行这一计算过程。</p>
<p>通过结合SSE和PCLMULQDQ指令集，可以在硬件层面上进一步提升CRC32的计算性能，使其更适用于高性能计算和大规模数据处理。一些快速计算crc的库基本是运用了</p>
<h5 id="VARINT"><a href="#VARINT" class="headerlink" title="VARINT"></a>VARINT</h5><p>Varint使用7个比特的组合来表示整数的值，其中每个字节的最高位用于指示是否有更多的字节。如果最高位为1，表示后面还有一个字节；如果最高位为0，表示这是最后一个字节。这种设计使得解码过程相对简单，而且可以高效地处理不同大小的整数。<br>下面是一个转化varint为u64的例子，这里定义了一个Varint的trait，使用这个trait是为了展示Rust的Trait的一个特点：可以<br>给外部对象定义方法。这样通过<code>use Varint</code>，u64就会拥有<code>to_varint_bytes</code>的方法。<br>补充说明：Rust不允许给外部对象定义外部的Trait的实现，如果可以的话相当于可以篡改外部模块的实现了。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">trait</span> <span class="title class_">Varint</span> &#123;</span><br><span class="line">    <span class="comment">// Define your trait methods here</span></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">to_varint_bytes</span>(<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">Vec</span>&lt;<span class="type">u8</span>&gt;;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">from_varint_bytes</span>(data: &amp;[<span class="type">u8</span>]) <span class="punctuation">-&gt;</span> (<span class="keyword">Self</span>, <span class="type">usize</span>)</span><br><span class="line">    <span class="keyword">where</span></span><br><span class="line">        <span class="keyword">Self</span>: <span class="built_in">Sized</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">Varint</span> <span class="keyword">for</span> <span class="title class_">u64</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">to_varint_bytes</span>(<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">Vec</span>&lt;<span class="type">u8</span>&gt; &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">value</span> = <span class="keyword">self</span>;</span><br><span class="line">        <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">bytes</span> = <span class="type">Vec</span>::<span class="title function_ invoke__">new</span>();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">loop</span> &#123;</span><br><span class="line">            <span class="comment">// 0b是表示binary的表示方法</span></span><br><span class="line">            <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">byte</span> = (value &amp; <span class="number">0b0111_1111</span>) <span class="keyword">as</span> <span class="type">u8</span>;</span><br><span class="line">            value &gt;&gt;= <span class="number">7</span>;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> value != <span class="number">0</span> &#123;</span><br><span class="line">                byte |= <span class="number">0b1000_0000</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            bytes.<span class="title function_ invoke__">push</span>(byte);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> value == <span class="number">0</span> &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        bytes</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">from_varint_bytes</span>(data: &amp;[<span class="type">u8</span>]) <span class="punctuation">-&gt;</span> (<span class="keyword">Self</span>, <span class="type">usize</span>) &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">value</span> = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">shift</span> = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">bytes_read</span> = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> &amp;byte <span class="keyword">in</span> data &#123;</span><br><span class="line">            value |= ((byte &amp; <span class="number">0b0111_1111</span>) <span class="keyword">as</span> <span class="type">u64</span>) &lt;&lt; shift;</span><br><span class="line">            shift += <span class="number">7</span>;</span><br><span class="line">            bytes_read += <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> byte &amp; <span class="number">0b1000_0000</span> == <span class="number">0</span> &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        (value, bytes_read)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="内部Key"><a href="#内部Key" class="headerlink" title="内部Key"></a>内部Key</h3><p>存储于数据库中的Key携带了额外信息：Sequence和Meta。<br>Sequence是一个单调递增的序列值，meta用于保存key的类型比如是一个用于标记删除的key。<br>其结构如下：</p>
<p><code>| User key (string) | sequence number (7 bytes) |  meta (1 byte) |</code></p>
<p>Rust定义如下：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">InternalKey</span> &#123;</span><br><span class="line">    <span class="keyword">pub</span> user_key: <span class="type">Vec</span>&lt;<span class="type">u8</span>&gt;,</span><br><span class="line">    trailer: <span class="type">u64</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">const</span> INTERNAL_KEY_SEQ_NUM_MAX: <span class="type">u64</span> = (<span class="number">1</span> &lt;&lt; <span class="number">56</span>) - <span class="number">1</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>编解码的方式</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">make_trailer</span>(seq: <span class="type">u64</span>, kind: InternalKeyKind) <span class="punctuation">-&gt;</span> <span class="type">u64</span> &#123;</span><br><span class="line">    (seq &lt;&lt; <span class="number">8</span>) | (kind <span class="keyword">as</span> <span class="type">u64</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">decode</span>(<span class="keyword">mut</span> encoded_key: <span class="type">Vec</span>&lt;<span class="type">u8</span>&gt;) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;InternalKey&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> encoded_key.<span class="title function_ invoke__">len</span>() &gt;= <span class="number">8</span> &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">trailer</span> =</span><br><span class="line">            <span class="type">u64</span>::<span class="title function_ invoke__">from_le_bytes</span>(encoded_key[encoded_key.<span class="title function_ invoke__">len</span>() - <span class="number">8</span>..].<span class="title function_ invoke__">try_into</span>().<span class="title function_ invoke__">unwrap</span>());</span><br><span class="line">        encoded_key.<span class="title function_ invoke__">resize</span>(encoded_key.<span class="title function_ invoke__">len</span>() - <span class="number">8</span>, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="title function_ invoke__">Some</span>(InternalKey &#123;</span><br><span class="line">            user_key: encoded_key,</span><br><span class="line">            trailer,</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="literal">None</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">encode</span>(<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">Vec</span>&lt;<span class="type">u8</span>&gt; &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">encoded_key</span> = <span class="keyword">self</span>.user_key;</span><br><span class="line">    encoded_key.<span class="title function_ invoke__">extend_from_slice</span>(&amp;<span class="keyword">self</span>.trailer.<span class="title function_ invoke__">to_le_bytes</span>());</span><br><span class="line">    encoded_key</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>trailer是一个u64，高位56bit保存sequence number，最后一个字节保存meta，目前只保存了key的类型标志。<br>Key的类型一般有两种一种是插入一种是删除，对于一个key的删除就是插入一个带类型为deletion的key的internal key。<br>其他的类型也可以扩展这最后的字节里面。</p>
<p>在Rust中如果一个对象实现了<code>Deref</code>，编译器可以自动帮助该对象进行引用的类型转换，这样就是为什么函数参数一般用<br><code>&amp;str</code>而不是用<code>&amp;String</code>，因为<code>&amp;String</code>可以被编译器自动转换成<code>&amp;str</code>。为了让编译器让<code>&amp;InternalKey</code>可以自动转换成<br><code>&amp;[u8]</code>，我们实现如下的<code>Deref</code>Trait。标准库中的<code>Path</code>、<code>PathBuf</code>、<code>String</code>、<code>str</code>和<code>[u8]</code>的引用都是<br>实现了彼此的<code>Deref</code>所以看到这些类型和函数的入参不一致的时候可以看看是不是有这个规则被编译器自动解引用了。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Implementing Deref for InternalKey</span></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">Deref</span> <span class="keyword">for</span> <span class="title class_">InternalKey</span> &#123;</span><br><span class="line">    <span class="keyword">type</span> <span class="title class_">Target</span> = [<span class="type">u8</span>];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">deref</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> &amp;<span class="keyword">Self</span>::Target &#123;</span><br><span class="line">        &amp;<span class="keyword">self</span>.content</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在如下的代码中会方便很多，尽管参数是<code>&amp;[u8]</code>但还是依旧可以用<code>&amp;InternalKey</code>作为参数。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">takes_slice</span>(slice: &amp;[<span class="type">u8</span>]) &#123;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;:?&#125;&quot;</span>, slice);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">key</span> = InternalKey::<span class="title function_ invoke__">new</span>(<span class="string">b&quot;123&quot;</span>);</span><br><span class="line">    <span class="title function_ invoke__">takes_slice</span>(&amp;key); <span class="comment">// Now this will implicitly call deref()</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>但有些看起来可以自动deref的其实不行例如：<code>&amp;u64</code>和<code>&amp;usize</code>，因为usize不一定是64位的所以标准库没有实现AsDeref。</p>
<h4 id="Sequence-Number"><a href="#Sequence-Number" class="headerlink" title="Sequence Number"></a>Sequence Number</h4><p>我们的数据库目前没有完整的事务，但是提供了一定的读的一致性视图和批量写入的原子性，<br>Sequence Number作为Key的一部分保存了对应的版本信息。<br>Sequence Number是为了实现Snapshot和原子的批量而依赖的，类似多版本控制的版本，是一个单增的序号。<br>对于一个读，特别是遍历的时候，会不读取比当前snapshot的sequence大的key，从而保证读的试图的一致性。<br>在批量写的情况中也是类似的。例如下面的例子来自于LevelDB的文档：将key1的值移动到key2，如果<code>put key2</code>成功之后在<code>del key1</code>之前失败了，<br>那么就会存在两个key存储了同一个值。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">value = get key1</span><br><span class="line">put key2 = value</span><br><span class="line">del key1</span><br></pre></td></tr></table></figure>

<p>通过原子的批量写可以避免这个问题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">value = get key1</span><br><span class="line">wb = new write batch</span><br><span class="line">wb.del key1</span><br><span class="line">wb.put key2 = value</span><br><span class="line">wb.write</span><br></pre></td></tr></table></figure>
<p>只有全部写入以后seq才能增加，不然在数据库重新启动以后发现了大于commited的seq就会放弃重放这些数据。</p>
<p>原子批量写也可以得益于批量写的能力增加写入的带宽。</p>
<h4 id="WriteBatch"><a href="#WriteBatch" class="headerlink" title="WriteBatch"></a>WriteBatch</h4><p>WriteBatch将多个写合并成一个写来实现原子性，格式如下。</p>
<p>开头是一个被所有entry共享的sequence，之后跟着一个u32的计数器。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">+-------------+------------+--- ... ---+</span><br><span class="line">| SeqNum (8B) | Count (4B) |  Entries  |</span><br><span class="line">+-------------+------------+--- ... ---+</span><br></pre></td></tr></table></figure>
<p>每个entry的开头是一个byte的Kind(上文提到的Put,Del等类型标记)，然后是一个或者两个varbytes，就是常见的varuint32的长度和对应N个字节的数据，取决于类型，例如删除就只有一个。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">+-----------+-----------------+-------------------+</span><br><span class="line">| Kind (1B) | Key (varstring) | Value (varstring) |</span><br><span class="line">+-----------+-----------------+-------------------+</span><br></pre></td></tr></table></figure>
<p>Rust的实现如下：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">Batch</span> &#123;</span><br><span class="line">    entries: <span class="type">Vec</span>&lt;<span class="type">u8</span>&gt;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>设置count和sequence号，</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">set_count</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, count: <span class="type">u32</span>) &#123;</span><br><span class="line">    <span class="keyword">self</span>.entries[<span class="number">8</span>..<span class="number">12</span>].<span class="title function_ invoke__">copy_from_slice</span>(&amp;count.<span class="title function_ invoke__">to_le_bytes</span>());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">set_seqnum</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, seqnum: <span class="type">u64</span>) &#123;</span><br><span class="line">    <span class="keyword">self</span>.entries[..<span class="number">8</span>].<span class="title function_ invoke__">copy_from_slice</span>(&amp;seqnum.<span class="title function_ invoke__">to_le_bytes</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>put操作，del操作也是类似的只是没有value，并且meta是类型不是Value而是Deletion。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">put</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, key: &amp;[<span class="type">u8</span>], value: &amp;[<span class="type">u8</span>]) &#123;</span><br><span class="line">    <span class="keyword">self</span>.entries.<span class="title function_ invoke__">push</span>(InternalKeyKind::Value <span class="keyword">as</span> <span class="type">u8</span>);</span><br><span class="line">    <span class="keyword">self</span>.entries</span><br><span class="line">        .<span class="title function_ invoke__">extend_from_slice</span>(&amp;(key.<span class="title function_ invoke__">len</span>() <span class="keyword">as</span> <span class="type">u32</span>).<span class="title function_ invoke__">to_varint_bytes</span>());</span><br><span class="line">    <span class="keyword">self</span>.entries.<span class="title function_ invoke__">extend_from_slice</span>(key);</span><br><span class="line">    <span class="keyword">self</span>.entries</span><br><span class="line">        .<span class="title function_ invoke__">extend_from_slice</span>(&amp;(value.<span class="title function_ invoke__">len</span>() <span class="keyword">as</span> <span class="type">u32</span>).<span class="title function_ invoke__">to_varint_bytes</span>());</span><br><span class="line">    <span class="keyword">self</span>.entries.<span class="title function_ invoke__">extend_from_slice</span>(value);</span><br><span class="line">    <span class="keyword">self</span>.<span class="title function_ invoke__">set_count</span>(<span class="keyword">self</span>.<span class="title function_ invoke__">count</span>() + <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="在WAL中保存WriteBatch"><a href="#在WAL中保存WriteBatch" class="headerlink" title="在WAL中保存WriteBatch"></a>在WAL中保存WriteBatch</h4><h4 id="Snapshot"><a href="#Snapshot" class="headerlink" title="Snapshot"></a>Snapshot</h4><p>Snapshot提供一致性的读视图，本质是一个sequence生成器和管理器，任何大于snapshot的key都不会被读取，从而保证读的一致性（特别是在遍历的时候）。在获取的时候会使用sequence来搜索，小于该sequence的key不会被搜索到。<br>如果是墓碑值也会过滤掉。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">get_internal</span>(&amp;<span class="keyword">self</span>, key: &amp;[<span class="type">u8</span>], seq: <span class="type">u64</span>) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;<span class="type">Vec</span>&lt;<span class="type">u8</span>&gt;&gt; &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">lookup</span> = InternalKey::<span class="title function_ invoke__">new</span>(key, seq, InternalKeyKind::Value);</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Some</span>((internal_key, value)) = <span class="keyword">self</span>.mt.<span class="title function_ invoke__">get_ge</span>(&amp;lookup.<span class="title function_ invoke__">encode</span>()) &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">internal_key</span> = InternalKey::<span class="title function_ invoke__">decode</span>(internal_key).<span class="title function_ invoke__">unwrap</span>();</span><br><span class="line">        <span class="keyword">if</span> internal_key.user_key == key</span><br><span class="line">            <span class="comment">// not deleted</span></span><br><span class="line">            &amp;&amp; internal_key.trailer &amp; <span class="number">0xff</span> != InternalKeyKind::Deletion <span class="keyword">as</span> <span class="type">u64</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="title function_ invoke__">Some</span>(value);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="literal">None</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="内部比较器"><a href="#内部比较器" class="headerlink" title="内部比较器"></a>内部比较器</h4><p>InternalKey可以重载比较符，在一些场景下比较方便。<br>但是一些场景我们需要对<code>&amp;[u8]</code>进行比较，这个时候重载比较符是不被允许的。<br>这样我们定义一个额外的用于比较相关的数据结构。</p>
<p>可以看到上面我们使用了<code>get_ge</code>代表搜索大于等于这个internal key的key。<br>为了实现大的sequence不被搜索到我们希望seq是降序排序的。<br>由于user key按升序排列，但希望seq能够按“降序”排列，我们需要定义一个内部比较器，<br>user key 升序但是当user key 相同时seq大的更“小”。<br>这样我们的搜索结构就能保持不变，只要寻找的时候找到第一个“大等于” user key,seq 的internal key就可以。<br>在MemTable中的SkipList将Greater和Equal合并。<br>我们要给memtable加上<code>get_ge</code>的方法，寻找第一个大于等于key的函数，SkipList的搜索过程中<br>要多加一个条件，当level为0时，还没有找到相等的值，就返回当前的较大值。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">std::cmp::Ordering::Greater =&gt; &#123;</span><br><span class="line">    <span class="comment">// no equal key, just return the first greater key.</span></span><br><span class="line">    <span class="keyword">if</span> l == <span class="number">0</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="title function_ invoke__">Some</span>((next.<span class="title function_ invoke__">borrow</span>().key.<span class="title function_ invoke__">clone</span>(), next.<span class="title function_ invoke__">borrow</span>().value.<span class="title function_ invoke__">clone</span>()));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>自定义比较函数，使用静态结构体保存函数集合。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> std::&#123;</span><br><span class="line">    cmp::&#123;<span class="keyword">self</span>, min, Ordering&#125;,</span><br><span class="line">    mem,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#[derive(Clone, Copy)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">Comparator</span> &#123;</span><br><span class="line">    <span class="keyword">pub</span> cmp: <span class="title function_ invoke__">fn</span>(&amp;[<span class="type">u8</span>], &amp;[<span class="type">u8</span>]) <span class="punctuation">-&gt;</span> Ordering,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">const</span> INTERNAL_COMPARATOR: Comparator = Comparator &#123; cmp: internal_cmp &#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// user key + seno + meta</span></span><br><span class="line"><span class="title function_ invoke__">pub</span>(<span class="keyword">super</span>) <span class="keyword">fn</span> <span class="title function_">internal_cmp</span>(a: &amp;[<span class="type">u8</span>], b: &amp;[<span class="type">u8</span>]) <span class="punctuation">-&gt;</span> Ordering &#123;</span><br><span class="line">    <span class="built_in">assert!</span>(a.<span class="title function_ invoke__">len</span>() &gt;= <span class="number">8</span>);</span><br><span class="line">    <span class="built_in">assert!</span>(b.<span class="title function_ invoke__">len</span>() &gt;= <span class="number">8</span>);</span><br><span class="line">    <span class="keyword">match</span> &amp;a[<span class="number">0</span>..a.<span class="title function_ invoke__">len</span>() - <span class="number">8</span>].<span class="title function_ invoke__">cmp</span>(&amp;b[<span class="number">0</span>..b.<span class="title function_ invoke__">len</span>() - <span class="number">8</span>]) &#123;</span><br><span class="line">        Ordering::Less =&gt; Ordering::Less,</span><br><span class="line">        Ordering::Greater =&gt; Ordering::Greater,</span><br><span class="line">        Ordering::Equal =&gt; &#123;</span><br><span class="line">            <span class="keyword">let</span> <span class="variable">a_trailer</span> = <span class="type">u64</span>::<span class="title function_ invoke__">from_le_bytes</span>(a[a.<span class="title function_ invoke__">len</span>() - <span class="number">8</span>..].<span class="title function_ invoke__">try_into</span>().<span class="title function_ invoke__">unwrap</span>());</span><br><span class="line">            <span class="keyword">let</span> <span class="variable">b_trailer</span> = <span class="type">u64</span>::<span class="title function_ invoke__">from_le_bytes</span>(b[b.<span class="title function_ invoke__">len</span>() - <span class="number">8</span>..].<span class="title function_ invoke__">try_into</span>().<span class="title function_ invoke__">unwrap</span>());</span><br><span class="line">            <span class="comment">// revsersed order</span></span><br><span class="line">            b_trailer.<span class="title function_ invoke__">cmp</span>(&amp;a_trailer)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">const</span> BYTEWISE_COMPARATOR: Comparator = Comparator &#123; cmp: cmp::<span class="built_in">Ord</span>::cmp &#125;;</span><br></pre></td></tr></table></figure>
<p>一个是默认的字节序比较器，一个是根据seq做降序比较的比较器，最后的一个字节是type，但是<br>seq递增的，所以一起比较也不会影响大小，写成静态的结构体来作为相关函数的静态工具集合，<br>后面还会扩展对应的方法，所以定义了两个<code>Comparator</code>。</p>
<p>至于说为什么不定义成InternalKey的方法是因为，我们的比较<br>大部分情况下是对其他字节序列做比较，因为InternalKey有所有权，<br>转换成InternalKey要进行一次数据拷贝。</p>
<p>我们可以类似这样定义一个持有引用的对象然后给这种对象增加方法，<br>因为区别不是很大就还是按照上面的方式实现，没有那么面向对象。</p>
<p>InternalComparator是包含UserComparator的这样就可以支持用户自定义的排序排序方式。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> <span class="title class_">InternalKeyRef</span> = &amp;[<span class="type">u8</span>];</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">InternalKeyRef</span> &#123;</span><br><span class="line">    <span class="title function_ invoke__">cmp</span>(<span class="keyword">self</span>, other: Other)...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="SSTable"><a href="#SSTable" class="headerlink" title="SSTable"></a>SSTable</h3><p>SSTable（Sorted String Table）是用于各种键值数据库（如LevelDB、RocksDB和Cassandra）的基本数据结构。它旨在高效地存储和检索键值对，同时保持不变性、键有序和基于磁盘存储的原则。<br>SSTable是一个不可变对象，这和Rust的默认不可变属性很类似。</p>
<p>SSTable的内容通常由以下部分组成：</p>
<ul>
<li>排序键值数据: SSTable主要包含按特定顺序排序的键值对，以实现键的范围查询和键的单一检索。其中，值和键通常为字符串或字节序列。</li>
<li>数据块: 数据块是SSTable中存储一系列键值对的部分，专门设计用于高效读取操作。每个块可以包含固定数量的键值对，并且通常会进行压缩以节省磁盘空间。</li>
<li>块缓存：块缓存是一个组件，旨在通过在内存中存储频繁访问的SSTable块来提高读取性能。</li>
<li>元数据块: SSTable通常还包括有关其自身基本信息的元数据，在文件版本、结构等方面提供帮助以正确管理和读取SSTable属性等详细信息。</li>
<li>索引块: 索引模块在快速数据检索方面起着关键作用，其中包含元数据和与之相关联的键引用信息，能够快速获取从特定文件偏移量到相应数据块之间映射关系，并支持高效随机访问特定键值对，索引块是一种元数据块。</li>
<li>布隆过滤器: 某些情况下，SSTable可能还会附带Bloom过滤器作为概率型数据结构来判断是否存在特定键，在查找操作期间允许系统跳过不必要I/O请求并减少磁盘读取次数。</li>
<li>压缩：SSTable中的压缩涉及到应用算法来减少数据块的大小。常用的压缩算法有Snappy、LZ4和zlib。</li>
<li>墓碑: 在支持删除功能的数据库中，SSTable可能会包括墓碑来标记已删除的密钥，并确保这些被删除密钥仍然被考虑进去以保持一致性。</li>
<li>文件格式: SSTable内容采用特定文件格式进行组织和编码，在不同数据库系统之间可能存在差异；该设计旨在实现高效读写操作及合并重叠SSTable、有效管理磁盘空间等压缩过程。</li>
<li>校验和: 一些SSTable可能包含校验和或哈希值，在读取操作期间验证数据完整性；校验和有助于确保存储或传输过程中没有损坏。</li>
</ul>
<p>RocksDB中的<a target="_blank" rel="noopener" href="https://github.com/google/leveldb/blob/main/doc/table_format.md">SSTable</a>的格式如下：</p>
<img data-src="/zh-CN/2024/11/25/%E7%94%A8Rust%E4%BB%8E%E9%9B%B6%E7%BC%96%E5%86%99LevelDB/sstable_format.svg" class="">
<p>LevelDB是每个block有一个专有的filter，但考虑到我们的sst文件的filter并不大，所以参考RocksDB的默认实现只用一个full filter。</p>
<!-- 并且把整个文件当作一个大的block，不做block的拆分，综合下来我们简化成如下设计。 -->
<p>每个SSTable的block的最大的大小是典型的和page大小一致的4K大小，在一般的数据库或者存储系统中都会使用这个大小，因为<br>这个大小是page cache的大小，和page cache大小对齐（当然也可以倍数）能够充分利用操作系统的 page cache。</p>
<p>目前我们先实现一个只有一个block的SSTable，规定SSTable的第一层只能是4K，先实现block内部的数据结构。后面我们可以扩展<br>多个block的SSTable。</p>
<p>我们希望Table有搜索的能力（使用于查找某个键的时候），也有遍历的能力（使用于归并的时候）。</p>
<p>搜索基于二分查找，读取每个restart的开头key作为比较的key，二分查找对应的restart（该restart是key所在的区间）然后遍历restart查找该key。</p>
<h3 id="Data-Block构建器"><a href="#Data-Block构建器" class="headerlink" title="Data Block构建器"></a>Data Block构建器</h3><p>BlockBuilder对key的存储是前缀压缩的，对于有序的字符串来讲，这能极大的减少存储空间。但是却增加了查找的时间复杂度，为了兼顾查找效率，每隔K个key，leveldb就不使用前缀压缩，而是存储整个key，这就是重启点（restartpoint）。重启点不依赖之前的前缀读取完整的key，可以作为二分查找的分界点，合适的间隔是对压缩效率和查询效率的平衡。</p>
<img data-src="/zh-CN/2024/11/25/%E7%94%A8Rust%E4%BB%8E%E9%9B%B6%E7%BC%96%E5%86%99LevelDB/block_format.svg" class="">
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;beginning_of_file&gt;</span><br><span class="line">[data block 1]</span><br><span class="line">[meta block 1: filter block]</span><br><span class="line">[metaindex block]</span><br><span class="line">[Footer]</span><br><span class="line">&lt;end_of_file&gt;</span><br></pre></td></tr></table></figure>
<p>其中一个block由多个restart构成。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">restart 1</span><br><span class="line">restart 2</span><br><span class="line">restarts_length</span><br></pre></td></tr></table></figure>
<p>每个restart由一个header和一对kv构成，plen表示和之前的key的共享长度的部分可以省略存储的空间，klen表示不共享的长度部分，<br>value表示值的长度。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plen</span><br><span class="line">klen</span><br><span class="line">vlen</span><br><span class="line">key</span><br><span class="line">value</span><br></pre></td></tr></table></figure>
<p>作为可选项，可以对block进行压缩，所以block后会追加一个字节表示压缩算法再追加一个crc32的校验值，总共要多5个字节。<br>如果设置了这些可选项，那block的最终格式是：<code>block data | type(1B) | crc32(4B)</code>。</p>
<h3 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h3><h4 id="Snappy"><a href="#Snappy" class="headerlink" title="Snappy"></a>Snappy</h4><p>Snappy 是由 Google 开发的一种快速数据压缩和解压缩算法。<br>它专注于提供较高的压缩速度和相对较快的解压速度，适用于需要在低延迟环境中传输大量数据的应用场景。<br>Snappy 不是通用的无损压缩算法，因此它可能不适用于所有类型的数据。</p>
<p>Snappy 的压缩算法基于一系列的变长编码和字典压缩。<br>它使用两种主要类型的标记：字面值标记和复制标记。<br>字面值标记用于表示原始数据的一部分，而复制标记用于表示先前出现过的数据块的重复。<br>这使得 Snappy 在处理一些特定模式的数据时能够取得很好的压缩效果。</p>
<h3 id="Data-Block读取"><a href="#Data-Block读取" class="headerlink" title="Data Block读取"></a>Data Block读取</h3><ol>
<li><p><strong>Block 结构</strong></p>
<ul>
<li><code>Block</code> 结构包含两个字段，<code>content</code> 是块的二进制内容，<code>restarts</code> 是存储重启点偏移的数组。</li>
</ul>
</li>
<li><p><strong>Block::new 方法</strong></p>
<ul>
<li>通过 <code>Read</code> 实例读取整个块的内容。</li>
<li>解析末尾的重启点数量，获取重启点偏移数组。</li>
<li>截断块的内容，去除重启点信息，返回 <code>Block</code> 实例。</li>
</ul>
</li>
<li><p><strong>Block::restart_iter 方法</strong></p>
<ul>
<li>根据给定的重启点索引，初始化 <code>RestartIterator</code> 实例，用于迭代重启点范围内的条目。</li>
<li>计算重启点的起始和结束位置。</li>
</ul>
</li>
<li><p><strong>Block::iter 方法</strong></p>
<ul>
<li>返回 <code>BlockIterator</code> 实例，用于迭代整个块的内容。</li>
<li>将块的内容、重启点数组、以及迭代状态传递给 <code>BlockIterator</code>。</li>
</ul>
</li>
<li><p><strong>RestartIterator 迭代过程</strong></p>
<ul>
<li>迭代器按顺序遍历重启点范围内的条目。</li>
<li>每个条目由键和值组成，通过解析块内容的头部信息获取长度信息，依次读取键和值。</li>
</ul>
</li>
<li><p><strong>BlockIterator 迭代过程</strong></p>
<ul>
<li>迭代器按顺序遍历整个块的内容。</li>
<li>对于每个条目，解析块内容的头部信息，获取键和值的长度，依次读取键和值。</li>
</ul>
</li>
<li><p><strong>Block::get_ge 方法</strong></p>
<ul>
<li>使用二分查找在块的重启点中找到第一个大于等于给定键的位置。</li>
<li>通过迭代器查找该位置对应的键值对，返回找到的值。</li>
</ul>
</li>
<li><p><strong>Block::get 方法</strong></p>
<ul>
<li>使用二分查找在块的重启点中找到等于给定键的位置。</li>
<li>通过迭代器查找该位置对应的键值对，返回找到的值。</li>
</ul>
</li>
</ol>
<p>总体来说，块的读取过程通过迭代器实现对块内容的顺序访问，而二分查找用于在重启点中快速定位目标位置，提高查找效率。</p>
<h3 id="统一Filter-Block构建"><a href="#统一Filter-Block构建" class="headerlink" title="统一Filter Block构建"></a>统一Filter Block构建</h3><h3 id="分块的Filter-Block构建"><a href="#分块的Filter-Block构建" class="headerlink" title="分块的Filter Block构建"></a>分块的Filter Block构建</h3><p>Full Filter适合SSTable的key比较少的情况，每个SSTable用一个full filter即可，如果SSTable的key较多的情况下，full filter一次性要load太多<br>不太合适，所以可以按照每个block的规模去创建block级别的fitler。<br>LevelDB的设计是用base划分filter block，只要data block落在一个base的区间内那么data block的filter负责人就是对应base的filter。<br>base一般是11也就是2048，举例来说，如果两个block的开始offset都小于2048那么都由第0个filter来管理。<br>block_offset / base = filter index. filter的结构如下。一个filter可以管理多个block，一个block很大的话会有空的filter，只要这个filter在block范围内。<br>空的filter的offsets是和之前的offset一样。这里的空的filter和EmptyFilterPolicy又是两回事了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[filter 0]</span><br><span class="line">[filter 1]</span><br><span class="line">[filter 2]</span><br><span class="line">...</span><br><span class="line">[filter N-1]</span><br><span class="line"></span><br><span class="line">[offset of filter 0]                  : 4 bytes</span><br><span class="line">[offset of filter 1]                  : 4 bytes</span><br><span class="line">[offset of filter 2]                  : 4 bytes</span><br><span class="line">...</span><br><span class="line">[offset of filter N-1]                : 4 bytes</span><br><span class="line"></span><br><span class="line">[offset of beginning of offset array] : 4 bytes</span><br><span class="line">lg(base)                              : 1 byte</span><br></pre></td></tr></table></figure>

<p>这个设计在RocksDB里面被废弃了而采用了完整Filter Block。</p>
<h3 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h3><p><a target="_blank" rel="noopener" href="https://leveldb-handbook.readthedocs.io/zh/latest/bloomfilter.html">LevelDB BloomFilter</a><br><a target="_blank" rel="noopener" href="https://www.eecs.harvard.edu/~michaelm/postscripts/rsa2008.pdf">Double Hash</a><br>Bloom Filter是一种空间效率极高的概率型数据结构，用于判断一个元素是否在一个集合中。它可能会产生误判，即判断一个不存在的元素存在，但不会误判存在的元素。</p>
<p>Bloom Filter的基本原理是，当一个元素被插入集合时，通过K个哈希函数将这个元素哈希成K个位置，然后将这些位置的位都设为1。检查一个元素是否在集合中时，通过同样的哈希函数找到K个位置，如果任何一个位置的位为0，则元素一定不在集合中；如果所有位置的位都为1，则元素可能在集合中。</p>
<p>在LevelDB中，Bloom Filter被用作SSTable的一部分，用于减少不必要的磁盘读取。当查找一个键时，首先使用Bloom Filter判断这个键是否可能在SSTable中，如果可能在，则进行磁盘读取；否则，直接跳过这个SSTable，从而减少了不必要的磁盘读取。</p>
<p>Bloom Filter的优点是空间效率和查询时间都极高，特别适合于元素数量巨大，但内存空间有限的场景。缺点是存在一定的误判率。</p>
<p>Bloom Filter本身是个bit vector，最后一个字节保存K的值。</p>
<p>在LevelDB的Bloom Filter中，使用了一种称为双重哈希（Double Hashing）的技术。这种技术的主要目的是为了解决哈希冲突，即当两个不同的输入产生相同的哈希值时，如何处理。</p>
<p>双重哈希的基本思想是，当哈希冲突发生时，不是简单地在哈希表中寻找下一个空闲位置，而是使用第二个哈希函数来确定探测序列。这个第二个哈希函数会根据输入的键值生成一个新的哈希值，这个新的哈希值会与原始的哈希值结合在一起，用于确定在哈希表中的位置。</p>
<p>在LevelDB的Bloom Filter中，双重哈希的实现方式是，首先使用一个哈希函数将键值哈希到Bloom Filter的某个位置，然后使用第二个哈希函数生成一个新的哈希值，这个新的哈希值用于确定在Bloom Filter中的第二个位置。这样，每个键值在Bloom Filter中都会对应两个位置，大大降低了哈希冲突的可能性，从而提高了Bloom Filter的效率和准确性。</p>
<p>在Bloom Filter中，K值表示我们使用的哈希函数的数量。如果K值大于2，我们将对每个插入的元素应用K个哈希函数，然后在Bloom Filter中设置对应的K个位置。</p>
<p>以下是一个简单的例子，假设我们有一个空的Bloom Filter，长度为m，和3个哈希函数（即K=3）。当我们插入一个元素时，我们将对这个元素应用这3个哈希函数，得到3个哈希值。然后，我们将这3个哈希值对m取模，得到在Bloom Filter中的3个位置，然后将这3个位置的位都设为1。</p>
<p>当我们要检查一个元素是否在集合中时，我们也会对这个元素应用这3个哈希函数，得到3个哈希值，然后查看Bloom Filter中对应的3个位置。如果这3个位置的位都为1，那么我们认为这个元素可能在集合中；如果这3个位置中有任何一个位为0，那么这个元素肯定不在集合中。</p>
<p>需要注意的是，随着K值的增大，误判率会降低，但是插入和查询的时间复杂度也会增大。因此，选择合适的K值是一个需要权衡的问题。</p>
<p>如果你有很多点查找操作(例如Get())，那么Bloom Filter可以帮助加速这些操作，相反，如果你的大部分操作是范围扫描(例如Scan())，那么Bloom Filter就没有帮助了。因为Range两端的两个key可能不存在，这样过滤器就不会生效了，大部分情况下都退化成了一次搜索大于左边界的键和从当前位置遍历直到超过右边界。</p>
<p>murmurhash有比较好的平衡分布的特性，计算速度快也比较简单，LevelDB使用的是最简单的murmur1。他之所以叫murmur的原因是因为他的算法就是两次乘法（multiply）和右移操作（Right shift），在版本三种这个R其实是（Rotate Left）。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">murmur1</span>(bytes: &amp;[<span class="type">u8</span>], seed: <span class="type">u32</span>) <span class="punctuation">-&gt;</span> <span class="type">u32</span> &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">m</span>: <span class="type">u32</span> = <span class="number">0xc6a4a793</span>;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">r</span> = <span class="number">24</span>;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">h</span>: <span class="type">u32</span> = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// seed ^ ( n * m )</span></span><br><span class="line">    <span class="comment">// may overflow</span></span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">h</span>: <span class="type">u32</span> = seed ^ (bytes.<span class="title function_ invoke__">len</span>() <span class="keyword">as</span> <span class="type">u32</span>).<span class="title function_ invoke__">wrapping_mul</span>(m);</span><br><span class="line">    <span class="keyword">for</span> <span class="variable">chunk</span> <span class="keyword">in</span> bytes.<span class="title function_ invoke__">chunks</span>(<span class="number">4</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> chunk.<span class="title function_ invoke__">len</span>() == <span class="number">4</span> &#123;</span><br><span class="line">            <span class="keyword">let</span> <span class="variable">w</span> = <span class="type">u32</span>::<span class="title function_ invoke__">from_le_bytes</span>([chunk[<span class="number">0</span>], chunk[<span class="number">1</span>], chunk[<span class="number">2</span>], chunk[<span class="number">3</span>]]);</span><br><span class="line">            <span class="comment">// may overflow</span></span><br><span class="line">            h = h.<span class="title function_ invoke__">wrapping_add</span>(w);</span><br><span class="line">            h = h.<span class="title function_ invoke__">wrapping_mul</span>(m);</span><br><span class="line">            h ^= h &gt;&gt; <span class="number">16</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">for</span> (i, &amp;b) <span class="keyword">in</span> chunk.<span class="title function_ invoke__">iter</span>().<span class="title function_ invoke__">enumerate</span>() &#123;</span><br><span class="line">                h += <span class="type">u32</span>::<span class="title function_ invoke__">from</span>(b) &lt;&lt; (i * <span class="number">8</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// may overflow</span></span><br><span class="line">            h = h.<span class="title function_ invoke__">wrapping_mul</span>(m);</span><br><span class="line">            h ^= h &gt;&gt; r;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    h</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>LevelDB使用Double Hashing模拟多个哈希函数。第一个函数是一个类似murmur的hash函数，而第二个函数则是一个将后15bit和前17bit兑换的简单函数。数据结构包含一个<code>k</code>用来标记hash函数的个数，<code>bits</code>用来保存bit数组。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">BloomFilter</span> &#123;</span><br><span class="line">    bits: <span class="type">Vec</span>&lt;<span class="type">u8</span>&gt;,</span><br><span class="line">    k: <span class="type">usize</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Index-Block"><a href="#Index-Block" class="headerlink" title="Index Block"></a>Index Block</h3><p>Index Block 的 key，按照<a target="_blank" rel="noopener" href="https://github.com/facebook/rocksdb/wiki/Index-Block-Format">RocksDB</a>的Wiki，<br>Index Block 的 key &gt;= 当前block，小于下一个block。</p>
<p>经历了几次优化比如把 first encode 到value中，这次就不做这个实现。</p>
<p>理论上用 last key 就可以，但是为了减小大小可以优化一下选择一个较小的key。</p>
<p>比如 [0,1,2] 和 [0,2,3] 当中 [0,1,2]和[0,2]都满足要求。</p>
<p>shortestseperator</p>
<p>shortestseperator是比较器的一部分，在这里作为index block的切分作用，所以在这里做介绍。<br><code>shortest_separator</code>的功能：找到一个最字节串介于两个key或者边界之间。<br>首先找到公共前缀，如果前缀相等那么start就是分割者，如果不想等就顺序找到第一个可以<code>+1</code>的字节（小于255），然后<br>从那个字节截断就是最小的分割者。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">shortest_separator</span>(start: &amp;<span class="keyword">mut</span> <span class="type">Vec</span>&lt;<span class="type">u8</span>&gt;, limit: &amp;[<span class="type">u8</span>]) &#123;</span><br><span class="line">    <span class="comment">// Iterate over common prefix of start and limit</span></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">min_length</span> = <span class="title function_ invoke__">min</span>(start.<span class="title function_ invoke__">len</span>(), limit.<span class="title function_ invoke__">len</span>());</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">diff_index</span> = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> diff_index &lt; min_length &amp;&amp; start[diff_index] == limit[diff_index] &#123;</span><br><span class="line">        diff_index += <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Find the first differing byte</span></span><br><span class="line">    <span class="keyword">if</span> diff_index &lt; min_length &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">diff_byte</span> = start[diff_index];</span><br><span class="line">        <span class="keyword">if</span> diff_byte &lt; <span class="number">255</span> &amp;&amp; diff_byte + <span class="number">1</span> &lt; limit[diff_index] &#123;</span><br><span class="line">            <span class="comment">// Increment the differing byte</span></span><br><span class="line">            start[diff_index] += <span class="number">1</span>;</span><br><span class="line">            <span class="comment">// Remove the rest of the vector to make it shorter</span></span><br><span class="line">            start.<span class="title function_ invoke__">resize</span>(diff_index + <span class="number">1</span>, <span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="comment">// Do not shorten if one string is a prefix of the other</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果是内部key的话，如果分割者比sart短的话，就要完善这个内部ke的构成，我们需要补上一个<br><code>MAX_SEQUENCE_NUMBER &lt;&lt; 8 | ValueType::TypeForSeek as u64</code>，这样就可以保证分割者比start大。<br>这里的<code>TypeForSeek</code>表示这个key并没有代表使用的key，而是在index block中起索引作用的key。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">internal_shortest_separator</span>(start: &amp;<span class="keyword">mut</span> <span class="type">Vec</span>&lt;<span class="type">u8</span>&gt;, limit: &amp;[<span class="type">u8</span>]) &#123;</span><br><span class="line">    <span class="built_in">assert!</span>(start.<span class="title function_ invoke__">len</span>() &gt;= <span class="number">8</span>);</span><br><span class="line">    <span class="built_in">assert!</span>(limit.<span class="title function_ invoke__">len</span>() &gt;= <span class="number">8</span>);</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">l</span> = &amp;start[<span class="number">0</span>..start.<span class="title function_ invoke__">len</span>() - <span class="number">8</span>];</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">j</span> = &amp;limit[<span class="number">0</span>..limit.<span class="title function_ invoke__">len</span>() - <span class="number">8</span>];</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">tmp</span> = l.<span class="title function_ invoke__">to_vec</span>();</span><br><span class="line">    (UserKeyComparator.separator)(&amp;<span class="keyword">mut</span> tmp, j);</span><br><span class="line">    <span class="keyword">if</span> tmp.<span class="title function_ invoke__">len</span>() &lt; l.<span class="title function_ invoke__">len</span>() &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">pack</span> = MAX_SEQUENCE_NUMBER &lt;&lt; <span class="number">8</span> | ValueType::TypeForSeek <span class="keyword">as</span> <span class="type">u64</span>;</span><br><span class="line">        tmp.<span class="title function_ invoke__">extend_from_slice</span>(pack.<span class="title function_ invoke__">to_le_bytes</span>().<span class="title function_ invoke__">as_ref</span>());</span><br><span class="line">        <span class="built_in">assert!</span>(<span class="title function_ invoke__">internal_cmp</span>(start, &amp;tmp) == Ordering::Less);</span><br><span class="line">        <span class="built_in">assert!</span>(<span class="title function_ invoke__">internal_cmp</span>(&amp;tmp, limit) == Ordering::Less);</span><br><span class="line">        mem::<span class="title function_ invoke__">swap</span>(start, &amp;<span class="keyword">mut</span> tmp);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="TableBuilder"><a href="#TableBuilder" class="headerlink" title="TableBuilder"></a>TableBuilder</h3><p>SSTable是不可修改的，只存在创建和删除。</p>
<h4 id="Option"><a href="#Option" class="headerlink" title="Option"></a>Option</h4><p>用于管理选项，例如restart_block_interval，block_size等。</p>
<h3 id="TableReader"><a href="#TableReader" class="headerlink" title="TableReader"></a>TableReader</h3><p>block的设计有一个好处可以根据block index去读取block。</p>
<h3 id="Block-Cache"><a href="#Block-Cache" class="headerlink" title="Block Cache"></a>Block Cache</h3><p>LRU Cache 需要一个队列和HashMap并且，为了缓解缩的压力也可以对key分片做分段锁。<br>当需要从BlockHandle获取Block时会先从Block Cache当中获取。</p>
<h3 id="Index-和-Filter-Cache"><a href="#Index-和-Filter-Cache" class="headerlink" title="Index 和 Filter Cache"></a>Index 和 Filter Cache</h3><p>会把level0的index block 和 filer block 缓存起来。<br>pin_l0_filter_and_index_blocks_in_cache</p>
<p>块缓存用来来缓存未压缩的数据块，它的大小一般来说可以是总内存预算的1/3左右。</p>
<h3 id="LRU-Cache"><a href="#LRU-Cache" class="headerlink" title="LRU Cache"></a>LRU Cache</h3><p>为了加速读取可以将最近使用的一些Table缓存到内存中加速Table的加载。<br>LRU Cache是个比较经典的数据结构了，但是标准库的双向链表是O(n)的删除。<br>如果要实现O(1)的链表可以还得自己定一个链表，实现起来比较复杂，我们先暂时容忍一下这个O(n)。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">LRUCache</span>&lt;K, V&gt; &#123;</span><br><span class="line">    map: HashMap&lt;K, V&gt;,</span><br><span class="line">    order: VecDeque&lt;K&gt;,</span><br><span class="line">    capacity: <span class="type">usize</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;K: <span class="built_in">Clone</span> + <span class="built_in">Eq</span> + Hash, V&gt; LRUCache&lt;K, V&gt; &#123;</span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">new</span>(capacity: <span class="type">usize</span>) <span class="punctuation">-&gt;</span> <span class="keyword">Self</span> &#123;</span><br><span class="line">        LRUCache &#123;</span><br><span class="line">            map: HashMap::<span class="title function_ invoke__">with_capacity</span>(capacity),</span><br><span class="line">            order: VecDeque::<span class="title function_ invoke__">with_capacity</span>(capacity),</span><br><span class="line">            capacity,</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">get_or_insert_with</span>&lt;F: <span class="title function_ invoke__">FnOnce</span>() <span class="punctuation">-&gt;</span> V&gt;(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, key: &amp;K, f: F) <span class="punctuation">-&gt;</span> &amp;V &#123;</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">self</span>.map.<span class="title function_ invoke__">contains_key</span>(key) &#123;</span><br><span class="line">            <span class="keyword">self</span>.<span class="title function_ invoke__">refresh</span>(key);</span><br><span class="line">            <span class="keyword">self</span>.map.<span class="title function_ invoke__">get</span>(key).<span class="title function_ invoke__">unwrap</span>()</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">self</span>.<span class="title function_ invoke__">put</span>(key.<span class="title function_ invoke__">clone</span>(), <span class="title function_ invoke__">f</span>());</span><br><span class="line">            <span class="keyword">self</span>.map.<span class="title function_ invoke__">get</span>(key).<span class="title function_ invoke__">unwrap</span>()</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">put</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, key: K, value: V) &#123;</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">self</span>.map.<span class="title function_ invoke__">contains_key</span>(&amp;key) &#123;</span><br><span class="line">            <span class="keyword">self</span>.<span class="title function_ invoke__">refresh</span>(&amp;key);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">self</span>.map.<span class="title function_ invoke__">len</span>() == <span class="keyword">self</span>.capacity &#123;</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Some</span>(oldest) = <span class="keyword">self</span>.order.<span class="title function_ invoke__">pop_back</span>() &#123;</span><br><span class="line">                    <span class="keyword">self</span>.map.<span class="title function_ invoke__">remove</span>(&amp;oldest);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">self</span>.order.<span class="title function_ invoke__">push_front</span>(key.<span class="title function_ invoke__">clone</span>());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">self</span>.map.<span class="title function_ invoke__">insert</span>(key, value);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">refresh</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, key: &amp;K) &#123;</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Some</span>(position) = <span class="keyword">self</span>.order.<span class="title function_ invoke__">iter</span>().<span class="title function_ invoke__">position</span>(|k| k == key) &#123;</span><br><span class="line">            <span class="keyword">let</span> <span class="variable">key</span> = <span class="keyword">self</span>.order.<span class="title function_ invoke__">remove</span>(position).<span class="title function_ invoke__">unwrap</span>();</span><br><span class="line">            <span class="keyword">self</span>.order.<span class="title function_ invoke__">push_front</span>(key);</span><br><span class="line">        &#125; </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="Block-Cache-1"><a href="#Block-Cache-1" class="headerlink" title="Block Cache"></a>Block Cache</h3><p>TODO</p>
<h3 id="Table-Cache"><a href="#Table-Cache" class="headerlink" title="Table Cache"></a>Table Cache</h3><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">TableCache</span> &#123;</span><br><span class="line">    cache: LRUCache&lt;<span class="type">u64</span>, Table&lt;File&gt;&gt;,</span><br><span class="line">    opt: Options,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">TableCache</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">new</span>(opt: Options) <span class="punctuation">-&gt;</span> <span class="keyword">Self</span> &#123;</span><br><span class="line">        <span class="keyword">Self</span> &#123;</span><br><span class="line">            cache: LRUCache::<span class="title function_ invoke__">new</span>(<span class="number">100</span>),</span><br><span class="line">            opt,</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">get_table</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, file_num: <span class="type">u64</span>) <span class="punctuation">-&gt;</span> &amp;Table&lt;File&gt; &#123;</span><br><span class="line">        <span class="keyword">self</span>.cache.<span class="title function_ invoke__">get_or_insert_with</span>(&amp;file_num, ||&#123;</span><br><span class="line">            <span class="keyword">let</span> <span class="variable">file</span> = std::fs::OpenOptions::<span class="title function_ invoke__">new</span>()</span><br><span class="line">                .<span class="title function_ invoke__">read</span>(<span class="literal">true</span>)</span><br><span class="line">                .<span class="title function_ invoke__">open</span>(<span class="built_in">format!</span>(<span class="string">&quot;&#123;&#125;.sst&quot;</span>, file_num))</span><br><span class="line">                .<span class="title function_ invoke__">unwrap</span>();</span><br><span class="line">            Table::<span class="title function_ invoke__">from_reader</span>(file, <span class="keyword">self</span>.opt).<span class="title function_ invoke__">unwrap</span>()</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="MANIFEST"><a href="#MANIFEST" class="headerlink" title="MANIFEST"></a>MANIFEST</h3><p>MANIFEST也是一个基于record的日志。<br>版本跟着 sst 文件走，每次插入都会有新版本。<br>Leveldb每次新生成sstable文件，或者删除sstable文件，都会从一个版本升级成另外一个版本。</p>
<h3 id="相关文件的管理"><a href="#相关文件的管理" class="headerlink" title="相关文件的管理"></a>相关文件的管理</h3><p>lognum 用来创建 log 文件。<br>filenum 用来创建 sst 文件（加载文件时获取）。<br>level 和文件的映射关系。</p>
<p>当 manifest 文件超过一定大小后会进行压缩，按照全部新建的 edit 进行追加写。<br>manifest edit 时如果超过大小就会进行压缩。</p>
<p>不需要 version，维护一个 table 的引用计数（rc），当 rc 为 0 时就删除。</p>
<p>需要将 manifest 转换成符合重放的追加写的 edit，这样在重放时可以恢复成原本的 manifest。</p>
<h3 id="合并"><a href="#合并" class="headerlink" title="合并"></a>合并</h3><p>合并的基本思想是：数据按多个level组织，目标大小呈指数级增长，例如level0的SSTable的大小是4MB的话，<br>level1就是8MB，level2就是16MB，以此类推，这里的目标大小相当于level的一个总大小限制。<br>当一个level的大小超过它的目标大小时，我们选择它的一个或多个文件，并将该文件合并到下一个级别。<br>合并算法保证了了LSM结构的平衡条件被满足并且可以缩小磁盘占用。合并过程包含的三个主要过程：</p>
<p>minor compaction 和 major compaction</p>
<ul>
<li>寻找level，选择自身大小除以目标大小的比率最大的level。</li>
<li>在合适的level中挑选合适的文件，比如和下级文件重叠最多的文件，节省空间。</li>
<li>将文件与下一个level的文件（可能多个）进行归并排序组合成新的文件（可能多个），同时之前的墓碑值也可以在合并的时候顺带删除掉。</li>
</ul>
<p>Major Compaction主要有三种分别为：</p>
<ol>
<li>Manual Compaction，是人工触发的Compaction，由外部接口调用产生。</li>
<li>Size Compaction，是根据每个level的总文件大小来触发，注意Size Compation的优先级高于Seek Compaction。</li>
<li>Seek Compaction，每个文件的 seek miss 次数都有一个阈值，如果超过了这个阈值，那么认为这个文件需要Compact。</li>
</ol>
<p>compact_pointer 就是 round robin的标记，如果没找到就从第一个文件开始。LevelDB挑选文件的方式很简单。</p>
<h3 id="读写存储放大"><a href="#读写存储放大" class="headerlink" title="读写存储放大"></a>读写存储放大</h3><p>读写存储放大（Read/Write/Space Amplification）是数据库系统中一个重要的性能问题，特别是对于基于磁盘的存储引擎。<br>读写存储放大是我们在讨论合并策略的时候需要参考的重要指标。<br>例如：当我们为了减少存储放大把冗余的文件合并的时候就会因为重写多个冗余文件而引入写放大。当不重写文件来减少写放大的时候，又会引入<br>存储放大和读放大（对应的key可能需要检查多个冗余文件才能找到）。</p>
<p>我们衡量读写存放大的指标是这么计算的：</p>
<ul>
<li>读放大：读取过程中读取的全部数据/实际读取本身所需要的数据。</li>
<li>写放大：写入过程中写入的全部数据/实际写入本身所需要的数据。</li>
<li>存放大：存储数据占用的磁盘空间/实际存储的数据本身占用的磁盘空间。</li>
</ul>
<p>数据库的大量优化除了操作执行的时间之外，很重要的性能指标就是这些“放大”，合并当中的很多优化都是围绕它们展开的。</p>
<h3 id="Version"><a href="#Version" class="headerlink" title="Version"></a>Version</h3><p>Version中的level的映射可以使用Vec，files是有序的也只需要一个Vec，然后根据file的Smallest和Largest的Key做二分搜索既可以。</p>
<p>Version一个引用计数器，读的时候Ref，读结束的时候UnRef，当没有引用的时候从VersionSet当中删除。<br>写入的时候是先写到MemTable再写到WAL，和Version没关系，但是Compact的时候有关系。</p>
<p>Verion和Compaction的关系是一对一的。<br>VersionSet包含多个Version，每个Version是串联的关系，一个Compaction会导致一个新的Version的追加。</p>
<p>LevelDB在合并和打开数据库的时候会删除不需要的文件，这个不需要是通过live_files获取的。<br>live_files来自所有的live的version，不live的Version会从version_set内删除。</p>
<p>合并涉及到删除操作，但是可能当前有相关文件的读操作还没有结束，所以我们希望在没有引用的情况下再删除改文件。</p>
<p>Version相较于MANIFEST是内存中的对象，每次重启以后只会初始化一个只有一个Version的VersionSet。<br>每次元数据的改动（SSTable的增加删除和移动等）更新，会导致一次MANIFEST文件的追加写，和内存中的一个新的Version的产生。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/// VersionSet managed the various versions that are live within a database. A single version</span><br><span class="line">/// contains references to the files on disk as they were at a certain point.</span><br></pre></td></tr></table></figure>

<p>版本保存了当前LSM结构的元信息，版本信息对应的是每个level有哪些文件存在，删除的文件不会立即删除<br>有可能有访问者正在访问。Version对应的版本是manifest的版本，每个版本对应了不同时刻的levels和sst的变化。</p>
<p>如果有读事务位于旧的文件，那么暂时就不能删除。因此利用引用计数，只要一个Verison还活着，就不允许删除该Verison管理的所有文件。当一个Version生命周期结束，它管理的所有文件的引用计数减1。</p>
<p>当sst文件不再被“活着”的版本引用的时候就可以删除对应的文件了。</p>
<p>有几种情况</p>
<ul>
<li>重启的时候对log的重放</li>
<li>minor compaction</li>
<li>major compaction 没有文件合并</li>
<li>major compaction 有文件合并</li>
</ul>
<p>VersionEdit会以追加写的Record形式追加到manifest当中。</p>
<p>这样重放的时候不需要全部堆到level0。<br>Riak 1.3 版本做了优化，改变了目录结构，对于google 最初版本的LevelDB，所有的文件都在一个目录下，但是Riak 1.3版本引入了子目录， 将不同level的sst 文件放入不同的子目录：</p>
<p>sst_0<br>sst_1<br>…<br>sst_6</p>
<p>MANIFEST文件和LOG文件一样，只要DB不关闭，这个文件一直在增长。我查看了我一个线上环境，MANIFEST文件已经膨胀到了205MB。</p>
<p>试试上，随着时间的流逝，早期的版本是没有意义的，我们没必要还原所有的版本的情况，我们只需要还原还活着的版本的信息。MANIFEST只有一个机会变小，抛弃早期过时的VersionEdit，给当前的VersionSet来个快照，然后从新的起点开始累加VerisonEdit。这个机会就是重新开启DB。</p>
<p>LevelDB的早期，只要Open DB必然会重新生成MANIFEST，哪怕MANIFEST文件大小比较小，这会给打开DB带来较大的延迟。<br>MANIFEST 文件列出了构成每个级别的排序表集、相应的键范围以及其他重要元数据。每当数据库重新打开时，都会创建一个新的 MANIFEST 文件（文件名中嵌入一个新编号）。MANIFEST 文件的格式为日志，对服务状态所做的更改（如文件的添加或删除）都会附加到该日志中。</p>
<p>在系统（重新）启动时，最新的清单日志（manifest log）包含了数据库的一致状态。任何后续变化都会被记录到清单日志文件中。<br>当清单日志文件超过一定大小时，就会创建一个包含状态快照的新清单日志文件。最新的清单文件指针会被更新，文件系统也会同步。一旦成功更新到 CURRENT 文件，多余的清单日志就会被清除。<br>Badger</p>
<p>Version和FileMetadata是多对1的，当没有Version引用这个FileMetadata的时候就可以删除对应的文件。</p>
<p>也可以通过比较当前Version和数据库目录下的文件删除不需要的，这个在数据库重启的时候比较有用。</p>
<h3 id="VersionEdit"><a href="#VersionEdit" class="headerlink" title="VersionEdit"></a>VersionEdit</h3><p>VersionEdit是一次修改的记录，apply一次VersionEdit以后会生成一个新的Version。<br>VersionEdit使用的是WAL一样的Record。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">+-------------+------ ......... ----------+</span><br><span class="line">| Record ID   | Variable size record data |</span><br><span class="line">+-------------+------ .......... ---------+</span><br><span class="line">&lt;-- byte  ---&gt;|&lt;-- varies by type       --&gt;</span><br></pre></td></tr></table></figure>
<p>例如删除文件 RecordID 为 DeleteFile，保存了删除了哪个level的文件号。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Mark a file as deleted from database.</span><br><span class="line"></span><br><span class="line">+-----------------+-------------+--------------+</span><br><span class="line">| kDeletedFile    | level       | file number  |</span><br><span class="line">+-----------------+-------------+--------------+</span><br><span class="line">&lt;-- byte     ---&gt;|&lt;-- Var32 --&gt;|&lt;-- Var64  --&gt;|</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// The MANIFEST file describes the startup state of the db -- all LSM files and what level they&#x27;re</span><br><span class="line">// at.</span><br></pre></td></tr></table></figure>

<p>manifest记录了两个主要对象 levels 和 table。<br>他是一条一条的changeSet，需要replay一次才能重新构建出来。<br>有哪些level，这些level都有哪些SSTable。</p>
<p>changeSet 在rocksdb里面叫 versionedit</p>
<p>Manifest -&gt; version<br>Version set<br>VersionSet<br>VersionSet 是一个 Version 的集合。<br>随着数据库状态的变化，LevelDB 内部会不停地生成 VersionEdit——进而产生新的 Version。此时，旧的 Version 可能还在被正在执行的请求使用。所以，同一时刻可能存在多个 Version。<br>VersionSet 用一个链表将这些 Version 维护起来，每生成一个 Version 就往这个链表尾部插入一个节点（AppendVersion）。</p>
<p>Levels 表示每个level包含的table信息，是一个数组，每个数组的元素是一个 table id的set。<br>Tables 是一个 map key是id，value包含level 和 checksum的信息。</p>
<p>这样根据 level 可以查找所包含的table，根据table id 可以查找所包含的 level 和 checksum。</p>
<p>level是从零开始连续的所以是个数组。</p>
<p>VersionEdit还有两个指标allowed_seeks和compaction_ptrs，一个代表的是seek操作的次数如果过多某种程度上代表了<br>文件被搜索的次数过多需要进行合并（TODO：补充其中的逻辑），还有一个代表的是轮转合并的文件指针，只要是为了重启的时候能从<br>上次的文件之后选择合并的文件，都是和合并相关的指标，在后面和合并相关的章节会展开说明。</p>
<h3 id="VersionBuilder"><a href="#VersionBuilder" class="headerlink" title="VersionBuilder"></a>VersionBuilder</h3><p>Version是一个静态只读的数据结构，当我们需要从一个Version转换成另外一个Version的时候，<br>需要复制当前的Version然后删除和增加对应的文件，我们的files是用Vec保存的，没办法根据file num来做增删。<br>files的需要保存file num到file metadata的映射需要map，<br>并且这个file的顺序是有序的要按照边界的key来排序，所以要有一个复合的数据结构。<br>我们引入一个新的数据结构<code>Version Builder</code>这个Builder会将Version的file拷贝成map然后<br>应用VersionEdit之后转换再根据file的SmallestKey排序组装回新的Version。</p>
<p>除此之外这个</p>
<p>deleted_file上是一个file num的Set<br>added_file是一个file metadta的Set</p>
<h3 id="VersionSet"><a href="#VersionSet" class="headerlink" title="VersionSet"></a>VersionSet</h3><p>VersionSet是一个双向循环链表，但是在Rust中没有比较好的办法不用unsafe实现<br>如果你看过 Rust实现链表或者too many list可能会觉得使用Rc加Weak可以，但是双向循环不行，<br>这个数据结构存在自己指向自己的情况 <code>head.next=head</code>，所以不得不用指针了。</p>
<p>其实不需要这个循环链表，交给Rust的ref去管理就行了。</p>
<p>FileMetadata不是和file一一映射的不能靠file metadata来回收。</p>
<p>链表还是有用的，得查找所有的存活的version。</p>
<h3 id="合并时选择Level"><a href="#合并时选择Level" class="headerlink" title="合并时选择Level"></a>合并时选择Level</h3><p>选择文件是一个可以调优的选择，LevelDB用一个单线程的后台进程进行非常简单的RoundRobin轮询挑选。 Compaction操作在key空间中循环执行，详细讲一点就是，对于每个level，我们记录上次compaction的ending key。Level的下一次compaction将选择ending key之后的第一个文件（如果这样的文件不存在，将会跳到key空间的开始）。<br>也可以使用多线程的进行多文件的合并，每个文件会在一个线程中进行合并，如果有合并参与者则选择下一个文件，<br>这样就没有读写的冲突，选择的每个并行合并涉及的文件和目标文件互相不干扰，并行合并比较好实现。</p>
<p>这里我们考虑挑选文件的情况：</p>
<p>如果一个文件和下一级的N个文件有交集那么写放到就是近似于N倍，所有的N个文件都会被重写。<br>如果这个文件的key的分布很松散导致N的数量很大就会导致写放大的问题。<br>如果key是分布比较均匀这个写放大的效果不会太明显，但实际情况不会如此。<br>所以RocksDB的一种选项是挑选包含最老更新的文件，这类文件会有最密集的键的分布。或者从另一个角度理解是这个文件在这个level存在的时间够长，相同大小的情况下会保存更多的键，密度也会更大了。<br><code>kOldestSmallestSeqFirst</code> 这里的Oldest代表最老，Smallest代表的是时间戳表示最老的更新。</p>
<p>另一种情况是热点键，选择最新更新是最老的文件，则代表的是最“冷”的文件，这样可以减少热点键向下一级移动。<br>如果一些场景更新比插入的操作更多，具有热点键范围的话可以使用这个选项。<br><code>kOldestLargestSeqFirst</code> 这里的Oldest代表最老，Largest代表的是时间戳表示最新的更新。</p>
<p>如果一个文件包含很多墓碑值，它可能会减慢迭代该区域的速度，因为我们仍然需要在合并的时候迭代那些墓碑键。此外，我们越早将墓碑键压缩到最后一层，就能越早回收磁盘空间，因此这有利于提高空间效率。</p>
<p>我们的默认压缩优先级kByCompensatedSize考虑了这种情况。如果文件中的删除（插入墓碑）次数超过插入次数，则更有可能选择该文件进行压缩。删除次数超过插入次数越多，它就越有可能被压缩。这个选项一般是为了解决数据库中有大量的键被删除导致的空间浪费和读放大。</p>
<p>BadgerDB选择的不太一样，是选择最少的overlap，然后这样重写的量最少写放大就会比较少。</p>
<p>我们的实现使用<code>kOldestSmallestSeqFirst</code>这个参数，按照RocksDB的设计。</p>
<p>RocksDB中关于合并的配置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cf_options.level_compaction_dynamic_level_bytes = true;</span><br><span class="line">opts.max_background_jobs = 6;</span><br><span class="line">options.bytes_per_sync = 1048576;</span><br><span class="line">options.compaction_pri = kMinOverlappingRatio;</span><br></pre></td></tr></table></figure>

<p>合并是在后台进行的，level0一般都比较小，允许键有重叠，保存在MemTable中。<br>当MemTable到达一定大小之后，会被转化成SSTable格式刷入磁盘持久化存储。</p>
<p>合并的参与者是两个level，挑选两个level的算法是一个可选项。<br>选择需要合并的两个level在LevelDB中是level相对越“满”越应该被选为要合并的对象，<br>也就是如果一个level的大小相对于目标大小的比例<code>total_size / target_size </code>最大那么就应该被选为合并对象。我们的理想情况应该是两个level合并之后文件的总大小减少最多，或者是让读放大减少。</p>
<p>选定上下两层level以后寻找overlap的部分进行归并排序。<br>   badger 是用 top[0] 和 bottom[:]进行比较<br>   如果是level0的话就是所有table，不是level0的话top就一个文件。</p>
<p>合并完成之后会删除不需要的文件。</p>
<h3 id="动态的Level尺寸"><a href="#动态的Level尺寸" class="headerlink" title="动态的Level尺寸"></a>动态的Level尺寸</h3><p><a target="_blank" rel="noopener" href="https://rocksdb.org/blog/2015/07/23/dynamic-level.html">dynamic level size</a> 。<br>如果用户数据20GB，那么L6的100GB可能使用不到那么大，这样就会导致写放大。<br>如果能动态调整level的大小，在初期把l0的直接写入L6。</p>
<p>例如，假设<code>max_bytes_for_level_multiplier=10</code>，<code>num_levels=6</code>，以及<code>max_bytes_for_level_base=10MB</code>。<br>level 1到5的目标尺寸开始为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[- - - - 10MB]</span><br></pre></td></tr></table></figure>
<p>因为level 1到4的目标尺寸不适用，所以它们将不会被使用。<br>直到Level 5的大小增长到超过10MB，例如11MB，我们将基础目标设置为level 4，现在目标看起来是这样的：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[- - - 1.1MB 11MB]</span><br></pre></td></tr></table></figure>
<p>随着数据的累积，尺寸目标根据level 5的实际数据进行调整。当level 5的数据达到50MB时，目标是这样的：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[- - - 5MB 50MB]</span><br></pre></td></tr></table></figure>
<p>直到level 5的实际大小超过100MB，例如101MB。如果我们继续保持level 4作为基础级别，<br>它的目标尺寸需要是10.1MB，这不符合目标尺寸范围。<br>所以现在我们将level 3作为目标尺寸，各级别的目标尺寸看起来是这样的：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[- - 1.01MB 10.1MB 101MB]</span><br></pre></td></tr></table></figure>
<p>同样，当level 5进一步增长时，所有级别的目标也增长，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[- - 5MB 50MB 500MB]</span><br></pre></td></tr></table></figure>
<p>直到level 5超过1000MB并变为1001MB，我们将level 2作为基础级别，<br>并将级别的目标尺寸设置为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[- 1.001MB 10.01MB 100.1MB 1001MB]</span><br></pre></td></tr></table></figure>
<p>依此类推…</p>
<p>具体可以参考<a target="_blank" rel="noopener" href="https://github.com/facebook/rocksdb/wiki/Leveled-Compaction">leveled compaction</a></p>
<h3 id="选择合并文件的边界"><a href="#选择合并文件的边界" class="headerlink" title="选择合并文件的边界"></a>选择合并文件的边界</h3><p>当选择文件以后我们需要划分出一个“干净的”边界（亦称<code>clean cut</code>或<code>atomic compaction unit</code>）。<br>我们始终要保持一个版本的恒定性质：level i 的同一个key的版本要高于level i+1 的版本。<br>下面的描述文件用b来代表，下标作为文件的标号，其中u记作上限，l记作下限，例如，u1代表b1的上限，l2代表b2的下限。</p>
<p>提取来自 <code>|compaction_files|</code> 的最大文件 b1，然后在 <code>|level_files|</code> 中搜索一个文件 b2， user_key(u1) = user_key(l2)。如果找到这样的文件 b2（称为边界文件），则将其添加到 <code>|compaction_files|</code> 中，然后使用这个新的上限再次进行搜索。</p>
<p>之所以这样做的原因是因为：如果存在两个块，b1=(l1, u1) 和 b2=(l2, u2)，并且 user_key(u1) = user_key(l2)，如果我们压缩了 b1 但没有压缩 b2，那么后续的获取操作将产生不正确的结果（我们保持的恒定的性质：同一个user key，i层的seqnum要高于i+1层的seqnum，并且seqnum降序排序的），因为它将在第 i 层返回来自 b2 的记录而不是来自 b1，也就是b2的seqnum的key把b1中seqnum更大的key给“盖”住了。</p>
<p>在LevelDB当中，文件会”向右“扩展，视图去包含边界上的user key的更低的seqnum（内部key的seqnum是降序排序的）。在其他基于LevelDB的数据库中加入了一些优化。</p>
<h3 id="重叠的分布"><a href="#重叠的分布" class="headerlink" title="重叠的分布"></a>重叠的分布</h3><p>但我们讨论写放大的时候就需要考虑重叠的分布，如果一个重叠的分布比较均匀，那么范围越大重叠的文件就会越多。<br>理想情况下我们会用重叠的大小来代表写放大的程度（这是LevelDB隐含的一个假设），比如一个a-j的范围，分布很均匀，重叠的文件依次是：[a#10,a#1],[b#10,b#1]。<br>但如果分布不是很均匀 a-j 对应的是 [a#10,e#1],[f#10,f#1]，这样写放大的问题就会比较小，而减少了存储放大。</p>
<p>RocksDB针对key的分布不均匀有一些优化，这里我们还是记住一个LevelDB的隐含考量：key的分布是均匀的，重叠越多~文件的写放大越大。</p>
<h3 id="Trivial-move"><a href="#Trivial-move" class="headerlink" title="Trivial move"></a>Trivial move</h3><p>“Trivial move” 是 LevelDB 在执行合并操作时的一个优化策略。如果一个文件在转移到下一层时，并不与下一层的任何文件有重叠，那么这个文件的移动就被认为是 “trivial” 的，即不需要进行复杂的合并操作，可以直接移动文件。这样做的好处是减少了不必要的数据复制，从而提高了整体的性能。另外补充一点：BadgerDB<br>并没有使用这个策略，因为BadgerDB希望即使是不存在key的合并，但是如果文件里面有删除的key的话，一次复制而不是移动可以减少文件的体积因为合并的过程会把删除的无效key直接删除。</p>
<p>为了利用这个”trivial”移动的优化还需要记录”grandparents”（也就是level i+2）层的重叠文件，LevelDB 通过判断待移动的文件是否与其 “grandparents level” 中的文件有<strong>大量</strong>重叠来决定是否进行 “trivial move”。如果没有大量重叠，就可以直接移动文件，而不需要合并。这种策略有效地减少了I/O操作和提高了性能，特别是在处理大量数据时。这个大量在LevelDB里面是<code>10*max_file_size</code>（这里的10是每个层级的倍数），默认是25MB。</p>
<h3 id="多路合并"><a href="#多路合并" class="headerlink" title="多路合并"></a>多路合并</h3><p>从level到level+1需要对多个文件进行归并排序输出一个新的level+1的文件。我们要定义一个多路的归并器来处理这个问题。</p>
<p>创建一个CompactionState保存TableBuilder和outputfile<br>保存最小的snapshot，如果没有snapshots就使用最新的sequence。</p>
<p>VersionSet MakeInputIterator</p>
<p>需要的Iterator的数量：</p>
<ul>
<li>level 0 合并成一个 +1 = 2</li>
<li>leve &gt; 0 的 size 1= size +1</li>
</ul>
<h3 id="文件的删除"><a href="#文件的删除" class="headerlink" title="文件的删除"></a>文件的删除</h3><p>到目前为止我们的数据库都没有涉及任何的文件删除的能力，所有的老文件都还存在着，当前使用的文件被记录在log当中。<br>当我们重启数据库的时候我们可以把这些多余的文件删除。</p>
<p>当文件不再被引用的时候既可以删除，或者当Version被释放的时候比较current和目录中的文件集中清楚。<br>后者在数据库重启的时候比较有用。</p>
<h4 id="FileMetadata"><a href="#FileMetadata" class="headerlink" title="FileMetadata"></a>FileMetadata</h4><p>通过重载Drop，可以实现在FileMetadata没有被引用的时候删除这个文件。</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> std::fs;</span><br><span class="line"><span class="keyword">use</span> std::path::PathBuf;</span><br><span class="line"><span class="keyword">use</span> std::rc::Rc;</span><br><span class="line"><span class="keyword">use</span> std::io;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">TempFile</span> &#123;</span><br><span class="line">    path: PathBuf,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">TempFile</span> &#123;</span><br><span class="line">    <span class="comment">// Creates a new TempFile instance for a given path.</span></span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">new</span>(path: PathBuf) <span class="punctuation">-&gt;</span> Rc&lt;<span class="keyword">Self</span>&gt; &#123;</span><br><span class="line">        Rc::<span class="title function_ invoke__">new</span>(TempFile &#123; path &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">Drop</span> <span class="keyword">for</span> <span class="title class_">TempFile</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">drop</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">        <span class="keyword">match</span> fs::<span class="title function_ invoke__">remove_file</span>(&amp;<span class="keyword">self</span>.path) &#123;</span><br><span class="line">            <span class="title function_ invoke__">Ok</span>(()) =&gt; <span class="built_in">println!</span>(<span class="string">&quot;File &#123;:?&#125; was deleted successfully.&quot;</span>, <span class="keyword">self</span>.path),</span><br><span class="line">            <span class="title function_ invoke__">Err</span>(e) =&gt; <span class="built_in">eprintln!</span>(<span class="string">&quot;Error deleting file &#123;:?&#125;: &#123;&#125;&quot;</span>, <span class="keyword">self</span>.path, e),</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() <span class="punctuation">-&gt;</span> io::<span class="type">Result</span>&lt;()&gt; &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Example: Creating a temporary file.</span></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">temp_path</span> = PathBuf::<span class="title function_ invoke__">from</span>(<span class="string">&quot;my_temp_file.txt&quot;</span>);</span><br><span class="line">    fs::<span class="title function_ invoke__">write</span>(&amp;temp_path, <span class="string">&quot;Temporary file contents&quot;</span>)?;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">temp_file</span> = TempFile::<span class="title function_ invoke__">new</span>(temp_path.<span class="title function_ invoke__">clone</span>());</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Now `temp_file` is an Rc&lt;TempFile&gt;. You can clone `temp_file` to create multiple references.</span></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">temp_file_clone</span> = Rc::<span class="title function_ invoke__">clone</span>(&amp;temp_file);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Both `temp_file` and `temp_file_clone` point to the same `TempFile` instance.</span></span><br><span class="line">    <span class="comment">// The TempFile instance will not be dropped (and the file will not be deleted)</span></span><br><span class="line">    <span class="comment">// until all Rc references are out of scope.</span></span><br><span class="line">    <span class="title function_ invoke__">drop</span>(temp_file);</span><br><span class="line">    <span class="built_in">assert_eq!</span>(fs::<span class="title function_ invoke__">metadata</span>(<span class="string">&quot;my_temp_file.txt&quot;</span>).<span class="title function_ invoke__">is_ok</span>(), <span class="literal">true</span>);</span><br><span class="line">    <span class="comment">// Here you could check if the file still exists to verify it was deleted,</span></span><br><span class="line">    <span class="comment">// but normally you wouldn&#x27;t need to do this in your actual application.</span></span><br><span class="line">    <span class="title function_ invoke__">drop</span>(temp_file_clone);</span><br><span class="line">    <span class="built_in">assert_eq!</span>(fs::<span class="title function_ invoke__">metadata</span>(<span class="string">&quot;my_temp_file.txt&quot;</span>).<span class="title function_ invoke__">is_ok</span>(), <span class="literal">false</span>);</span><br><span class="line"></span><br><span class="line">    <span class="title function_ invoke__">Ok</span>(())</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><h3 id="Range-Delete"><a href="#Range-Delete" class="headerlink" title="Range Delete"></a>Range Delete</h3><p>在一些将键值数据库作为基础数据库的一些分布式数据库中涉及到删表操作。<br>Range Delete 会在 sstable 的 meta block 标记。</p>
<h3 id="干净的边界"><a href="#干净的边界" class="headerlink" title="干净的边界"></a>干净的边界</h3><p>TODO</p>
<h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><p>TODO</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>实现LevelDB的过程中，体会到了Rus的很多语法糖和特性，和Go还有Python之间都有相互借鉴，是一个不吝啬引入语言语法复杂性的语言。<br>在于内存安全方面确实也带了一种新的思考。内容不算完全写完，有的甚至没有实现，有时间在继续补充下去吧。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2014 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">ggaaooppeenngg</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.umd.js" integrity="sha256-a+H7FYzJv6oU2hfsfDGM2Ohw/cR9v+hPfxHCLdmCrE8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  



  <script src="/js/third-party/fancybox.js"></script>



  




<script class="next-config" data-name="disqus" type="application/json">{"enable":true,"shortname":"ggaaooppeenngg","count":true,"i18n":{"disqus":"disqus"}}</script>
<script src="/js/third-party/comments/disqus.js"></script>

</body>
</html>
