<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="_85tctgPWrqH2EPVuuD5IT6KE-tW8nH0hTISJDMnShg">
  <meta name="baidu-site-verification" content="bb16c5b1fd3302c18e0015bef11eea42">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"ggaaooppeenngg.github.io","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.22.0","exturl":false,"sidebar":{"position":"right","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12,"onmobile":false},"hljswrap":true,"copycode":{"enable":true,"style":"default"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="为什么计算机科学是无限的但生命是有限的">
<meta property="og:type" content="website">
<meta property="og:title" content="ggaaooppeenngg">
<meta property="og:url" content="https://ggaaooppeenngg.github.io/page/3/index.html">
<meta property="og:site_name" content="ggaaooppeenngg">
<meta property="og:description" content="为什么计算机科学是无限的但生命是有限的">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="ggaaooppeenngg">
<meta property="article:tag" content="ggaaooppeenngg,kernel,sysml,golang,python,rust">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://ggaaooppeenngg.github.io/page/3/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/3/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>ggaaooppeenngg</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-62096626-1"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"UA-62096626-1","only_pageview":false,"measure_protocol_api_secret":null}</script>
  <script src="/js/third-party/analytics/google-analytics.js"></script>

  <script src="/js/third-party/analytics/baidu-analytics.js"></script>
  <script async src="https://hm.baidu.com/hm.js?bb16c5b1fd3302c18e0015bef11eea42"></script>







  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">ggaaooppeenngg</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">为什么计算机科学是无限的但生命是有限的</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签<span class="badge">134</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="th fa-fw"></i>分类<span class="badge">14</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档<span class="badge">78</span></a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">ggaaooppeenngg</p>
  <div class="site-description" itemprop="description">为什么计算机科学是无限的但生命是有限的</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">78</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">134</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/ggaaooppeenngg" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;ggaaooppeenngg" rel="noopener me" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:peng.gao.dut@gmail.com" title="E-Mail → mailto:peng.gao.dut@gmail.com" rel="noopener me" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ggaaooppeenngg.github.io/zh-CN/2022/09/06/%E4%BD%BF%E7%94%A8ebpf%E5%AF%B9oomkill%E8%BF%9B%E8%A1%8C%E6%8E%A2%E6%B5%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ggaaooppeenngg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ggaaooppeenngg">
      <meta itemprop="description" content="为什么计算机科学是无限的但生命是有限的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ggaaooppeenngg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/zh-CN/2022/09/06/%E4%BD%BF%E7%94%A8ebpf%E5%AF%B9oomkill%E8%BF%9B%E8%A1%8C%E6%8E%A2%E6%B5%8B/" class="post-title-link" itemprop="url">使用ebpf对oomkill进行探测</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-09-06 17:48:18" itemprop="dateCreated datePublished" datetime="2022-09-06T17:48:18+08:00">2022-09-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-28 18:39:05" itemprop="dateModified" datetime="2025-03-28T18:39:05+08:00">2025-03-28</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/zh-CN/2022/09/06/%E4%BD%BF%E7%94%A8ebpf%E5%AF%B9oomkill%E8%BF%9B%E8%A1%8C%E6%8E%A2%E6%B5%8B/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="zh-CN/2022/09/06/使用ebpf对oomkill进行探测/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>ebpf是内核当中一个非常重要的功能，简单来说就是以虚拟机的形式提供一种在内核中执行嵌入字节码的能力。<br>ebpf定义的指令集也非常简答，但是写起来比较麻烦所以作为工具提供了libbpf和bpf-tool。<br>用户可以通过写C的形式写ebpf程序嵌入到内核中，同时在用户态进行交互，用户态的程序没有语言限制。<br>ebpf特性的对应内核版本列表在<a target="_blank" rel="noopener" href="https://github.com/iovisor/bcc/blob/master/docs/kernel-versions.md">这</a>，后面例子中的ringbuffer map是要内核版本在5.8以上。<br>ebpf的架构和工具链的一个比较完整的文档是cilium的一个<a target="_blank" rel="noopener" href="https://docs.cilium.io/en/stable/bpf/">文档</a>。</p>
<p><code>vmlinux.h</code>是通过bpftool生成的一个虚拟<a target="_blank" rel="noopener" href="https://github.com/libbpf/libbpf-bootstrap/blob/330abf58d8e20476583ed7c9c90a46fe906e4d7a/examples/rust/tracecon/README.md">头文件</a>，用于访问内核数据结构。</p>
<p>libbpf 和 bpftool 都是在内核的代码仓库里面开发的。对应的目录分别是<code>tools/lib/bpf</code>和<code>tools/bpf</code>，帮助用户用c开发和调试ebpf程序。<br>相当于说bpftool是ebpf的调试和观测工具，libbpf是一提供给开发者的ebpf库。</p>
<p>在<code>bpf_herplers.h</code>有一个section的定义<code>SEC</code>用来决定在ebpf的<code>.o</code>对象文件中的位置，以及一些功能。<br>比如<code>SEC(kprobe/xxx)</code>就代表修饰的程序会嵌入到内核函数的调用中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> * Helper macro to place programs, maps, license in</span><br><span class="line"> * different sections in elf_bpf file. Section names</span><br><span class="line"> * are interpreted by libbpf depending on the context (BPF programs, BPF maps,</span><br><span class="line"> * extern variables, etc).</span><br><span class="line"> * To allow use of SEC() with externs (e.g., for extern .maps declarations),</span><br><span class="line"> * make sure __attribute__((unused)) doesn&#x27;t trigger compilation warning.</span><br><span class="line"> */</span><br><span class="line">#define SEC(name) \</span><br><span class="line">        _Pragma(&quot;GCC diagnostic push&quot;)                                      \</span><br><span class="line">        _Pragma(&quot;GCC diagnostic ignored \&quot;-Wignored-attributes\&quot;&quot;)          \</span><br><span class="line">        __attribute__((section(name), used))                                \</span><br><span class="line">        _Pragma(&quot;GCC diagnostic pop&quot;)                                       \</span><br></pre></td></tr></table></figure>

<p>libbpf.c 有对应的SEC的定义。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#define SEC_DEF(sec_pfx, ptype, ...) &#123;                                      \</span><br><span class="line">        .sec = sec_pfx,                                                     \</span><br><span class="line">        .len = sizeof(sec_pfx) - 1,                                         \</span><br><span class="line">        .prog_type = BPF_PROG_TYPE_##ptype,                                 \</span><br><span class="line">        __VA_ARGS__                                                         \</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">static const struct bpf_sec_def section_defs[] = &#123;</span><br><span class="line">          BPF_PROG_SEC(&quot;socket&quot;,                  BPF_PROG_TYPE_SOCKET_FILTER),</span><br><span class="line">          BPF_EAPROG_SEC(&quot;sk_reuseport/migrate&quot;,  BPF_PROG_TYPE_SK_REUSEPORT,</span><br><span class="line">                                                  BPF_SK_REUSEPORT_SELECT_OR_MIGRATE),</span><br><span class="line">          BPF_EAPROG_SEC(&quot;sk_reuseport&quot;,          BPF_PROG_TYPE_SK_REUSEPORT,</span><br><span class="line">                                                  BPF_SK_REUSEPORT_SELECT),</span><br><span class="line">          SEC_DEF(&quot;kprobe/&quot;, KPROBE,</span><br><span class="line">                  .attach_fn = attach_kprobe),</span><br><span class="line">          BPF_PROG_SEC(&quot;uprobe/&quot;,                 BPF_PROG_TYPE_KPROBE),</span><br><span class="line">          SEC_DEF(&quot;kretprobe/&quot;, KPROBE,</span><br><span class="line">                  .attach_fn = attach_kprobe),</span><br><span class="line">          BPF_PROG_SEC(&quot;uretprobe/&quot;,              BPF_PROG_TYPE_KPROBE),</span><br><span class="line">          BPF_PROG_SEC(&quot;classifier&quot;,              BPF_PROG_TYPE_SCHED_CLS),</span><br><span class="line">          BPF_PROG_SEC(&quot;action&quot;,                  BPF_PROG_TYPE_SCHED_ACT),</span><br><span class="line">          SEC_DEF(&quot;tracepoint/&quot;, TRACEPOINT,</span><br><span class="line">                  .attach_fn = attach_tp),</span><br><span class="line">          SEC_DEF(&quot;tp/&quot;, TRACEPOINT,</span><br><span class="line">                  .attach_fn = attach_tp),</span><br><span class="line">          SEC_DEF(&quot;raw_tracepoint/&quot;, RAW_TRACEPOINT,</span><br><span class="line">                  .attach_fn = attach_raw_tp),</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>kprobe的attach方式。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">struct bpf_link *bpf_program__attach_kprobe(struct bpf_program *prog,</span><br><span class="line">                                            bool retprobe,</span><br><span class="line">                                            const char *func_name)</span><br><span class="line">&#123;</span><br><span class="line">        char errmsg[STRERR_BUFSIZE];</span><br><span class="line">        struct bpf_link *link;</span><br><span class="line">        int pfd, err;</span><br><span class="line"></span><br><span class="line">        pfd = perf_event_open_probe(false /* uprobe */, retprobe, func_name,</span><br><span class="line">                                    0 /* offset */, -1 /* pid */);</span><br><span class="line">        if (pfd &lt; 0) &#123;</span><br><span class="line">                pr_warn(&quot;prog &#x27;%s&#x27;: failed to create %s &#x27;%s&#x27; perf event: %s\n&quot;,</span><br><span class="line">                        prog-&gt;name, retprobe ? &quot;kretprobe&quot; : &quot;kprobe&quot;, func_name,</span><br><span class="line">                        libbpf_strerror_r(pfd, errmsg, sizeof(errmsg)));</span><br><span class="line">                return libbpf_err_ptr(pfd);</span><br><span class="line">        &#125;</span><br><span class="line">        link = bpf_program__attach_perf_event(prog, pfd);</span><br><span class="line">        err = libbpf_get_error(link);</span><br><span class="line">        if (err) &#123;</span><br><span class="line">                close(pfd);</span><br><span class="line">                pr_warn(&quot;prog &#x27;%s&#x27;: failed to attach to %s &#x27;%s&#x27;: %s\n&quot;,</span><br><span class="line">                        prog-&gt;name, retprobe ? &quot;kretprobe&quot; : &quot;kprobe&quot;, func_name,</span><br><span class="line">                        libbpf_strerror_r(err, errmsg, sizeof(errmsg)));</span><br><span class="line">                return libbpf_err_ptr(err);</span><br><span class="line">        &#125;</span><br><span class="line">        return link;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>根据函数名用<code>perf_event_open_probe</code>注入<code>program</code>。</p>
<p>内核对于oom的处理主要在<code>mm/oom_kill.c</code>中。<br>oom的触发就是在内存无法分配的时候，选择一个最“差”的进程发送kill信号。<br><code>oom_kill_process</code>这个函数是主要入口，定义是<code>static void oom_kill_process(struct oom_control *oc, const char *message)</code>，<br>其中<code>oc-&gt;victim</code>是要被杀掉的进程，如果有cgroup会把相同内存cgroup的进程都杀掉，所以如果要检测一个进程的oom可以通过检测这个函数的参数做到。</p>
<p>下面这段就是OOM的时候dmesg看到的信息。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">/* Get a reference to safely compare mm after task_unlock(victim) */</span><br><span class="line">mm = victim-&gt;mm;</span><br><span class="line">mmgrab(mm);</span><br><span class="line"></span><br><span class="line">/* Raise event before sending signal: task reaper must see this */</span><br><span class="line">count_vm_event(OOM_KILL);</span><br><span class="line">memcg_memory_event_mm(mm, MEMCG_OOM_KILL);</span><br><span class="line"></span><br><span class="line">/*</span><br><span class="line"> * We should send SIGKILL before granting access to memory reserves</span><br><span class="line"> * in order to prevent the OOM victim from depleting the memory</span><br><span class="line"> * reserves from the user space under its control.</span><br><span class="line"> */</span><br><span class="line">do_send_sig_info(SIGKILL, SEND_SIG_PRIV, victim, PIDTYPE_TGID);</span><br><span class="line">mark_oom_victim(victim);</span><br><span class="line">pr_err(&quot;%s: Killed process %d (%s) total-vm:%lukB, anon-rss:%lukB, file-rss:%lukB, shmem-rss:%lukB, UID:%u pgtables:%lukB oom_score_adj:%hd\n&quot;,</span><br><span class="line">        message, task_pid_nr(victim), victim-&gt;comm, K(mm-&gt;total_vm),</span><br><span class="line">        K(get_mm_counter(mm, MM_ANONPAGES)),</span><br><span class="line">        K(get_mm_counter(mm, MM_FILEPAGES)),</span><br><span class="line">        K(get_mm_counter(mm, MM_SHMEMPAGES)),</span><br><span class="line">        from_kuid(&amp;init_user_ns, task_uid(victim)),</span><br><span class="line">        mm_pgtables_bytes(mm) &gt;&gt; 10, victim-&gt;signal-&gt;oom_score_adj);</span><br><span class="line">task_unlock(victim);</span><br></pre></td></tr></table></figure>

<p>对于内核函数的检测需要ebpf当中的<a target="_blank" rel="noopener" href="https://docs.kernel.org/trace/kprobes.html">kprobe</a>的能力。<br>kprobe类似单步调试的能力，在函数入口插入一个breakpoint，然后通过trap让执行流转到注册的ebpf的程序。</p>
<p>oomkill的内核中的ebpf程序主要参考datadog的<a target="_blank" rel="noopener" href="https://github.com/DataDog/datadog-agent/blob/main/pkg/collector/corechecks/ebpf/c/runtime/oom-kill-kern.c">agent</a>的实现。<br>框架程序主要参考cilium/ebpf当中的<a target="_blank" rel="noopener" href="https://github.com/cilium/ebpf/tree/master/examples/ringbuffer">例子</a>。</p>
<p><code>PT_REGS_PARM1</code>是一个宏可以帮助读取内核函数的参数，因为按照约定ebpf都是通过寄存器传参的，所以其实返回的是第1个参数对应的寄存器。<code>bpf_probe_read</code>是一个用于读取内存到ebpf程序中的辅助函数。<br>所以oomkill的ebpf实现的内核中的代码就比较简单，嵌入oom_kill_process的函数调用，或者要被结束的进程复制出进程的pid和command，然后通过类型为<code>BPF_MAP_TYPE_RINGBUF</code>的map发送event。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">// +build ignore</span><br><span class="line"></span><br><span class="line">#include &quot;vmlinux.h&quot;</span><br><span class="line">#include &quot;bpf_helpers.h&quot;</span><br><span class="line">#include &quot;bpf_tracing.h&quot;</span><br><span class="line"></span><br><span class="line">char __license[] SEC(&quot;license&quot;) = &quot;Dual MIT/GPL&quot;;</span><br><span class="line"></span><br><span class="line">struct event &#123;</span><br><span class="line">	u32 pid;</span><br><span class="line">	u8 comm[80];</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">struct &#123;</span><br><span class="line">	__uint(type, BPF_MAP_TYPE_RINGBUF);</span><br><span class="line">	__uint(max_entries, 1 &lt;&lt; 24);</span><br><span class="line">&#125; events SEC(&quot;.maps&quot;);</span><br><span class="line"></span><br><span class="line">// Force emitting struct event into the ELF.</span><br><span class="line">const struct event *unused __attribute__((unused));</span><br><span class="line"></span><br><span class="line">SEC(&quot;kprobe/oom_kill_process&quot;)</span><br><span class="line">int kprobe_oom_kill_process(struct pt_regs *ctx) &#123;</span><br><span class="line">	struct event *task_info;</span><br><span class="line">	struct oom_control *oc = (struct oom_control *)PT_REGS_PARM1(ctx);</span><br><span class="line"></span><br><span class="line">	task_info = bpf_ringbuf_reserve(&amp;events, sizeof(struct event), 0);</span><br><span class="line"></span><br><span class="line">	if (!task_info) &#123;</span><br><span class="line">		return 0;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	struct task_struct *p;</span><br><span class="line">        bpf_probe_read(&amp;p, sizeof(p), &amp;oc-&gt;chosen);</span><br><span class="line">	bpf_probe_read(&amp;task_info-&gt;pid, sizeof(task_info-&gt;pid), &amp;p-&gt;pid);</span><br><span class="line">	bpf_probe_read(&amp;task_info-&gt;comm, sizeof(task_info-&gt;comm), (void *)&amp;p-&gt;comm);</span><br><span class="line"></span><br><span class="line">	bpf_ringbuf_submit(task_info, 0);</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>用户态的程序也比较简单，把ebpf的对象文件attach以后读取ringbuffer别解析event。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line">package main</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">	&quot;bytes&quot;</span><br><span class="line">	&quot;encoding/binary&quot;</span><br><span class="line">	&quot;errors&quot;</span><br><span class="line">	&quot;fmt&quot;</span><br><span class="line">	&quot;log&quot;</span><br><span class="line">	&quot;os&quot;</span><br><span class="line">	&quot;os/signal&quot;</span><br><span class="line">	&quot;syscall&quot;</span><br><span class="line"></span><br><span class="line">	&quot;github.com/cilium/ebpf/link&quot;</span><br><span class="line">	&quot;github.com/cilium/ebpf/ringbuf&quot;</span><br><span class="line">	&quot;github.com/cilium/ebpf/rlimit&quot;</span><br><span class="line">	&quot;golang.org/x/sys/unix&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">//go:generate go run github.com/cilium/ebpf/cmd/bpf2go -cc clang -type event -target amd64 bpf oom_kill_kernel.c</span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line">	// Name of the kernel function to trace.</span><br><span class="line">	fn := &quot;oom_kill_process&quot;</span><br><span class="line"></span><br><span class="line">	// Subscribe to signals for terminating the program.</span><br><span class="line">	stopper := make(chan os.Signal, 1)</span><br><span class="line">	signal.Notify(stopper, os.Interrupt, syscall.SIGTERM)</span><br><span class="line"></span><br><span class="line">	// Allow the current process to lock memory for eBPF resources.</span><br><span class="line">	if err := rlimit.RemoveMemlock(); err != nil &#123;</span><br><span class="line">		log.Fatal(err)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	// Load pre-compiled programs and maps into the kernel.</span><br><span class="line">	objs := bpfObjects&#123;&#125;</span><br><span class="line">	if err := loadBpfObjects(&amp;objs, nil); err != nil &#123;</span><br><span class="line">		log.Fatalf(&quot;loading objects: %v&quot;, err)</span><br><span class="line">	&#125;</span><br><span class="line">	defer objs.Close()</span><br><span class="line"></span><br><span class="line">	fmt.Println(&quot;probe&quot;)</span><br><span class="line">	// Open a Kprobe at the entry point of the kernel function and attach the</span><br><span class="line">	// pre-compiled program. Each time the kernel function enters, the program</span><br><span class="line">	// will emit an event containing pid and command of the execved task.</span><br><span class="line">	kp, err := link.Kprobe(fn, objs.KprobeOomKillProcess, nil)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		log.Fatalf(&quot;opening kprobe: %s&quot;, err)</span><br><span class="line">	&#125;</span><br><span class="line">	defer kp.Close()</span><br><span class="line">	fmt.Println(&quot;attach done&quot;)</span><br><span class="line"></span><br><span class="line">	// Open a ringbuf reader from userspace RINGBUF map described in the</span><br><span class="line">	// eBPF C program.</span><br><span class="line">	rd, err := ringbuf.NewReader(objs.Events)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		log.Fatalf(&quot;opening ringbuf reader: %s&quot;, err)</span><br><span class="line">	&#125;</span><br><span class="line">	defer rd.Close()</span><br><span class="line"></span><br><span class="line">	// Close the reader when the process receives a signal, which will exit</span><br><span class="line">	// the read loop.</span><br><span class="line">	go func() &#123;</span><br><span class="line">		&lt;-stopper</span><br><span class="line"></span><br><span class="line">		if err := rd.Close(); err != nil &#123;</span><br><span class="line">			log.Fatalf(&quot;closing ringbuf reader: %s&quot;, err)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;()</span><br><span class="line"></span><br><span class="line">	log.Println(&quot;Waiting for events..&quot;)</span><br><span class="line"></span><br><span class="line">	// bpfEvent is generated by bpf2go.</span><br><span class="line">	var event bpfEvent</span><br><span class="line">	for &#123;</span><br><span class="line">		record, err := rd.Read()</span><br><span class="line">		if err != nil &#123;</span><br><span class="line">			if errors.Is(err, ringbuf.ErrClosed) &#123;</span><br><span class="line">				log.Println(&quot;Received signal, exiting..&quot;)</span><br><span class="line">				return</span><br><span class="line">			&#125;</span><br><span class="line">			log.Printf(&quot;reading from reader: %s&quot;, err)</span><br><span class="line">			continue</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		// Parse the ringbuf event entry into a bpfEvent structure.</span><br><span class="line">		if err := binary.Read(bytes.NewBuffer(record.RawSample), binary.LittleEndian, &amp;event); err != nil &#123;</span><br><span class="line">			log.Printf(&quot;parsing ringbuf event: %s&quot;, err)</span><br><span class="line">			continue</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		log.Printf(&quot;pid: %d\tcomm: %s\n&quot;, event.Pid, unix.ByteSliceToString(event.Comm[:]))</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>使用一个python脚本进行测试OOM。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a=&quot;111111111111111&quot;</span><br><span class="line">while True:</span><br><span class="line">    a+=a</span><br></pre></td></tr></table></figure>
<p>最后运行结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">probe</span><br><span class="line">attach done</span><br><span class="line">Waiting for events..</span><br><span class="line">pid: 16541 comm: python</span><br></pre></td></tr></table></figure>

<p>ebpf的能力还不止于此，业界做了很多流量控制，性能监控的实践，包括calico用ebpf的实现替代kube-proxy，waeve-scope 用ebpf记录tcp连接，cilium 也用eBPF，结合了tc和XDP。datadog-agent 也是使用了ebpf做一些监控，上面的oomkill的例子也是参考datadog的。ebpf能够让linux内核变得更动态更灵活。甚至有一种说法是eBPF让Linux内核正在变成微内核。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ggaaooppeenngg.github.io/zh-CN/2021/12/02/Knative-%E6%9E%B6%E6%9E%84%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ggaaooppeenngg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ggaaooppeenngg">
      <meta itemprop="description" content="为什么计算机科学是无限的但生命是有限的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ggaaooppeenngg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/zh-CN/2021/12/02/Knative-%E6%9E%B6%E6%9E%84%E5%88%86%E6%9E%90/" class="post-title-link" itemprop="url">Knative 架构分析</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-12-02 14:25:51" itemprop="dateCreated datePublished" datetime="2021-12-02T14:25:51+08:00">2021-12-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-28 18:39:05" itemprop="dateModified" datetime="2025-03-28T18:39:05+08:00">2025-03-28</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/zh-CN/2021/12/02/Knative-%E6%9E%B6%E6%9E%84%E5%88%86%E6%9E%90/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="zh-CN/2021/12/02/Knative-架构分析/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Knative主要有两个重要的部分，一个是自动扩展一个是流量切换，并且目前的设计已经和istio是相对独立的了。</p>
<p>Knative的service和k8s的service容易混淆，所以用sks指代knative的service，然后service本身是指k8s本身的service。</p>
<p>sks的revision创建的时候会有两个service，一个是 public service，一个是 private service，如果用istio的话会看到一个和ingressgateway关联的有externalname的service，这个service是和ingress实现相关的。主要的实现还是public和private两个service，实现和具体的ingress的实现是独立的。</p>
<p>Private service 对应的是真实的pod的endpoints，public service 有两种模式一个serve模式，一个是proxy模式。当public service出于proxy模式时，其endpoints指向的是activator，当处于serve模式时endpoints指向的是private service所指向的后端endpoints。</p>
<p>在scale从0到1的过程中，会先阻塞在activator上，当有pod启动以后，还是会保持proxy模式，直到超过burst才会切换到private service的endpoints上。在从1到0的过程中会再切换回activator，直到有新的请求到来再触发pod的启动。</p>
<h2 id="activator"><a href="#activator" class="headerlink" title="activator"></a>activator</h2><p>Throttler</p>
<blockquote>
<p>Throttler is the interface that Handler calls to Try to proxy the user request</p>
</blockquote>
<p>Health Handler 注册用于 kubelet 做 readiness 和 health probe 的接口，返回statSink的状态，收到 signal term 的时候就开始返回500。</p>
<p>Network probe handler<br>knative组件用来 probe 的接口，在header里面会有区分。</p>
<p>Context handler<br>把header中的revision的name和namespace注入的context当中</p>
<p>Metric Handler<br>收集request的qps等metrics的信息。</p>
<p>Log Handler<br>请求日志</p>
<p>Tracing Handler<br>Trace spans</p>
<p>Cocurrency report Handler</p>
<p>记录请求信息，这些信息会被reporter上报</p>
<p>Activator handler</p>
<p>过一层 throttler 进行proxy，如果没受限制就会proxy request。</p>
<p>Throttler 会根据revID创建一个throttler，revision如果存在的话就会创建throttler。（revision肯定是一直在的哪怕没有起pod）如果超过revision的并发数就会退出。</p>
<p>Throttler 会try对应的revisionThrottler的pods然后转发过去。</p>
<h2 id="controller"><a href="#controller" class="headerlink" title="controller"></a>controller</h2><p>Controller 主要是对用户使用的几个CRD的同步：Service、Route、Revision、Configuration。</p>
<h2 id="net-istio"><a href="#net-istio" class="headerlink" title="net-istio"></a>net-istio</h2><p>Ingress 的一种实现</p>
<p>internal 的 ingress创建一个 ingress virtualservice 并且将gate指定为isito-gateway，其他的ingress实现其实类似，只是目前没有traefik的支持。knative有没有istio现在是没啥区别了。</p>
<h2 id="domain-mappings"><a href="#domain-mappings" class="headerlink" title="domain mappings"></a>domain mappings</h2><p>一个用于扩展域名的CRD DomainClaim，会根据domainclaim创建一个ingress。</p>
<h2 id="queue-proxy"><a href="#queue-proxy" class="headerlink" title="queue-proxy"></a>queue-proxy</h2><p>tracing metrics breaker 都是正常操作。本质是个sidecar层面的反向代理。</p>
<p>Metrcis</p>
<p>Admin</p>
<p>有一个给cocurrency endpoint发 paused 和 resumed 的回调。</p>
<p>Main</p>
<p>Proxy handler 收集 request in 和 request out。</p>
<h2 id="自定义默认域名的问题"><a href="#自定义默认域名的问题" class="headerlink" title="自定义默认域名的问题"></a>自定义默认域名的问题</h2><p>kubectl get  cm config-network -n knative-serving -o yaml 可以看到默认的模板去修改他</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">domain-template: &quot;&#123;&#123;.Name&#125;&#125;.&#123;&#123;.Namespace&#125;&#125;.&#123;&#123;.Domain&#125;&#125;&quot;</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ggaaooppeenngg.github.io/zh-CN/2021/10/26/Go%E7%9A%84WASM%E8%BF%90%E8%A1%8C%E6%97%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ggaaooppeenngg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ggaaooppeenngg">
      <meta itemprop="description" content="为什么计算机科学是无限的但生命是有限的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ggaaooppeenngg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/zh-CN/2021/10/26/Go%E7%9A%84WASM%E8%BF%90%E8%A1%8C%E6%97%B6/" class="post-title-link" itemprop="url">Go的WASM运行时</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-10-26 15:56:55" itemprop="dateCreated datePublished" datetime="2021-10-26T15:56:55+08:00">2021-10-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-28 18:39:05" itemprop="dateModified" datetime="2025-03-28T18:39:05+08:00">2025-03-28</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/zh-CN/2021/10/26/Go%E7%9A%84WASM%E8%BF%90%E8%A1%8C%E6%97%B6/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="zh-CN/2021/10/26/Go的WASM运行时/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>WASM 作为一种通用字节码可以让很多语言编译成 WASM 跑在沙箱VM环境当中：跑在浏览器的 V8 引擎上，让别的语言可以写前端、<br>构建成 Istio 的代理 Envoy 的 WASM 插件形成一些过滤器或者日志插件（有点像内核的 eBPF）、作为各种语言的浇水层（让Rust调用Go编译出的WASM）。</p>
<blockquote>
<p>The major problem is that, whilst the Go compiler supports WebAssembly, it does not support WASI (WebAssembly System Interface). It generates an ABI that is deeply tied to JavaScript, and one needs to use the wasm_exec.js file provided by the Go toolchain, which doesn’t work outside a JavaScript host.</p>
</blockquote>
<p>Go 的 WASM 目前没有支持 WASI，类似于没有 native 的系统调用，所以很多文件、网络的请求不能通过系统执行，目前只能跑在浏览器通过浏览器的接口执行。<br><a target="_blank" rel="noopener" href="https://github.com/tinygo-org/tinygo">TinyGo</a> 是一个支持比较好的 WASM 的 Go 的运行时，有些需要WASI的项目就需要TinyGo来构建。</p>
<h2 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h2><p>WASM 是一个单线程的环境，js 是一个基于事件的模型，对于 goroutine 的调度是如何进行的，本着这个好奇研究了一下 Go 本身的 WASM 运行时。比如下面这段代码就明确了 Go 的 WASM 没有多线程也就没有跑 sysmon。<br>没有sysmon就相当于sysmon的forcegc触发gc的部分也没有，只能靠主动GC和内存分配的时候触发超过阈值开始gc。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> GOARCH != <span class="string">&quot;wasm&quot;</span> &#123; <span class="comment">// no threads on wasm yet, so no sysmon</span></span><br><span class="line">        <span class="comment">// For runtime_syscall_doAllThreadsSyscall, we</span></span><br><span class="line">        <span class="comment">// register sysmon is not ready for the world to be</span></span><br><span class="line">        <span class="comment">// stopped.</span></span><br><span class="line">        atomic.Store(&amp;sched.sysmonStarting, <span class="number">1</span>)</span><br><span class="line">        systemstack(<span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">                newm(sysmon, <span class="literal">nil</span>, <span class="number">-1</span>)</span><br><span class="line">        &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在这里回忆一下 GMP 的关系。P的数量由启动时环境变量 $GOMAXPROCS 或者是由 runtime 的方法 GOMAXPROCS() 决定。这意味着在程序执行的任意时刻都只有 $GOMAXPROCS 个 goroutine 在同时运行。<br>M的数量可以通过 runtime/debug 中的 SetMaxThreads 函数，设置 M 的最大数量一个 M 阻塞了，会创建新的 M。<br>M 与 P 的数量没有绝对关系，一个 M 阻塞，P 就会去创建或者切换另一个 M，所以，即使 P 的默认数量是 1，也有可能会创建很多个 M 出来。<br>在确定了 P 的最大数量 n 后，运行时系统会根据这个数量创建 n 个 P。<br>没有足够的 M 来关联 P 并运行其中的可运行的 G。比如所有的 M 此时都阻塞住了，而 P 中还有很多就绪任务，就会去寻找空闲的 M，而没有空闲的，就会去创建新的 M。</p>
<p>这个关系在对应的代码里面也有体现，在 osinit 的时候会强制将 P 设置为1，newosproc 也是空的，无法启动新进程。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">osinit</span><span class="params">()</span></span> &#123;</span><br><span class="line">        ncpu = <span class="number">1</span></span><br><span class="line">        getg().m.procid = <span class="number">2</span></span><br><span class="line">        physPageSize = <span class="number">64</span> * <span class="number">1024</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>没有 sysmon 也就没有异步抢占，只能靠 goroutine 之间的协作式抢占来切换 goroutine。</p>
<p>在 schedule 里面也有一段专用的调度逻辑。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// wasm only:</span></span><br><span class="line"><span class="comment">// If a callback returned and no other goroutine is awake,</span></span><br><span class="line"><span class="comment">// then wake event handler goroutine which pauses execution</span></span><br><span class="line"><span class="comment">// until a callback was triggered.</span></span><br><span class="line">gp, otherReady := beforeIdle(now, pollUntil)</span><br><span class="line"><span class="keyword">if</span> gp != <span class="literal">nil</span> &#123;</span><br><span class="line">        casgstatus(gp, _Gwaiting, _Grunnable)</span><br><span class="line">        <span class="keyword">if</span> trace.enabled &#123;</span><br><span class="line">                traceGoUnpark(gp, <span class="number">0</span>)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> gp, <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> otherReady &#123;</span><br><span class="line">        <span class="keyword">goto</span> top</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>等于是在 wasm 中在找不到 G 的时候会启动一个 pause goroutine 占住当前的 P。</p>
<p>Lock_js 有 handle event 的逻辑。</p>
<h2 id="内存分配"><a href="#内存分配" class="headerlink" title="内存分配"></a>内存分配</h2><p>通过 WASM 的内存分配接口代替 linux 里面的 mmap 接管过来做内存分配。</p>
<h2 id="系统调用"><a href="#系统调用" class="headerlink" title="系统调用"></a>系统调用</h2><p>系统调用是使用 js 实现的，而且也不是像 linux 那种完整一套系统调用这个可能需要 WASI 的支持。<br>没有系统调用 M 也不会阻塞，等于是一个完全的单 P 单 M 多 G 的模型。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> jsProcess = js.Global().Get(<span class="string">&quot;process&quot;</span>)</span><br><span class="line"><span class="keyword">var</span> jsFS = js.Global().Get(<span class="string">&quot;fs&quot;</span>)</span><br><span class="line"><span class="keyword">var</span> constants = jsFS.Get(<span class="string">&quot;constants&quot;</span>)</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ggaaooppeenngg.github.io/zh-CN/2021/07/19/%E5%9C%A8goroutine%E4%B8%8A%E5%88%9B%E5%BB%BA%E5%8D%8F%E7%A8%8Bgogoroutine/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ggaaooppeenngg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ggaaooppeenngg">
      <meta itemprop="description" content="为什么计算机科学是无限的但生命是有限的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ggaaooppeenngg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/zh-CN/2021/07/19/%E5%9C%A8goroutine%E4%B8%8A%E5%88%9B%E5%BB%BA%E5%8D%8F%E7%A8%8Bgogoroutine/" class="post-title-link" itemprop="url">在goroutine上创建协程gogoroutine</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-19 14:14:54" itemprop="dateCreated datePublished" datetime="2021-07-19T14:14:54+08:00">2021-07-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-28 18:39:05" itemprop="dateModified" datetime="2025-03-28T18:39:05+08:00">2025-03-28</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/zh-CN/2021/07/19/%E5%9C%A8goroutine%E4%B8%8A%E5%88%9B%E5%BB%BA%E5%8D%8F%E7%A8%8Bgogoroutine/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="zh-CN/2021/07/19/在goroutine上创建协程gogoroutine/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>目前实现的版本是参照<a target="_blank" rel="noopener" href="https://github.com/golang/go/blob/96824000ed89d13665f6f24ddc10b3bf812e7f47/src/runtime/proc.c">go0.x</a>的一个实现也就是只有一个m，在m上调度g，对应的是我们只用一个goroutine然后在goroutine上调度多个gogoroutine。在实现gogoroutine之前需要介绍一下go的调用惯例，这个<a target="_blank" rel="noopener" href="https://dr-knz.net/go-calling-convention-x86-64-2020.html">文章</a>讲的比较清楚。目前Golang在传递参数和返回值的时候是通过栈传递的。gcc会使用寄存器传递参数，golang有一个使用寄存器传递参数的<a target="_blank" rel="noopener" href="https://go.googlesource.com/proposal/+/refs/changes/78/248178/1/design/40724-register-calling.md">提案</a>。如果要实现一个goroutine上的协程可以利用这么一个调用惯例。</p>
<h2 id="上下文切换"><a href="#上下文切换" class="headerlink" title="上下文切换"></a>上下文切换</h2><p>Go的上下文切换其实和操作系统的上下文切换比较类似，go的实现也是类似的，但相对来说比较简单，因为Go的调用惯例其他的寄存器在函数调用的时候是没有被使用的，主要是保存栈指针和一个指令寄存器PC就可以。Golang的抢占一开始是协作式的，入口是在函数调用的时候。在引入了异步抢占也就是让信号处理函数去切换到调度逻辑（这个切换的过程也类似后面讲到的gogo和gosave，但是他的入口是任何一个指令的地方都会发送所以要保存所有的寄存器）实现抢占以后就可以实现非协作的抢占了。</p>
<p>现在实现的是相对简单的协作式抢占。</p>
<p>0.x的代码是C写的，其中两个汇编函数实现的上下文的保存和切换。这里简单先补充一下Go中汇编的一些知识点。</p>
<p>函数定义:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> TEXT 包名·函数名(SB),一些标签,$栈帧大小-参数大小(包括返回值)</span><br></pre></td></tr></table></figure>
<p>SP表示栈指针，AX是对应的ax系列的寄存器。<br>保存上下文的汇编函数如下,gobuf是一个结构体有两个指针成员分别是sp和pc。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">TEXT gosave(SB), NOSPLIT, $0</span><br><span class="line">		MOVQ	8(SP), AX		// 8(SP)是函数的第一个参数：gobuf的地址</span><br><span class="line">		MOVQ	SP, 0(AX)		// 保存SP也就是栈指针到 gobuf.sp 中。</span><br><span class="line">		MOVQ	0(SP), BX    // 0(SP)是函数的返回地址</span><br><span class="line">		MOVQ	BX, 8(AX)		// 将函数的返回地址保存到 gobuf.pc 中。</span><br><span class="line">		MOVL	$0, AX			// return 0</span><br><span class="line">		RET</span><br></pre></td></tr></table></figure>
<p>这段函数其实主要是保存了gosave调用时的栈指针，而返回地址就是gosave返回后的下一条指令的地址，返回值是0，这个0可以标记到这个函数是从gosave返回的，这个要结合后面的gogo来理解。<br>现在来看gogo</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">TEXT gogo(SB), 7, $0</span><br><span class="line">		MOVQ	8(SP), AX		// 8(SP)是gobuf这个参数的地址</span><br><span class="line">		MOVQ	0(AX), SP		// 将栈针修改为之前保存的SP</span><br><span class="line">		MOVQ	8(AX), AX   // 获取PC</span><br><span class="line">		MOVQ	AX, 0(SP)		// 把 PC 放到0(SP)上</span><br><span class="line">		MOVL	$1, AX			// return 1</span><br><span class="line">		RET</span><br></pre></td></tr></table></figure>
<p>gogo返回以后其实是返回到了之前gosave需要返回的地方，并且返回值是1。这里用寄存器做返回值是c里面的一种方式。所以如果一个gosave是返回0那么它是从真正的调用者那里返回的，如果返回的是1就是从gogo返回的，如果这里点理解了以后就可以实现一个上下文切换了。<br>对应Go的函数调用的版本就是：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">TEXT ·gogogo(SB), NOSPLIT, $0-16</span><br><span class="line">MOVQ	8(SP), AX		// gogobuf</span><br><span class="line">MOVQ	0(AX), SP		// restore SP</span><br><span class="line">MOVQ	8(AX), AX</span><br><span class="line">MOVQ	AX, 0(SP)		// put PC on the stack</span><br><span class="line">MOVL	$1, 16(SP) // return true</span><br><span class="line">RET</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">TEXT ·gosave(SB), NOSPLIT, $0-16</span><br><span class="line">MOVQ	8(SP), AX		// gogobuf</span><br><span class="line">MOVQ	SP, 0(AX)		// save SP</span><br><span class="line">MOVQ	0(SP), BX</span><br><span class="line">MOVQ	BX, 8(AX)		// save PC</span><br><span class="line">MOVB	$0, 16(SP)		// return false</span><br><span class="line">RET</span><br></pre></td></tr></table></figure>
<p>这面的区别是参数gobuf和返回值用了16个字节，因为Go的调用是用栈的，之前说到过。<br>0(SP)就是返回地址，8(SP)是gobuf，16(SP)是true或者false的返回地址。</p>
<h2 id="gogoroutine的创建"><a href="#gogoroutine的创建" class="headerlink" title="gogoroutine的创建"></a>gogoroutine的创建</h2><p>原本函数做的两件事情就是分配栈和指定PC，pc只要对于一个新的gogoroutine指向函数指针就可以。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span></span><br><span class="line">	sys·<span class="built_in">newproc</span>(int32 siz, byte* fn, byte* arg0)</span><br><span class="line">	&#123;</span><br><span class="line">		byte *stk, *sp;</span><br><span class="line">		G *newg;</span><br><span class="line"></span><br><span class="line">	<span class="comment">//prints(&quot;newproc siz=&quot;);</span></span><br><span class="line">	<span class="comment">//sys·printint(siz);</span></span><br><span class="line">	<span class="comment">//prints(&quot; fn=&quot;);</span></span><br><span class="line">	<span class="comment">//sys·printpointer(fn);</span></span><br><span class="line"></span><br><span class="line">		siz = (siz<span class="number">+7</span>) &amp; ~<span class="number">7</span>;</span><br><span class="line">		<span class="keyword">if</span>(siz &gt; <span class="number">1024</span>)</span><br><span class="line">			<span class="keyword">throw</span>(<span class="string">&quot;sys·newproc: too many args&quot;</span>);</span><br><span class="line"></span><br><span class="line">		<span class="built_in">lock</span>(&amp;sched);</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span>((newg = <span class="built_in">gfget</span>()) != nil)&#123;</span><br><span class="line">			newg-&gt;status = Gwaiting;</span><br><span class="line">			stk = newg-&gt;stack0;</span><br><span class="line">		&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">			newg = <span class="built_in">mal</span>(<span class="built_in">sizeof</span>(G));</span><br><span class="line">			stk = <span class="built_in">mal</span>(<span class="number">4096</span>);</span><br><span class="line">			newg-&gt;stack0 = stk;</span><br><span class="line">			newg-&gt;status = Gwaiting;</span><br><span class="line">			newg-&gt;alllink = allg;</span><br><span class="line">			allg = newg;</span><br><span class="line">		&#125;</span><br></pre></td></tr></table></figure>
<p>到这就是分配了一段给栈用的内存，内存的具体分配后面会有一个文章讲解。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">		<span class="comment">// 160 这个地方是一个约定</span></span><br><span class="line">   <span class="comment">// 一些小函数会利用栈之外的160个字节进行优化</span></span><br><span class="line">newg-&gt;stackguard = stk<span class="number">+160</span>;</span><br></pre></td></tr></table></figure>
<p>上面多留出来的地方是一个x86的约定需要给出一个redzone给一些小函数优化用的，不用分配栈直接去使用栈外的这个redzone来增加效率。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">   // 栈是从高地址向低地址增长的，至于这个 4*8是留给什么的没搞清</span><br><span class="line">	sp = stk + 4096 - 4*8;</span><br><span class="line">	newg-&gt;stackbase = sp;</span><br><span class="line">    // 拷贝参数</span><br><span class="line">	sp -= siz;</span><br><span class="line">	mcpy(sp, (byte*)&amp;arg0, siz);</span><br><span class="line">   // 函数结束时返回到 goexit 进行收尾工作</span><br><span class="line">	sp -= 8;</span><br><span class="line">	*(byte**)sp = (byte*)sys·goexit;</span><br><span class="line">    // 留给 gogo 的修改返回地址用的地方</span><br><span class="line">  // 相当于假装在gogo的地方返回到了fn的函数指针</span><br><span class="line">	sp -= 8;	// retpc used by gogo</span><br><span class="line">	newg-&gt;sched.SP = sp;</span><br><span class="line">	newg-&gt;sched.PC = fn;</span><br><span class="line"></span><br><span class="line">	sched.gcount++;</span><br><span class="line">	goidgen++;</span><br><span class="line">	newg-&gt;goid = goidgen;</span><br><span class="line"></span><br><span class="line">	readylocked(newg);</span><br><span class="line">	unlock(&amp;sched);</span><br><span class="line"></span><br><span class="line">//prints(&quot; goid=&quot;);</span><br><span class="line">//sys·printint(newg-&gt;goid);</span><br><span class="line">//prints(&quot;\n&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对应的go代码，Go当中获取函数地址的方式比较tricky，需要了解interface的layout，他是一个interface的头和一个interface包含的对象的地址。FuncPC就是通过转换获取这个函数地址，对应的实现可以在Go的<a target="_blank" rel="noopener" href="https://github.com/golang/go/blob/41d8e61a6b9d8f9db912626eb2bbc535e929fefc/src/runtime/proc.go#L447">源码</a>找到。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewProc</span><span class="params">(f <span class="keyword">interface</span>&#123;&#125;, args ...<span class="keyword">interface</span>&#123;&#125;)</span></span> &#123;</span><br><span class="line">		pc := FuncPC(f)</span><br><span class="line">		stack := Malloc(<span class="number">1024</span>)</span><br><span class="line">		sp := stack + <span class="number">1024</span> - <span class="number">4</span>*<span class="number">8</span></span><br><span class="line">		*(*<span class="type">uintptr</span>)(unsafe.Pointer(sp - <span class="number">8</span>)) = FuncPC(goexit) + <span class="number">1</span></span><br><span class="line">		gogoRoutine := GoGoRoutine&#123;&#125;</span><br><span class="line">		gogoRoutine.Sched.PC = pc</span><br><span class="line">		gogoRoutine.Sched.SP = sp - <span class="number">8</span> - <span class="number">8</span></span><br><span class="line">		gogoRoutine.Stack = stack</span><br><span class="line">		globalgoid++</span><br><span class="line">		gogoRoutine.goid = globalgoid</span><br><span class="line">		gogoRoutine.status = _Grunnable</span><br><span class="line">		ggput(&amp;gogoRoutine)</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<h2 id="调度主体"><a href="#调度主体" class="headerlink" title="调度主体"></a>调度主体</h2><p>0.x版本的逻辑其实很简单，通过if(gosave)的方式可以判断是从哪里跳过来的。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Scheduler loop: find g to run, run it, repeat.</span></span><br><span class="line">	<span class="function"><span class="type">static</span> <span class="type">void</span></span></span><br><span class="line"><span class="function">	<span class="title">scheduler</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		G* gp;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// Initialization.</span></span><br><span class="line">		m-&gt;procid = <span class="built_in">getprocid</span>();</span><br><span class="line">		<span class="built_in">lock</span>(&amp;sched);</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span>(<span class="built_in">gosave</span>(&amp;m-&gt;sched))&#123;</span><br><span class="line">     <span class="comment">// 这里的 gosave 返回的是 true</span></span><br><span class="line">            <span class="comment">// 说明是通过 gogo 过来的</span></span><br><span class="line">            <span class="comment">// 如果当前的 g 是 running 的话就保存上下文</span></span><br><span class="line"><span class="comment">// 切换成 runnable 放入到 queue 中</span></span><br><span class="line">            <span class="comment">// 走出 if 去到调度逻辑。</span></span><br><span class="line">			<span class="comment">// Jumped here via gosave/gogo, so didn&#x27;</span></span><br><span class="line">			<span class="comment">// execute lock(&amp;sched) above.</span></span><br><span class="line">			<span class="built_in">lock</span>(&amp;sched);</span><br><span class="line"></span><br><span class="line">			<span class="comment">// Just finished running m-&gt;curg.</span></span><br><span class="line">			gp = m-&gt;curg;</span><br><span class="line">			gp-&gt;m = nil;	<span class="comment">// for debugger</span></span><br><span class="line">			<span class="keyword">switch</span>(gp-&gt;status)&#123;</span><br><span class="line">			<span class="keyword">case</span> Grunnable:</span><br><span class="line">			<span class="keyword">case</span> Gdead:</span><br><span class="line">				<span class="comment">// Shouldn&#x27;t have been running!</span></span><br><span class="line">				<span class="keyword">throw</span>(<span class="string">&quot;bad gp-&gt;status in sched&quot;</span>);</span><br><span class="line">			<span class="keyword">case</span> Grunning:</span><br><span class="line">				gp-&gt;status = Grunnable;</span><br><span class="line">				<span class="built_in">gput</span>(gp);</span><br><span class="line">				<span class="keyword">break</span>;</span><br><span class="line">			<span class="keyword">case</span> Gmoribund:</span><br><span class="line">				gp-&gt;status = Gdead;</span><br><span class="line">				<span class="keyword">if</span>(--sched.gcount == <span class="number">0</span>)</span><br><span class="line">					sys·<span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">				<span class="keyword">break</span>;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="built_in">notewakeup</span>(&amp;gp-&gt;stopped);</span><br><span class="line">		&#125;</span><br><span class="line">     <span class="comment">// 真正的 gosave 是返回 false的。</span></span><br><span class="line">	    <span class="comment">// 这个地方是 gosave 的返回地址</span></span><br><span class="line">    <span class="comment">// 也是 gogo 后 if 处理完的地方</span></span><br><span class="line">        <span class="comment">// 在这里寻找合适的g然后运行。</span></span><br><span class="line">		<span class="comment">// Find (or wait for) g to run.  Unlocks sched.</span></span><br><span class="line">		gp = <span class="built_in">nextgandunlock</span>();</span><br><span class="line"></span><br><span class="line">		<span class="built_in">noteclear</span>(&amp;gp-&gt;stopped);</span><br><span class="line">		gp-&gt;status = Grunning;</span><br><span class="line">		m-&gt;curg = gp;</span><br><span class="line">		gp-&gt;m = m;	<span class="comment">// for debugger</span></span><br><span class="line">		g = gp;</span><br><span class="line">		<span class="built_in">gogo</span>(&amp;gp-&gt;sched);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>对应的go代码：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">   <span class="comment">//go:noline</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">schedule</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> gosave(&amp;sched.gg0.Sched) &#123;</span><br><span class="line">		curgg := sched.curgg</span><br><span class="line">		<span class="keyword">switch</span> curgg.status &#123;</span><br><span class="line">		<span class="keyword">case</span> _Grunnable:</span><br><span class="line">			<span class="built_in">panic</span>(<span class="string">&quot;invalid status&quot;</span>)</span><br><span class="line">		<span class="keyword">case</span> _Grunning:</span><br><span class="line">			curgg.status = _Grunnable</span><br><span class="line">			ggput(curgg)</span><br><span class="line">			<span class="keyword">break</span></span><br><span class="line">		<span class="keyword">case</span> _Gdead:</span><br><span class="line">			<span class="keyword">break</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="comment">// 调度循环</span></span><br><span class="line">	<span class="keyword">for</span>  &#123;</span><br><span class="line">		<span class="comment">// println(&quot;find g&quot;)</span></span><br><span class="line">		gg := ggget()</span><br><span class="line">		<span class="keyword">if</span> gg == <span class="literal">nil</span> &#123;</span><br><span class="line">			time.Sleep(time.Second)</span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line">		&#125;</span><br><span class="line">		gg.status = _Grunning</span><br><span class="line">		sched.curgg = gg</span><br><span class="line">		gogogo(&amp;gg.Sched)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样就能实现一个简单的单goroutine上跑多个gogoroutine的上下文切换了。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ggaaooppeenngg.github.io/zh-CN/2020/05/13/Spark-Ray-PS-MPI%E7%AD%89%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E%E5%92%8C%E6%A1%86%E6%9E%B6%E7%9A%84%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ggaaooppeenngg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ggaaooppeenngg">
      <meta itemprop="description" content="为什么计算机科学是无限的但生命是有限的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ggaaooppeenngg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/zh-CN/2020/05/13/Spark-Ray-PS-MPI%E7%AD%89%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E%E5%92%8C%E6%A1%86%E6%9E%B6%E7%9A%84%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">Spark/Ray/PS/MPI等计算引擎和框架的小总结</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-05-13 23:29:47" itemprop="dateCreated datePublished" datetime="2020-05-13T23:29:47+08:00">2020-05-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-28 18:39:05" itemprop="dateModified" datetime="2025-03-28T18:39:05+08:00">2025-03-28</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/zh-CN/2020/05/13/Spark-Ray-PS-MPI%E7%AD%89%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E%E5%92%8C%E6%A1%86%E6%9E%B6%E7%9A%84%E6%80%BB%E7%BB%93/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="zh-CN/2020/05/13/Spark-Ray-PS-MPI等计算引擎和框架的总结/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>大规模的并发并行计算考虑的问题主要关于数据、计算的吞吐量还有容错。不管是设计者还是使用者，关心的是在期望上（因为可能会失败）运行任务的效率，从设计者的角度来讲要提供一个可靠高效的环境，从使用者的角度来讲这个东西需要足够的简单，简单意味着编程效率也保证了可靠性。大数据的整套技术栈在解决一些吞吐量大的批处理问题时得心应手，但是到了深度学习的场景，计算吞吐的要求反而提高了，比较现实点的情况是很多时候我们考虑的是能处理多大的数据量的日志，和多快能把一个ImageNet ResNet50训练完。这个区别在于 Spark 或者 Hadoop 的 MapReduce 的设计和 Tensorflow 以及 PyTorch 的设计理念不同以及对应的计算场景的不同。到了强化学习的场景又是一个大融合，强化学习的场景不光有迭代式的反向误差传播的计算，同时也包含了大规模的仿真环境的计算，Ray主要是在这方面提供了一个一站式的解决框架。分布式系统的问题某种程度上和操作系统的问题其实很类似，都是要考量如何从整个系统的角度充分利用物理资源，从错误中恢复，满足效率。这篇文章主要是比较一下几种主流的计算引擎或者框架或者说是算法的异同。</p>
<h1 id="Spark-MapReduce"><a href="#Spark-MapReduce" class="headerlink" title="Spark(MapReduce)"></a>Spark(MapReduce)</h1><p>我把Spark和MapReduce都归于大数据栈这一类，RDD(Resillient Distributed Dataset) 和 MapReduce<br>这两者的区别没有和MPI/PS的区别大那么多。</p>
<img data-src="/zh-CN/2020/05/13/Spark-Ray-PS-MPI%E7%AD%89%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E%E5%92%8C%E6%A1%86%E6%9E%B6%E7%9A%84%E6%80%BB%E7%BB%93/spark.png" class="">

<p>MapReduce 有 JobTracker，Spark 有 Driver</p>
<p>MapReduce 有 TaskTracker，Spark 有 Executor</p>
<p>MapReduce 中间结果是基于 HDFS，会落盘，Spark 中间结果是基于内存的，也可以落盘，主要是利用内存做缓存</p>
<p>MapReduce 计算抽象由Map和Reduce构成，Spark 的 RDD 有一系列的Transform和Action，封装程度更高</p>
<p>MapReduce 的错误处理比较简单，把失败的Map重试就好了，重试是一种非常好理解的错误处理。<br>Spark 的重试是根据 RDD 的有向无环图中的血缘关系计算的，可以理解为从失败的拓扑序上重新计算，也可以有中间的checkpoint。</p>
<img data-src="/zh-CN/2020/05/13/Spark-Ray-PS-MPI%E7%AD%89%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E%E5%92%8C%E6%A1%86%E6%9E%B6%E7%9A%84%E6%80%BB%E7%BB%93/rdd.png" class="">

<p>RDD 的特性是只读的，在机器学习场景下参数不大的时候 MLLib 通过把参数存到 Driver 上来计算，当参数比较大特别是深度网络的参数大得吓人 Driver 存不下的时候,<br>只能通过新增 RDD，对于要频繁更新的模型参数要生成非常多的 RDD，这是 Spark 在深度学习上设计的缺陷。<br>一般来说一些简单的机器学习任务通过 sklearn 就能完成，当数据量比较大的时候就需要通过 Spark 的MLLib来处理。<br>当然 MLLib 现在也在开始从RDD-based转向SparkSQL用的Dataframe-based，从大的角度上讲两者互相融合是可行的，可能需要一些时间。<br>上 Spark 用 Yarn 调度 Tensorflow，还是用 Kuberenetes 调度 Spark 和 Tensorflow，我个人支持后者，而且这种分层是我比较喜欢的一种分层。</p>
<h1 id="Ray"><a href="#Ray" class="headerlink" title="Ray"></a>Ray</h1><p>Ray 的基本抽象就是 Remote 或者 Actor，一个是分布式调用函数，一个式分布式调用类。Ray 和 Ray 的 RLlib 主要面对的问题是强化学习有大量的 simulating 的环境，比如仿真一局Dota，涉及到模拟一局Dota，反馈Agent的神经网络，是并行计算和神经网络训练的结合。当然 Ray 本身的抽象就是个分布式 goroutine，所以某种程度上可以完成的事情不光是强化学习一种任务，比如HypterTunning等一些并行计算的模型也是试用的。</p>
<img data-src="/zh-CN/2020/05/13/Spark-Ray-PS-MPI%E7%AD%89%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E%E5%92%8C%E6%A1%86%E6%9E%B6%E7%9A%84%E6%80%BB%E7%BB%93/ray.png" class="">

<p>反过来想，如果没有 Ray 的话，如何做这个系统呢，要构建大批量的仿真计算环境，然后能根据仿真的反馈训练神经网络。<br>这两个任务的调度控制就是一个问题，当然放到 k8s 的调度器里做似乎也可以，然后涉及这些分布式任务的同步问题，<br>需要构建这些任务的关系和信息传输，似乎用一些 DAG （比如 argo）的 workflow 也能解决，但他们之间通信的高效性似乎会是一个问题，需要<br>选择一种高效的远程调用传输方式，肯能gRPC也可以，还有他们的元数据管理用什么呢，自己搞个Redis似乎也行。<br>Ray 从这些方面综合考虑了这些问题提供了一个一站式的RL训练平台。</p>
<h1 id="PS和MPI"><a href="#PS和MPI" class="headerlink" title="PS和MPI"></a>PS和MPI</h1><p>MPI和PS的介绍有很多，我也不需要费篇幅唠叨。</p>
<p>PS和MPI是比较常用的分布式深度学习的训练方式，两者的主要区别在于Paramater Server，在PS的场景下参数统一走一个或者shard多个PS更新。</p>
<img data-src="/zh-CN/2020/05/13/Spark-Ray-PS-MPI%E7%AD%89%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E%E5%92%8C%E6%A1%86%E6%9E%B6%E7%9A%84%E6%80%BB%E7%BB%93/ps_worker_arch.png" class="">

<p>在MPI的场景下每个Worker是对等的（或者分层级对等，比如主机上的四张卡走NVLink，主机之间走万兆网卡）工作节点，使用AllReduce参数的同步在Worker之间进行。</p>
<img data-src="/zh-CN/2020/05/13/Spark-Ray-PS-MPI%E7%AD%89%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E%E5%92%8C%E6%A1%86%E6%9E%B6%E7%9A%84%E6%80%BB%E7%BB%93/mpi.png" class="">

<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>MPI在我出生前应该就有了，但是MapReduce之所以能火起来主要还是在 fault-tolerance 上，MPI的抽象比较基础，但是MapReduce和Spark在廉价大集群上的表现非常亮眼，对于没那么并行化理想的场景能够tolerate，时间到了深度学习的场景这玩意儿又冒出来了，一方面是深度学习的计算资源好得不得了，因为配备GPU的机器和传统的机器比起来好很多，对于这种纯粹的并行计算框架来说非常友好，错误处理的问题就没那么严重，即使是这样也慢慢开始有人着手优化MPI/PS的fault tolerance，在一些并行化退化的场景下能够把训练并行度降级不至于完全失败的工作。</p>
<p>从长远来看 Ray 还会有很多进化的空间，Spark 也会更好地适配深度学习场景，深度学习本身在System上的优化也层出不穷，大家对于大规模的并发并行计算系统的方方面面的要求都会越来越高。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ggaaooppeenngg.github.io/zh-CN/2019/10/14/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96%E4%B9%8B%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B%E5%92%8C%E5%BA%94%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ggaaooppeenngg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ggaaooppeenngg">
      <meta itemprop="description" content="为什么计算机科学是无限的但生命是有限的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ggaaooppeenngg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/zh-CN/2019/10/14/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96%E4%B9%8B%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B%E5%92%8C%E5%BA%94%E7%94%A8/" class="post-title-link" itemprop="url">贝叶斯优化之高斯过程和应用</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-10-14 01:21:32" itemprop="dateCreated datePublished" datetime="2019-10-14T01:21:32+08:00">2019-10-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-28 18:39:05" itemprop="dateModified" datetime="2025-03-28T18:39:05+08:00">2025-03-28</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/zh-CN/2019/10/14/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96%E4%B9%8B%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B%E5%92%8C%E5%BA%94%E7%94%A8/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="zh-CN/2019/10/14/贝叶斯优化之高斯过程和应用/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="贝叶斯优化-BO"><a href="#贝叶斯优化-BO" class="headerlink" title="贝叶斯优化(BO)"></a>贝叶斯优化(BO)</h2><p>贝叶斯优化是一种黑盒优化方法，一般有几个特征：</p>
<p>输入纬度不大，一般小于 20 个，时间复杂度是$O(n^3)$<br>有设定的取值空间<br>目标函数需要是连续的（我觉得这个好像不是必须的，离散的也可以）<br>目标函数的计算非常消耗成本（时间等等）<br>目标函数是黑盒的，没有明确的结构<br>目标函数（derivative-free）没有一阶二阶导数（不然就可以用梯度下降去算了）</p>
<p>因为这些特性，在做机器学习的超参数调优的时候特别合适。</p>
<blockquote>
<p>BayesOpt consists of two main components: a Bayesian statistical model for modeling the objective function, and an acquisition function for deciding where to sample next.</p>
</blockquote>
<p>贝叶斯优化主要是要两个部分，一个是统计模型比如高斯过程(GP)，一个是采样函数(AC)决定下一个样本从拿里获取。</p>
<h2 id="高斯过程-GP"><a href="#高斯过程-GP" class="headerlink" title="高斯过程(GP)"></a>高斯过程(GP)</h2><p>高斯过程是贝叶斯优化中的一种统计模型，先抛开具体的数学问题，简单讲一下就是，假设我在一个变量空间（比如多个超参数）采样了一个目标函数（我们训练结果的 evaluation），然后我们会得到一个后验分布，这就类似条件概率里面，我们知道了某个事情发生以后，如果随机变量是相关的，我们有更大的概率确定其他变量的分布。例如下图，绿色是我们的分布空间，每次采样以后，分布的空间就会缩小，进而接近我们的曲线。</p>
<img data-src="/zh-CN/2019/10/14/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96%E4%B9%8B%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B%E5%92%8C%E5%BA%94%E7%94%A8/GP.gif" class="">

<p>从数学上描述这件事情就需要高斯分布和高斯过程了。高斯分布我相信大家都耳熟能详，他由平均值 $\mu$ 还有标准差 $\sigma$ 决定分布。高斯过程的本质是一个多元高斯分布，只不过他是无限空间上的，定义高斯过程需要一个核函数定义他的协方差矩阵，也就是一个矩阵定义多个随机变量的相关性。当然了，有限的离散点用协方差矩阵可以，如果取值是连续的就需要核函数描述这个“无限”的协方差矩阵了。</p>
<p>协方差的核函数就很多选项，<a target="_blank" rel="noopener" href="https://distill.pub/2019/visual-exploration-gaussian-processes/">A Visual Exploration of Gaussian Processes</a> 提供了一个非常 intuitive 的可视化来解释 GP 和各种描述协方差矩阵的核函数。</p>
<p>高斯过程被定义为一个<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B">随机过程</a>，相当于每个样本点自己也是个随机函数，对于高斯分布来说，每个样本点也是一个高斯分布函数就是高斯过程，<a target="_blank" rel="noopener" href="http://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote15.html">cs4780 的 Lecture 15</a>有非常详细的解释。</p>
<blockquote>
<p>Definition: A GP is a (potentially infinte) collection of random variables (RV) such that the joint distribution of every finite subset of RVs is multivariate Gaussian:<br>$ f \sim GP(\mu, k), $<br>where $\mu(\mathbf{x})$ and $k(\mathbf{x}, \mathbf{x}’)$ are the mean resp. covariance function! Now, in order to model the predictive distribution $P(f_* \mid \mathbf{x}_*, D)$ we can use a Bayesian approach by using a GP prior: $P(f\mid \mathbf{x}) \sim \mathcal{N}(\mu, \Sigma)$ and condition it on the training data $D$ to model the joint distribution of $f=f(X)$ (vector of training observations) and $f_* = f(\mathbf{x}_*)$ (prediction at test input).</p>
</blockquote>
<h2 id="采样函数"><a href="#采样函数" class="headerlink" title="采样函数"></a>采样函数</h2><p>采样函数一般有 expected improvement(EI)，当然还有 probability improvement(PI), upper confidence bound(UCB), knowledge gradient(KG),entropy search and predictive entropy search 等等。<br>采样的策略有两种：<br>Explore：探索新的点，这种采样有助于估计更准确的；<br>Exploit：利用已有结果附近的点进行采样，从而希望找到更大的；</p>
<p>这两个标准是互相矛盾的，如何在这两者之间寻找一个平衡点可以说是采样函数面对的主要挑战。</p>
<blockquote>
<p>Expected improvement is a popular acquisition function owing to its good practical performance and an analytic form that is easy to compute. As the name suggests it rewards evaluation of the objective $f$ based on the expected improvement relative to the current best. If $f^* = \max_i y_i$ is the current best observed outcome and our goal is to maximize $f$, then EI is defined as</p>
</blockquote>
<blockquote>
<p>$\text{EI}(x) = \mathbb{E}\bigl[\max((f(x) - f^*), 0)\bigr]$</p>
</blockquote>
<p>在 Facebook 的 Ax 在<a target="_blank" rel="noopener" href="https://ax.dev/docs/bayesopt">这里</a>提到使用了 PyTorch 的一个 BoTorch 用的就是 EI，就是期望的增加度。</p>
<p>高斯分布式的期望就是 $\mu$ 所以是很好算的，$f^*$ 是已知的定值，<a target="_blank" rel="noopener" href="http://ash-aldujaili.github.io/blog/2018/02/01/ei/">这里</a>有一个计算的推导。</p>
<p>BoTorch 提供了一个优化的 EI 叫 Noisy EI，主要功能是抗噪。</p>
<blockquote>
<p>The above definition of the EI function assumes that the objective function is observed free of noise. In many types of experiments, such as those found in A/B testing and reinforcement learning, the observations are typically noisy. For these cases, BoTorch implements an efficient variant of EI, called Noisy EI, which allow for optimization of highly noisy outcomes, along with any number of constraints (i.e., ensuring that auxiliary outcomes do not increase or decrease too much). For more on Noisy EI, see our <a target="_blank" rel="noopener" href="https://research.fb.com/efficient-tuning-of-online-systems-using-bayesian-optimization/">blog post</a>.</p>
</blockquote>
<p>这是采样的过程的一个示例：</p>
<img data-src="/zh-CN/2019/10/14/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96%E4%B9%8B%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B%E5%92%8C%E5%BA%94%E7%94%A8/bo_1d_opt.gif" class="">


<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><p>高斯过程本身可以用来回归和分类，使用高斯过程的贝叶斯优化有很多具体的应用场景，除了超参数优化之外，对于网络结果（层数，数据并行度）等等也是可以使用的。<br>除此之外像 horovod 也使用了贝叶斯优化，在这个目录<a target="_blank" rel="noopener" href="https://github.com/horovod/horovod/tree/master/horovod/common/optim">下面</a>。</p>
<blockquote>
<p>Horovod comes with several adjustable “knobs” that can affect runtime performance, including –fusion-threshold-mb and –cycle-time-ms (tensor fusion), –cache-capacity (response cache), and hierarchical collective algorithms –hierarchical-allreduce and –hierarchical-allgather.</p>
</blockquote>
<p>他主要是服务于一些 Tensor Fusion 和 response cache 等参数以及层级 collective 通信选择，<a target="_blank" rel="noopener" href="https://horovod.readthedocs.io/en/latest/autotune.html">文档</a>提到了通过设置一些参数细致控制调优的过程。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li> <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_23947237/article/details/78265026">一个例子搞清楚（先验分布/后验分布/似然估计）</a></li>
<li> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1807.02811">A Tutorial on Bayesian Optimization</a></li>
<li> <a target="_blank" rel="noopener" href="https://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf">Practical Bayesian Optimization of Machine Learning Algorithms</a></li>
<li> <a target="_blank" rel="noopener" href="https://github.com/hibayesian/awesome-automl-papers">Awesome-AutoML-Papers</a></li>
<li> <a target="_blank" rel="noopener" href="http://www.gaussianprocess.org/gpml/chapters/RW.pdf">Gaussian Processes for Machine Learning</a></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ggaaooppeenngg.github.io/zh-CN/2019/08/30/horovod-%E5%AE%9E%E7%8E%B0%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ggaaooppeenngg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ggaaooppeenngg">
      <meta itemprop="description" content="为什么计算机科学是无限的但生命是有限的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ggaaooppeenngg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/zh-CN/2019/08/30/horovod-%E5%AE%9E%E7%8E%B0%E5%88%86%E6%9E%90/" class="post-title-link" itemprop="url">horovod 实现分析</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-08-30 01:22:44" itemprop="dateCreated datePublished" datetime="2019-08-30T01:22:44+08:00">2019-08-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-28 18:39:05" itemprop="dateModified" datetime="2025-03-28T18:39:05+08:00">2025-03-28</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/zh-CN/2019/08/30/horovod-%E5%AE%9E%E7%8E%B0%E5%88%86%E6%9E%90/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="zh-CN/2019/08/30/horovod-实现分析/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>Horovod 是一个兼容主流计算框架的分布式机器学习训练框架，主要基于的算法是 AllReduce，这个是 baidu-research 在17年做的一个实现，这个东西原来是高性能计算范畴里的东西应用了 MPI 并行计算接口来实现，这是并行计算里的一个框架，已经很老了，<a target="_blank" rel="noopener" href="https://mpitutorial.com/tutorials/">这里</a>有一个介绍 MPI 的 tutorial 写的比较好。</p>
<p>在介绍 horovod 的之前需要解释一下 AllReduce。在 MapReduce 里面 reduce 被翻译成了规约，在上面提到的 MPI tutorial 里面的解释是</p>
<blockquote>
<p>Reduce is a classic concept from functional programming. Data reduction involves reducing a set of numbers into a smaller set of numbers via a function. For example, let’s say we have a list of numbers <code>[1, 2, 3, 4, 5]</code>. Reducing this list of numbers with the sum function would produce <code>sum([1, 2, 3, 4, 5]) = 15</code>. Similarly, the multiplication reduction would yield <code>multiply([1, 2, 3, 4, 5]) = 120</code>.</p>
</blockquote>
<p>就是说把一个大的集合“缩减”成了小的集合，这里要注意的是这种缩减的计算是要满足交换律的，也就是减法或者除法是不行的，因为在并行计算当中不太好去控制计算的顺序。Reduce 就是这个意思，具体到 MPI_Reduce 就是把不同节点的数字“缩减”到一个节点上，支持的计算方式有加法乘法和取大小值等。</p>
<p>教程中给出的 Reduce 是求和。</p>
<img data-src="/zh-CN/2019/08/30/horovod-%E5%AE%9E%E7%8E%B0%E5%88%86%E6%9E%90/mpi_reduce_1.png" class="">
<p>AllReduce 就是在每个节点都获得 Reduce 的结果</p>
<img data-src="/zh-CN/2019/08/30/horovod-%E5%AE%9E%E7%8E%B0%E5%88%86%E6%9E%90/mpi_allreduce_1.png" class="">
<p>基于这个标准就有很多的 All-Reduce 的实现，比如 Ring-Reduce，这个实现分两部分，一部分是 Scatter-Reduce 另一部分是 All-Gather。最早是在<a target="_blank" rel="noopener" href="http://andrew.gibiansky.com/">这篇 post</a>里提到的。这个算法的好处是可以摆脱之前 PS 非常依赖 Parameter-Server 的带宽，Parameter-Server 的带宽会成为计算瓶颈的问题，而 AllReduce 可以让每个节点在带宽传输中的位置是对等的，并且减少传输次数。具体的算法可以看文章的解释，scatter-reduce 就是让每个节点有 K/N 的一个 reduce(也就是 sum)，然后把自己的一个 K/N 的 reduce 再传递给其他节点，每个节点只和自己相邻的节点通信。</p>
<blockquote>
<p>In the system we described, each of the N GPUs will send and receive values N-1 times for the scatter-reduce, and N-1 times for the allgather. Each time, the GPUs will send K / N values, where K is the total number of values in array being summed across the different GPUs. Therefore, the total amount of data transferred to and from every GPU is</p>
</blockquote>
<blockquote>
<p>Data Transferred=2(N−1)KN</p>
</blockquote>
<p>数据传输量在 N 比较大的时候越没有影响，这就消弭了多节点给 Parameter-Server 造成的瓶颈。</p>
<p>还有一些其他术语，假设有 4 台 4 卡的 GPU 服务器。size 是工作进程（GPU）的数量(6)，rank 是所有工作进程的 id(0-15)，local rank 是当前服务器上的 id(0-3)。</p>
<h2 id="Horovod-的介绍"><a href="#Horovod-的介绍" class="headerlink" title="Horovod 的介绍"></a>Horovod 的介绍</h2><p>使用 horovod 有一定的侵入性，代码需要一定的修改才能变成适配分布式训练，但是有一个好处就是适配的成本不高，并且 horovod 提供的各种框架的支持可以让 horovod 比较好的在各个框架的基础上使用，他支持 tensorflow/keras/mxnet/pytorch，MPI 的实现也有很多，比如 OpenMPI 还有 Nvidia 的 NCCL，还有 facebook 的 gloo，他们都实现了一种并行计算的通信和计算方式。而且 horovod 的本身的实现也很简单。</p>
<h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>以 <a target="_blank" rel="noopener" href="https://github.com/horovod/horovod/blob/master/examples/keras_imagenet_resnet50.py">Keras 用 ResNet50 训练 ImageNet </a>为例，主要侵入了几部分 <code>hvd.init()</code> 这个是 MPI 的初始化，让并行进程能够知道自己的 rank/local_rank 等信息。</p>
<p>第二部根据 local_rank（相当于单节点上的第n张卡），并且设置不占用全部显存，按需分配（可能因内没有统一管理导致显存碎片），然后传递给 keras 设置 session。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Horovod: pin GPU to be used to process local rank (one GPU per process)</span><br><span class="line">config = tf.ConfigProto()</span><br><span class="line">config.gpu_options.allow_growth = True</span><br><span class="line">config.gpu_options.visible_device_list = str(hvd.local_rank())</span><br><span class="line">K.set_session(tf.Session(config=config))</span><br></pre></td></tr></table></figure>
<p>然后在 rank 0 上恢复一个 checkpoint 并且广播给其他节点，这里的 broadcast 后面会介绍。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># If set &gt; 0, will resume training from a given checkpoint.</span><br><span class="line">resume_from_epoch = 0</span><br><span class="line">for try_epoch in range(args.epochs, 0, -1):</span><br><span class="line">    if os.path.exists(args.checkpoint_format.format(epoch=try_epoch)):</span><br><span class="line">        resume_from_epoch = try_epoch</span><br><span class="line">        break</span><br><span class="line"></span><br><span class="line"># Horovod: broadcast resume_from_epoch from rank 0 (which will have</span><br><span class="line"># checkpoints) to other ranks.</span><br><span class="line">resume_from_epoch = hvd.broadcast(resume_from_epoch, 0, name=&#x27;resume_from_epoch&#x27;)</span><br><span class="line"></span><br><span class="line"># Horovod: print logs on the first worker.</span><br><span class="line">verbose = 1 if hvd.rank() == 0 else 0</span><br></pre></td></tr></table></figure>
<p>设定传输的压缩函数，具体的压缩后面会提到，然后要么从之前的模型恢复要么重新训练。关键的 wrapper 在 <code>opt</code> 上，会给本地的 <code>opt</code> 包装一个 <code>DistributedOptimizer</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"># Horovod: (optional) compression algorithm.</span><br><span class="line">compression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none</span><br><span class="line"></span><br><span class="line"># Restore from a previous checkpoint, if initial_epoch is specified.</span><br><span class="line"># Horovod: restore on the first worker which will broadcast both model and optimizer weights</span><br><span class="line"># to other workers.</span><br><span class="line">if resume_from_epoch &gt; 0 and hvd.rank() == 0:</span><br><span class="line">    model = hvd.load_model(args.checkpoint_format.format(epoch=resume_from_epoch),</span><br><span class="line">                           compression=compression)</span><br><span class="line">else:</span><br><span class="line">    # ResNet-50 model that is included with Keras is optimized for inference.</span><br><span class="line">    # Add L2 weight decay &amp; adjust BN settings.</span><br><span class="line">    model_config = model.get_config()</span><br><span class="line">    for layer, layer_config in zip(model.layers, model_config[&#x27;layers&#x27;]):</span><br><span class="line">        if hasattr(layer, &#x27;kernel_regularizer&#x27;):</span><br><span class="line">            regularizer = keras.regularizers.l2(args.wd)</span><br><span class="line">            layer_config[&#x27;config&#x27;][&#x27;kernel_regularizer&#x27;] = \</span><br><span class="line">                &#123;&#x27;class_name&#x27;: regularizer.__class__.__name__,</span><br><span class="line">                 &#x27;config&#x27;: regularizer.get_config()&#125;</span><br><span class="line">        if type(layer) == keras.layers.BatchNormalization:</span><br><span class="line">            layer_config[&#x27;config&#x27;][&#x27;momentum&#x27;] = 0.9</span><br><span class="line">            layer_config[&#x27;config&#x27;][&#x27;epsilon&#x27;] = 1e-5</span><br><span class="line"></span><br><span class="line">    model = keras.models.Model.from_config(model_config)</span><br><span class="line"></span><br><span class="line">    # Horovod: adjust learning rate based on number of GPUs.</span><br><span class="line">    opt = keras.optimizers.SGD(lr=args.base_lr * hvd.size(),</span><br><span class="line">                               momentum=args.momentum)</span><br><span class="line"></span><br><span class="line">    # Horovod: add Horovod Distributed Optimizer.</span><br><span class="line">    opt = hvd.DistributedOptimizer(opt, compression=compression)</span><br><span class="line"></span><br><span class="line">    model.compile(loss=keras.losses.categorical_crossentropy,</span><br><span class="line">                  optimizer=opt,</span><br><span class="line">                  metrics=[&#x27;accuracy&#x27;, &#x27;top_k_categorical_accuracy&#x27;])</span><br></pre></td></tr></table></figure>
<p>然后设置一些回调函数，<code>hvd.callbacks.BroadcastGlobalVariablesCallback(0)</code> 保证的是 rank 0 上的所有参数只在 rank 0 初始化，然后广播给其他节点，后面是学习率 decay 的设置和一些统计信息的回调打印。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">callbacks = [</span><br><span class="line">    # Horovod: broadcast initial variable states from rank 0 to all other processes.</span><br><span class="line">    # This is necessary to ensure consistent initialization of all workers when</span><br><span class="line">    # training is started with random weights or restored from a checkpoint.</span><br><span class="line">    hvd.callbacks.BroadcastGlobalVariablesCallback(0),</span><br><span class="line"></span><br><span class="line">    # Horovod: average metrics among workers at the end of every epoch.</span><br><span class="line">    #</span><br><span class="line">    # Note: This callback must be in the list before the ReduceLROnPlateau,</span><br><span class="line">    # TensorBoard, or other metrics-based callbacks.</span><br><span class="line">    hvd.callbacks.MetricAverageCallback(),</span><br><span class="line"></span><br><span class="line">    # Horovod: using `lr = 1.0 * hvd.size()` from the very beginning leads to worse final</span><br><span class="line">    # accuracy. Scale the learning rate `lr = 1.0` ---&gt; `lr = 1.0 * hvd.size()` during</span><br><span class="line">    # the first five epochs. See https://arxiv.org/abs/1706.02677 for details.</span><br><span class="line">    hvd.callbacks.LearningRateWarmupCallback(warmup_epochs=args.warmup_epochs, verbose=verbose),</span><br><span class="line"></span><br><span class="line">    # Horovod: after the warmup reduce learning rate by 10 on the 30th, 60th and 80th epochs.</span><br><span class="line">    hvd.callbacks.LearningRateScheduleCallback(start_epoch=args.warmup_epochs, end_epoch=30, multiplier=1.),</span><br><span class="line">    hvd.callbacks.LearningRateScheduleCallback(start_epoch=30, end_epoch=60, multiplier=1e-1),</span><br><span class="line">    hvd.callbacks.LearningRateScheduleCallback(start_epoch=60, end_epoch=80, multiplier=1e-2),</span><br><span class="line">    hvd.callbacks.LearningRateScheduleCallback(start_epoch=80, multiplier=1e-3),</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>最后直接用 allreduce 计算一个 evaluation score。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Evaluate the model on the full data set.</span><br><span class="line">score = hvd.allreduce(model.evaluate_generator(input_fn(False, args.train_dir, args.val_batch_size),NUM_IMAGES[&#x27;validation&#x27;]))</span><br></pre></td></tr></table></figure>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><h4 id="适配层和压缩算法"><a href="#适配层和压缩算法" class="headerlink" title="适配层和压缩算法"></a>适配层和压缩算法</h4><p>horovod 的实现主要分几部分，第一部分是一个适配层，用于兼容各种框架，比如 tensorflow 的适配就是实现一个新的 Op，这个可以参考 <a target="_blank" rel="noopener" href="https://www.tensorflow.org/guide/extend/op">add new op</a>，里面规范了 Tensorflow 自定义算子的实现。</p>
<blockquote>
<p>请注意，生成的函数将获得一个蛇形名称（以符合 PEP8）。因此，如果您的操作在 C++ 文件中命名为 ZeroOut，则 Python 函数将称为 zero_out。</p>
</blockquote>
<p>C++ 的定义是驼峰的，生成出来的 python 函数是下划线小写的，所以最后对应的是，适配Op的代码在 <a target="_blank" rel="noopener" href="https://github.com/horovod/horovod/tree/master/horovod/tensorflow">horovod/tensorflow</a> 目录下面</p>
<table>
<thead>
<tr>
<th>C++</th>
<th>Python</th>
</tr>
</thead>
<tbody><tr>
<td>HorovodAllgather</td>
<td>horovod_allgather</td>
</tr>
<tr>
<td>HorovodAllreduce</td>
<td>horovod_allreduce</td>
</tr>
<tr>
<td>HorovodBroadcast</td>
<td>horovod_broadcast</td>
</tr>
</tbody></table>
<p>另外在适配层可以加入一些压缩算法(在 <code>horovod/[framework]/compression.py</code>)，我觉得压缩算法和框架无关的，放到适配层下面可能有别的原因，比如 tensorflow 默认带了一个 float16 压缩，具体的其他压缩算法比如<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1802.07389">3LC</a>，可以通过有损压缩或者无损压缩提高带宽利用率。</p>
<h4 id="统一层"><a href="#统一层" class="headerlink" title="统一层"></a>统一层</h4><p>这一层的实现是统一的，所有的适配层最后都是发出一些 Op+Tensor 的 Message 到队列中，后台初始化的时候会有一个专门的线程专门消费这个队列。他有一个同步消息的过程，相当于这个 tensor 在所有节点上都就绪以后就可以开始计算了，主体的流程是：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">// The coordinator currently follows a master-worker paradigm. Rank zero acts</span><br><span class="line">// as the master (the &quot;coordinator&quot;), whereas all other ranks are simply</span><br><span class="line">// workers. Each rank runs its own background thread which progresses in ticks.</span><br><span class="line">// In each tick, the following actions happen:</span><br><span class="line">//</span><br><span class="line">//      a) The workers send a Request to the coordinator, indicating what</span><br><span class="line">//      they would like to do (which tensor they would like to gather and</span><br><span class="line">//      reduce, as well as their shape and type). They repeat this for every</span><br><span class="line">//      tensor that they would like to operate on.</span><br><span class="line">//</span><br><span class="line">//      b) The workers send an empty &quot;DONE&quot; message to the coordinator to</span><br><span class="line">//      indicate that there are no more tensors they wish to operate on.</span><br><span class="line">//</span><br><span class="line">//      c) The coordinator receives the Requests from the workers, as well</span><br><span class="line">//      as from its own TensorFlow ops, and stores them in a [request table]. The</span><br><span class="line">//      coordinator continues to receive Request messages until it has</span><br><span class="line">//      received MPI_SIZE number of empty &quot;DONE&quot; messages.</span><br><span class="line">//</span><br><span class="line">//      d) The coordinator finds all tensors that are ready to be reduced,</span><br><span class="line">//      gathered, or all operations that result in an error. For each of those,</span><br><span class="line">//      it sends a Response to all the workers. When no more Responses</span><br><span class="line">//      are available, it sends a &quot;DONE&quot; response to the workers. If the process</span><br><span class="line">//      is being shutdown, it instead sends a &quot;SHUTDOWN&quot; response.</span><br><span class="line">//</span><br><span class="line">//      e) The workers listen for Response messages, processing each one by</span><br><span class="line">//      doing the required reduce or gather, until they receive a &quot;DONE&quot;</span><br><span class="line">//      response from the coordinator. At that point, the tick ends.</span><br><span class="line">//      If instead of &quot;DONE&quot; they receive &quot;SHUTDOWN&quot;, they exit their background</span><br><span class="line">//      loop.</span><br></pre></td></tr></table></figure>

<p>简单来讲就是说 coordinator 集 size 个 request DONE，然后找出就绪的 tensor （在 message_table 里面查找）构造出一个 read_to_reduce 的列表，然后发出 size 个 request 告知进程进行计算，然后 worker 接受到 response 开始真正的计算过程(通过 op_manager 具体执行)。</p>
<p>这是整体同步的过程，如果打开 horovod 的 trace log(<code>HOROVOD_LOG_LEVEL=trace</code>) 就能看到同步的过程。horovod 的主要 Op 除了 AllReduce 之外还有 allgather 和 broadcast。</p>
<h3 id="算子实现层"><a href="#算子实现层" class="headerlink" title="算子实现层"></a>算子实现层</h3><p>具体的 op 在 <a target="_blank" rel="noopener" href="https://github.com/horovod/horovod/tree/master/horovod/common/ops">common/op</a> 可以看到有 NCCL/Gloo/MPI 等等的，这些由 op_manager 管理，他会根据优先级找到可以用来计算的 op 进行计算，比如 MPI 用的就是 MPI_Allreduce，具体 scatter-gather 和 all-gather openMPI 有现成的实现，NCCL 就直接调用 <code>ncclAllReduce</code>，比较新的 nccl 也支持跨节点的 allreduce 了，不用自己再套一层。</p>
<p>除了 allreduce 之外，还有两个比较重要的算子。</p>
<p>allgather 主要是比 allreduce 少一层 reduce，所有数据被发送到所有进程就可以。allreduce 的第二步就是把每个进程的 scatter-reduce 的 reduce 结果发送到所有进程。</p>
<img data-src="/zh-CN/2019/08/30/horovod-%E5%AE%9E%E7%8E%B0%E5%88%86%E6%9E%90/mpi_allgather_1.png" class="">
<p>broadcast 的作用是一对多的广播，主要是把初始化的参数同步给其他进程的时候使用。</p>
<img data-src="/zh-CN/2019/08/30/horovod-%E5%AE%9E%E7%8E%B0%E5%88%86%E6%9E%90/mpi_broadcast_1.png" class="">




      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ggaaooppeenngg.github.io/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ggaaooppeenngg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ggaaooppeenngg">
      <meta itemprop="description" content="为什么计算机科学是无限的但生命是有限的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ggaaooppeenngg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/" class="post-title-link" itemprop="url">SysML2019 概览1</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-08-12 21:28:09" itemprop="dateCreated datePublished" datetime="2019-08-12T21:28:09+08:00">2019-08-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-28 18:39:05" itemprop="dateModified" datetime="2025-03-28T18:39:05+08:00">2025-03-28</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="zh-CN/2019/08/12/SysML2019-概览1/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>总结一下 SysML 2019 的一些论文。</p>
<h2 id="TICTAC"><a href="#TICTAC" class="headerlink" title="TICTAC"></a>TICTAC</h2><p>问题背景是解决分布式训练的 scale 问题。<br>如图，网络带宽和传输的顺序是关键因素，网络带宽很好理解，如果 Best 要提高只能加带宽，同时传输顺序如图会影响计算时间。</p>
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/tictac.png" class="">

<p>Communication to Computation Ratio 传输计算比，如果比值大说明效率高</p>
<ol>
<li><p> 增大 BatchSize，但是会过拟合(贾扬清的 Train ImageNet in 1 Hour)，减小参数精度(FP16，腾讯绝艺 1024 张V100）。</p>
</li>
<li><p> Overlay Coeffiecient 提供传输和计算的重合率，是 TicTac 的优化方向。</p>
</li>
</ol>
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/overlap.png" class="">

<p>计算最优传输依赖，这是个 NP 问题，需要找近似解。recv op 是图的 root，可行的拓扑排序有很多种，解决方案就是找到近似优化排序。（原问题是 NP 问题）</p>
<p>几种符号</p>
<p>op.P 直接 Op 执行计算时间<br>op.M Op传输时间<br>op.M+ 触发计算 op 的最小传输时间</p>
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic1.png" class="">

<h3 id="Tic"><a href="#Tic" class="headerlink" title="Tic"></a>Tic</h3><p>设 Communication Time 对于每个 recv op 来说都相等，从直觉上解释就是计算执行 recv op 的优先度。<br>如图计算对应的值</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">case 1</span><br><span class="line">A.M = B.M = 1</span><br><span class="line">case 2</span><br><span class="line">A.M = B.M = 1</span><br><span class="line">C.M = 1+1</span><br><span class="line">D.M = 1+1+1</span><br></pre></td></tr></table></figure>
<p>越小优先级越高，这个可以在 DAG 中静态算出</p>
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic2.png" class="">

<h3 id="Tac"><a href="#Tac" class="headerlink" title="Tac"></a>Tac</h3><img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic4.png" class="">

<p>Communication Time 对于每个 recv op 来说有对应的时间，对应的算法。</p>
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic3.png" class="">

<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic5.png" class="">

<h3 id="系统设计"><a href="#系统设计" class="headerlink" title="系统设计"></a>系统设计</h3><p>Time Oracle: Tensorflow metrics 计算 op time</p>
<p>Ordering Wizard: 计算静态依赖优先级</p>
<p>Enforcing: 修改 Tensorflow gRPC 子模块</p>
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic6.png" class="">

<h2 id="P3"><a href="#P3" class="headerlink" title="P3"></a>P3</h2><p>PRIORITY-BASED PARAMETER PROPAGATION FOR DISTRIBUTED DNN TRAINING</p>
<p>和上一篇论文类似，也是基于传输优化的思路，因为网络带宽基本上就是一个硬件问题。一些优化手段是用了有损压缩或者降低收敛时准确率的方式。还是通过提高 overlap 来实现。<br>直观的现象是如图 L4 的一次正向传播和反向传播之间的间隔很大。</p>
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic7.png" class="">

<h3 id="解决方法：带优先级的参数切分"><a href="#解决方法：带优先级的参数切分" class="headerlink" title="解决方法：带优先级的参数切分"></a>解决方法：带优先级的参数切分</h3><p>在 MXNet 里面，worker 算完当层的梯度<br>就会提一个 pull request 当其他 work 同步了这个梯度。<br>问题在于发送的顺序和反向传播的顺序一致，并且颗粒度<br>是以 layer 为单位的。</p>
<p>根据领域知识将大 layer 分片成小 slice。<br>对每个 slice 进行权重排序，优先传输权重高的 slice。<br>被称为 Priority-Based Parameter Propagation</p>
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic8.png" class="">

<p>如图如果参数传输有优先级能够被中断就能减少 delay</p>
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic9.png" class="">

<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic10.png" class="">

<p>大部分模型每层的参数是不平衡的，特别是全连接的参数非常大。</p>
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic11.png" class="">

<p>对每一层切分以后利用 TCP 的全双工可以达到流水线的效果。</p>
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic12.png" class="">

<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic13.png" class="">

<h3 id="P3-的设计"><a href="#P3-的设计" class="headerlink" title="P3 的设计"></a>P3 的设计</h3><p>参数切片：根据领域知识和实验选择大小(50000)<br>参数优先级：下一层先需要的先发送，可以抢占低优先级的</p>
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic14.png" class="">

<p>我个人觉得简单，这个比上一个更好理解也简单。</p>
<h2 id="BlueConnect"><a href="#BlueConnect" class="headerlink" title="BlueConnect"></a>BlueConnect</h2><p>主要是一个对分层（原本的一层或者两层）的 All-Reduce 的泛化算法。<br>首先使用递归的方法可以减少 all-gather 的传输次数。</p>
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic15.png" class="">

<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic16.png" class="">

<p>这个只要三次 logp</p>
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic17.png" class="">
<p>ring reduce 要7次 (p-1)</p>
<h3 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h3><p>多卡之间的带宽很高 32GB/s，不同网络拓扑下，最慢的会成为瓶颈。<br>分两层可以解决网络和总线的带宽差异。</p>
<p>对于二层的一个泛化，</p>
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic18.png" class="">
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic20.png" class="">
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic19.png" class="">
<p>三层的 reduce-scatter 的例子，reduce-gather 是反的。</p>
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic21.png" class="">
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic22.png" class="">

<h2 id="BEYOND-DATA-AND-MODEL-PARALLELISM-FOR-DEEP-NEURAL-NETWORKS"><a href="#BEYOND-DATA-AND-MODEL-PARALLELISM-FOR-DEEP-NEURAL-NETWORKS" class="headerlink" title="BEYOND DATA AND MODEL PARALLELISM FOR DEEP NEURAL NETWORKS"></a>BEYOND DATA AND MODEL PARALLELISM FOR DEEP NEURAL NETWORKS</h2><p>这个主要是提到了并行程度除了数据和模型之外可以更细粒度到参数和属性，也就是模型的小划分和样本的小划分。<br>SOAP= Sample Attribute Operator Parameter</p>
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic23.png" class="">

<p>全连接层有大量的参数，造成传输瓶颈。<br>领域特定的优化：RNN 和 CNN 用 data 并行，最后全连接用 model 并行。</p>
<h3 id="搜索策略"><a href="#搜索策略" class="headerlink" title="搜索策略"></a>搜索策略</h3><img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic25.png" class="">

<p>找到最优并行策略是 NP 问题。<br>Execution Optimizer 通过找到最小 cost 的<br>并行策略寻找较优解。<br>Cost = tensor size/ bandwidth</p>
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic28.png" class="">

<p>随机从搜索空间选取策略，依据 MCMC<br>最够贪心，又不会太局部贪心。</p>
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic23.png" class="">

<p>总的来有点和 AutoML 类似，在一个搜索空间选择一个策略使得 cost 最低，一个是原本的 cost 函数，这个是<br>计算本身执行的时间。目前主流框架也不支持 SOAP 级别的并行划分，没手调的好，但很接近。</p>
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic26.png" class="">

<p>可以看到搜索出来的结果全连接基本上是单卡算的</p>
<img data-src="/zh-CN/2019/08/12/SysML2019-%E6%A6%82%E8%A7%881/pic27.png" class="">

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ggaaooppeenngg.github.io/zh-CN/2019/07/21/N-Body-%E9%97%AE%E9%A2%98%E4%B9%8B-CUDA-%E8%AE%A1%E7%AE%97/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ggaaooppeenngg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ggaaooppeenngg">
      <meta itemprop="description" content="为什么计算机科学是无限的但生命是有限的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ggaaooppeenngg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/zh-CN/2019/07/21/N-Body-%E9%97%AE%E9%A2%98%E4%B9%8B-CUDA-%E8%AE%A1%E7%AE%97/" class="post-title-link" itemprop="url">N Body 问题之 CUDA 计算</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-07-21 23:03:54" itemprop="dateCreated datePublished" datetime="2019-07-21T23:03:54+08:00">2019-07-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-28 18:39:05" itemprop="dateModified" datetime="2025-03-28T18:39:05+08:00">2025-03-28</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/zh-CN/2019/07/21/N-Body-%E9%97%AE%E9%A2%98%E4%B9%8B-CUDA-%E8%AE%A1%E7%AE%97/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="zh-CN/2019/07/21/N-Body-问题之-CUDA-计算/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <img data-src="/zh-CN/2019/07/21/N-Body-%E9%97%AE%E9%A2%98%E4%B9%8B-CUDA-%E8%AE%A1%E7%AE%97/2-body.gif" class="">

<p>行星运动我们都是按万有引力定律算的，实际上按照爱因斯坦的说法，万有引力不是惯性力是时空弯曲的效果，但是按照爱因斯坦的公式算起来特别复杂，所以现在航天轨道的设计还是按万有引力定律在算。</p>
<h2 id="牛顿万有引力定律"><a href="#牛顿万有引力定律" class="headerlink" title="牛顿万有引力定律"></a>牛顿万有引力定律</h2><p>牛顿万有引力定律：任意两个质点由通过连心线方向上的力相互吸引。该吸引力的大小与它们的质量乘积成正比，与它们距离的平方成反比，G 是万有引力常数。</p>
<p>$$ F=-\frac{G M \cdot m}{r^2} \cdot \frac{\vec{r}}{r} $$</p>
<h2 id="多体问题"><a href="#多体问题" class="headerlink" title="多体问题"></a>多体问题</h2><p>多体问题，是所有吸引力的叠加，这里排除物体相撞的情况，因为宇宙非常大，两个天体之间的距离非常远，暂时不考虑这种情况，通过加入一个小常量可以在计算上忽略这个问题。</p>
<p>$$ F=-\frac{G M  m r}{(r^2 + \epsilon^2)^{\frac{3}{2}}} $$</p>
<p>这样累加的时候自己也可以加进去，因为 r 是 0，那一项相当于没算。</p>
<p>$$ F_j= \sum_{i=1}^{n} F_i $$</p>
<p>对于 N body 有很多的稍微近似的算法，多是基于实际的物理场景的，比如大部分天体是属于一个星系的，每个星系之间都非常远，所以可以将一些星系作为整体计算，构建一颗树，树中的某些节点是其所有叶子的质心，这样就可以减少计算量，但是放到 GPU 的场景下一个 O(N^2) 的暴力算法利用 GPU 的并行能力可以非常快的算出来。</p>
<h3 id="Python-暴力解"><a href="#Python-暴力解" class="headerlink" title="Python 暴力解"></a>Python 暴力解</h3><p>下面是 N-Body 暴力实现的例子，网上有个各种语言实验的，比较好用来测试准确性，来自<a target="_blank" rel="noopener" href="https://rosettacode.org/wiki/N-body_problemhttps://rosettacode.org/wiki/N-body_problem">这里</a>，就是两层循环。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &lt;&lt;<span class="string">EOF &gt;&gt; nbody.txt</span></span><br><span class="line"><span class="string">0.01 3 20</span></span><br><span class="line"><span class="string">1</span></span><br><span class="line"><span class="string">0 0 0</span></span><br><span class="line"><span class="string">0.01 0 0</span></span><br><span class="line"><span class="string">0.1</span></span><br><span class="line"><span class="string">1 1 0</span></span><br><span class="line"><span class="string">0 0 0.02</span></span><br><span class="line"><span class="string">0.001</span></span><br><span class="line"><span class="string">0 1 1</span></span><br><span class="line"><span class="string">0.01 -0.01 -0.01</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"> </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Vector</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x, y, z</span>):</span><br><span class="line">        <span class="variable language_">self</span>.x = x</span><br><span class="line">        <span class="variable language_">self</span>.y = y</span><br><span class="line">        <span class="variable language_">self</span>.z = z</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__add__</span>(<span class="params">self, other</span>):</span><br><span class="line">        <span class="keyword">return</span> Vector(<span class="variable language_">self</span>.x + other.x, <span class="variable language_">self</span>.y + other.y, <span class="variable language_">self</span>.z + other.z)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__sub__</span>(<span class="params">self, other</span>):</span><br><span class="line">        <span class="keyword">return</span> Vector(<span class="variable language_">self</span>.x - other.x, <span class="variable language_">self</span>.y - other.y, <span class="variable language_">self</span>.z - other.z)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__mul__</span>(<span class="params">self, other</span>):</span><br><span class="line">        <span class="keyword">return</span> Vector(<span class="variable language_">self</span>.x * other, <span class="variable language_">self</span>.y * other, <span class="variable language_">self</span>.z * other)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__div__</span>(<span class="params">self, other</span>):</span><br><span class="line">        <span class="keyword">return</span> Vector(<span class="variable language_">self</span>.x / other, <span class="variable language_">self</span>.y / other, <span class="variable language_">self</span>.z / other)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__eq__</span>(<span class="params">self, other</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(other, Vector):</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.x == other.x <span class="keyword">and</span> <span class="variable language_">self</span>.y == other.y <span class="keyword">and</span> <span class="variable language_">self</span>.z == other.z</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__ne__</span>(<span class="params">self, other</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">not</span> <span class="variable language_">self</span>.__eq__(other)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;(&#123;x&#125;, &#123;y&#125;, &#123;z&#125;)&#x27;</span>.<span class="built_in">format</span>(x=<span class="variable language_">self</span>.x, y=<span class="variable language_">self</span>.y, z=<span class="variable language_">self</span>.z)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">abs</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> math.sqrt(<span class="variable language_">self</span>.x*<span class="variable language_">self</span>.x + <span class="variable language_">self</span>.y*<span class="variable language_">self</span>.y + <span class="variable language_">self</span>.z*<span class="variable language_">self</span>.z)</span><br><span class="line"> </span><br><span class="line">origin = Vector(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NBody</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, fileName</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(fileName, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> fh:</span><br><span class="line">            lines = fh.readlines()</span><br><span class="line">            gbt = lines[<span class="number">0</span>].split()</span><br><span class="line">            <span class="variable language_">self</span>.gc = <span class="built_in">float</span>(gbt[<span class="number">0</span>])</span><br><span class="line">            <span class="variable language_">self</span>.bodies = <span class="built_in">int</span>(gbt[<span class="number">1</span>])</span><br><span class="line">            <span class="variable language_">self</span>.timeSteps = <span class="built_in">int</span>(gbt[<span class="number">2</span>])</span><br><span class="line">            <span class="variable language_">self</span>.masses = [<span class="number">0.0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.bodies)]</span><br><span class="line">            <span class="variable language_">self</span>.positions = [origin <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.bodies)]</span><br><span class="line">            <span class="variable language_">self</span>.velocities = [origin <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.bodies)]</span><br><span class="line">            <span class="variable language_">self</span>.accelerations = [origin <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.bodies)]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.bodies):</span><br><span class="line">                <span class="variable language_">self</span>.masses[i] = <span class="built_in">float</span>(lines[i*<span class="number">3</span> + <span class="number">1</span>])</span><br><span class="line">                <span class="variable language_">self</span>.positions[i] = <span class="variable language_">self</span>.__decompose(lines[i*<span class="number">3</span> + <span class="number">2</span>])</span><br><span class="line">                <span class="variable language_">self</span>.velocities[i] = <span class="variable language_">self</span>.__decompose(lines[i*<span class="number">3</span> + <span class="number">3</span>])</span><br><span class="line"> </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Contents of&quot;</span>, fileName)</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">                <span class="built_in">print</span>(line.rstrip())</span><br><span class="line">            <span class="built_in">print</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Body   :      x          y          z    |&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;     vx         vy         vz&quot;</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__decompose</span>(<span class="params">self, line</span>):</span><br><span class="line">        xyz = line.split()</span><br><span class="line">        x = <span class="built_in">float</span>(xyz[<span class="number">0</span>])</span><br><span class="line">        y = <span class="built_in">float</span>(xyz[<span class="number">1</span>])</span><br><span class="line">        z = <span class="built_in">float</span>(xyz[<span class="number">2</span>])</span><br><span class="line">        <span class="keyword">return</span> Vector(x, y, z)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__computeAccelerations</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.bodies):</span><br><span class="line">            <span class="variable language_">self</span>.accelerations[i] = origin</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.bodies):</span><br><span class="line">                <span class="keyword">if</span> i != j:</span><br><span class="line">                    temp = <span class="variable language_">self</span>.gc * <span class="variable language_">self</span>.masses[j] / math.<span class="built_in">pow</span>((<span class="variable language_">self</span>.positions[i] - <span class="variable language_">self</span>.positions[j]).<span class="built_in">abs</span>(), <span class="number">3</span>)</span><br><span class="line">                    <span class="variable language_">self</span>.accelerations[i] += (<span class="variable language_">self</span>.positions[j] - <span class="variable language_">self</span>.positions[i]) * temp</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__computePositions</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.bodies):</span><br><span class="line">            <span class="variable language_">self</span>.positions[i] += <span class="variable language_">self</span>.velocities[i] + <span class="variable language_">self</span>.accelerations[i] * <span class="number">0.5</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__computeVelocities</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.bodies):</span><br><span class="line">            <span class="variable language_">self</span>.velocities[i] += <span class="variable language_">self</span>.accelerations[i]</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__resolveCollisions</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.bodies):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.bodies):</span><br><span class="line">                <span class="keyword">if</span> <span class="variable language_">self</span>.positions[i] == <span class="variable language_">self</span>.positions[j]:</span><br><span class="line">                    (<span class="variable language_">self</span>.velocities[i], <span class="variable language_">self</span>.velocities[j]) = (<span class="variable language_">self</span>.velocities[j], <span class="variable language_">self</span>.velocities[i])</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">simulate</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.__computeAccelerations()</span><br><span class="line">        <span class="variable language_">self</span>.__computePositions()</span><br><span class="line">        <span class="variable language_">self</span>.__computeVelocities()</span><br><span class="line">        <span class="variable language_">self</span>.__resolveCollisions()</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">printResults</span>(<span class="params">self</span>):</span><br><span class="line">        fmt = <span class="string">&quot;Body %d : % 8.6f  % 8.6f  % 8.6f | % 8.6f  % 8.6f  % 8.6f&quot;</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.bodies):</span><br><span class="line">            <span class="built_in">print</span>(fmt % (i+<span class="number">1</span>, <span class="variable language_">self</span>.positions[i].x, <span class="variable language_">self</span>.positions[i].y, <span class="variable language_">self</span>.positions[i].z, <span class="variable language_">self</span>.velocities[i].x, <span class="variable language_">self</span>.velocities[i].y, <span class="variable language_">self</span>.velocities[i].z))</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"> </span><br><span class="line">nb = NBody(<span class="string">&quot;nbody.txt&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nb.timeSteps):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\nCycle %d&quot;</span> % (i + <span class="number">1</span>))</span><br><span class="line">    nb.simulate()</span><br><span class="line">    nb.printResults()</span><br></pre></td></tr></table></figure>

<h3 id="CUDA-并行计算"><a href="#CUDA-并行计算" class="headerlink" title="CUDA 并行计算"></a>CUDA 并行计算</h3><p>在 CUDA 中并行化首先要理解 CUDA 的层次结构，CUDA 有 grid 和 block 对线程做划分。首先设计一个 computation tile，相当于一个 block 的计算。</p>
<img data-src="/zh-CN/2019/07/21/N-Body-%E9%97%AE%E9%A2%98%E4%B9%8B-CUDA-%E8%AE%A1%E7%AE%97/cuda-tile.png" class="">

<p>左侧表示一个 block 中的 p 个 body 执行 p 次，最后就能更新所有 body 的加速度，这里的内存占用是 O(p) 的不是 O(p^2)，浅绿色表示的是串行执行的流，官方的文档没有更新，对应 CUDA 10 的例子里是这样的，vec3 存的是 x/y/z 轴的加速度，vec4 存的是坐标加质量，就是计算 i 受到 j 的加速度，这里没有并行设计是串行的。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">__device__ <span class="keyword">typename</span> vec3&lt;T&gt;::<span class="function">Type</span></span><br><span class="line"><span class="function"><span class="title">bodyBodyInteraction</span><span class="params">(<span class="keyword">typename</span> vec3&lt;T&gt;::Type ai,</span></span></span><br><span class="line"><span class="params"><span class="function">                    <span class="keyword">typename</span> vec4&lt;T&gt;::Type bi,</span></span></span><br><span class="line"><span class="params"><span class="function">                    <span class="keyword">typename</span> vec4&lt;T&gt;::Type bj)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">typename</span> vec3&lt;T&gt;::Type r;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// r_ij  [3 FLOPS]</span></span><br><span class="line">    r.x = bj.x - bi.x;</span><br><span class="line">    r.y = bj.y - bi.y;</span><br><span class="line">    r.z = bj.z - bi.z;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// distSqr = dot(r_ij, r_ij) + EPS^2  [6 FLOPS]</span></span><br><span class="line">    T distSqr = r.x * r.x + r.y * r.y + r.z * r.z;</span><br><span class="line">    distSqr += <span class="built_in">getSofteningSquared</span>&lt;T&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// invDistCube =1/distSqr^(3/2)  [4 FLOPS (2 mul, 1 sqrt, 1 inv)]</span></span><br><span class="line">    T invDist = <span class="built_in">rsqrt_T</span>(distSqr);</span><br><span class="line">    T invDistCube =  invDist * invDist * invDist;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// s = m_j * invDistCube [1 FLOP]</span></span><br><span class="line">    T s = bj.w * invDistCube;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// a_i =  a_i + s * r_ij [6 FLOPS]</span></span><br><span class="line">    ai.x += r.x * s;</span><br><span class="line">    ai.y += r.y * s;</span><br><span class="line">    ai.z += r.z * s;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ai;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>block 的 tile computation 就是串行计算 p 次 p 个 body 的加速度。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">unsigned</span> <span class="type">int</span> counter = <span class="number">0</span>; counter &lt; blockDim.x; counter++)</span><br><span class="line">&#123;</span><br><span class="line">    acc = <span class="built_in">bodyBodyInteraction</span>&lt;T&gt;(acc, bodyPos, sharedPos[counter]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>每次计算完了以后要对线程做共享内存的同步</p>
<img data-src="/zh-CN/2019/07/21/N-Body-%E9%97%AE%E9%A2%98%E4%B9%8B-CUDA-%E8%AE%A1%E7%AE%97/sync-title.png" class="">

<p>黑实线就是一次  block 共享内存同步的边界，也就是一次 tile compuation，图中是 p 个 body 按时间串行执行的流程，超出 p 的时间计算的不是 p 中的 body，看下面这张图。</p>
<img data-src="/zh-CN/2019/07/21/N-Body-%E9%97%AE%E9%A2%98%E4%B9%8B-CUDA-%E8%AE%A1%E7%AE%97/global-sync.png" class="">

<p>也就是按照时间串行的计算每个 body 对一个 body 的加速度，然后 N/p 个 block 并行，每个 block 有 p 个线程并行，没 p 次计算每个 block 要同步一次，但是多个 block 之间不需要同步，所以每个并行线程的主体是这样的要在 tile computation 之间包一层同步的调用 cg::sync(ca)，同步一次 block 中线程的共享内存。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">__device__ <span class="keyword">typename</span> vec3&lt;T&gt;::<span class="function">Type</span></span><br><span class="line"><span class="function"><span class="title">computeBodyAccel</span><span class="params">(<span class="keyword">typename</span> vec4&lt;T&gt;::Type bodyPos,</span></span></span><br><span class="line"><span class="params"><span class="function">                 <span class="keyword">typename</span> vec4&lt;T&gt;::Type *positions,</span></span></span><br><span class="line"><span class="params"><span class="function">                 <span class="type">int</span> numTiles, cg::thread_block cta)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">typename</span> vec4&lt;T&gt;::Type *sharedPos = SharedMemory&lt;<span class="keyword">typename</span> vec4&lt;T&gt;::Type&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">typename</span> vec3&lt;T&gt;::Type acc = &#123;<span class="number">0.0f</span>, <span class="number">0.0f</span>, <span class="number">0.0f</span>&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> tile = <span class="number">0</span>; tile &lt; numTiles; tile++)</span><br><span class="line">    &#123;</span><br><span class="line">        sharedPos[threadIdx.x] = positions[tile * blockDim.x + threadIdx.x];</span><br><span class="line"></span><br><span class="line">        cg::<span class="built_in">sync</span>(cta);</span><br><span class="line">        <span class="comment">// This is the &quot;tile_calculation&quot; from the GPUG3 article.</span></span><br><span class="line"><span class="meta">#<span class="keyword">pragma</span> unroll 128</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">unsigned</span> <span class="type">int</span> counter = <span class="number">0</span>; counter &lt; blockDim.x; counter++)</span><br><span class="line">        &#123;</span><br><span class="line">            acc = <span class="built_in">bodyBodyInteraction</span>&lt;T&gt;(acc, bodyPos, sharedPos[counter]);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        cg::<span class="built_in">sync</span>(cta);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> acc;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从 GPU 的角度来看，时间复杂度是 O(N)，空间复杂度也是 O(N)，但前提是要开 N 个线程同时计算。</p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a target="_blank" rel="noopener" href="https://developer.download.nvidia.com/compute/cuda/1.1-Beta/x86_website/projects/nbody/doc/nbody_gems3_ch31.pdf">n body nvidia</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/astro-ph/0202512">O(N) 算法计算天体运动</a></p>
<p><a target="_blank" rel="noopener" href="https://rosettacode.org/wiki/N-body_problem">n body problem</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ggaaooppeenngg.github.io/zh-CN/2019/03/03/tf-%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E5%92%8C%E5%86%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ggaaooppeenngg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ggaaooppeenngg">
      <meta itemprop="description" content="为什么计算机科学是无限的但生命是有限的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ggaaooppeenngg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/zh-CN/2019/03/03/tf-%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E5%92%8C%E5%86%BB%E7%BB%93/" class="post-title-link" itemprop="url">tensorflow 模型的存档、保存、冻结、优化</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-03-03 02:29:46" itemprop="dateCreated datePublished" datetime="2019-03-03T02:29:46+08:00">2019-03-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-28 18:39:05" itemprop="dateModified" datetime="2025-03-28T18:39:05+08:00">2025-03-28</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/zh-CN/2019/03/03/tf-%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E5%92%8C%E5%86%BB%E7%BB%93/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="zh-CN/2019/03/03/tf-模型的保存和冻结/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>模型的保存分三种类型</p>
<ol>
<li> 知道模型结构，单纯保存变量</li>
<li> 不知道模型结构，保存模型和变量</li>
<li> 不需要再改变量，只要常量化的模型（“冻结”）</li>
</ol>
<p>第一种用于训练的存档，并且临时恢复，这个时候用户是把训练需要的网络结构在代码里面构造好了的，只是在一定的时间下需要暂时保存网络中的变量，为了在崩溃之后继续训练。所以自然而然会有一个问题，如果我用 Python 写的代码，需要在 C++ 当中恢复，我需要知道你的模型结构，才能恢复，这个最蠢的办法是用 C++ 把你的网络结构再构造一遍，但我们按照统一的协议（比如 Protobuf）确定网络结构，就可以直接从标准序列化的数据中解析网络结构，这就是第二种情况，独立于语言，模型和变量一起保存的情况。然后如果碰到我们不需要再训练了，比如只是把这个模型进行部署，不需要改变相关的变量，那么其实只要一个带常量的模型就可以，这就是第三种情况，把变量冻结的正向传播模型。接下来会依次解释这几种情况的工作方式。</p>
<p>除了这些以外，针对用于服务的模型还可以做很多的优化。</p>
<h2 id="存档"><a href="#存档" class="headerlink" title="存档"></a>存档</h2><p>存档只是单纯的保存变量，并且能够恢复，可以在一定的迭代次数以后保存变量，并且从任意一个存档开始重新训练。以两个变量加减 1 为例。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line"># Create some variables.</span><br><span class="line">v1 = tf.get_variable(&quot;v1&quot;, shape=[3], initializer = tf.zeros_initializer)</span><br><span class="line">v2 = tf.get_variable(&quot;v2&quot;, shape=[5], initializer = tf.zeros_initializer)</span><br><span class="line"></span><br><span class="line">inc_v1 = v1.assign(v1+1)</span><br><span class="line">dec_v2 = v2.assign(v2-1)</span><br><span class="line"></span><br><span class="line"># Add an op to initialize the variables.</span><br><span class="line">init_op = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"># Add ops to save and restore all the variables.</span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line"># Later, launch the model, initialize the variables, do some work, and save the</span><br><span class="line"># variables to disk.</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">  sess.run(init_op)</span><br><span class="line">  # Do some work with the model.</span><br><span class="line">  inc_v1.op.run()</span><br><span class="line">  dec_v2.op.run()</span><br><span class="line">  # Save the variables to disk.</span><br><span class="line">  save_path = saver.save(sess, &quot;/tmp/tf-test/model.ckpt&quot;)</span><br><span class="line">  print(&quot;Model saved in path: %s&quot; % save_path)</span><br></pre></td></tr></table></figure>

<p>可以在 <code>/tmp/tf-test</code> 下面看到这几个文件 <code>checkpoint                     model.ckpt.data-00000-of-00001 model.ckpt.index               model.ckpt.meta</code>。</p>
<p>可以通过脚本观察保存的变量 <code>python  $tensorflow-src/tensorflow/python/tools/inspect_checkpoint.py --file_name=/tmp/tf-test/model.ckpt  --all_tensors</code></p>
<p>得到保存的变量的内容，注意 <code>model.ckpt</code> 这个只是文件前缀。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor_name:  v1</span><br><span class="line">[1. 1. 1.]</span><br><span class="line">tensor_name:  v2</span><br><span class="line">[-1. -1. -1. -1. -1.]</span><br></pre></td></tr></table></figure>
<p>如果要恢复的话，可以通过下面的代码。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line"># Create some variables.</span><br><span class="line">v1 = tf.get_variable(&quot;v1&quot;, shape=[3])</span><br><span class="line">v2 = tf.get_variable(&quot;v2&quot;, shape=[5])</span><br><span class="line"></span><br><span class="line"># Add ops to save and restore all the variables.</span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line"># Later, launch the model, use the saver to restore variables from disk, and</span><br><span class="line"># do some work with the model.</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">  # Restore variables from disk.</span><br><span class="line">  saver.restore(sess, &quot;/tmp/tf-test/model.ckpt&quot;)</span><br><span class="line">  print(&quot;Model restored.&quot;)</span><br><span class="line">  # Check the values of the variables</span><br><span class="line">  print(&quot;v1 : %s&quot; % v1.eval())</span><br><span class="line">  print(&quot;v2 : %s&quot; % v2.eval())</span><br></pre></td></tr></table></figure>
<p>得到一样的效果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">v1 : [1. 1. 1.]</span><br><span class="line">v2 : [-1. -1. -1. -1. -1.]</span><br></pre></td></tr></table></figure>
<p>具体来说 .meta 对应的是 MetaGraph 和 SaverGraph，.index 对应的是变量值的位置，key 是变量名，value 是变量保存的入口定义，data 变量的值具体保存的文件。这是恢复代码中已经原样构造出了 Graph，如果没有构造的化，需要通过 <code>tf.train.import_meta_graph(&#39;/tmp/model.ckpt.meta&#39;)</code> 来加载，但是存档保存的信息比较单一，Tensorflow 提供了一个更丰富的 API 来使用。</p>
<h2 id="保存"><a href="#保存" class="headerlink" title="保存"></a>保存</h2><p><code>SavedModelBuilder</code> 保存的 API 比较丰富，能够保存多个 MetaGraph 和 Variables 的组合，除此之外还能附带 assets，并且要指定模型签名，<code>simple_saved</code> 的方法是一个简单版本的调用，适用于 Predict API。这里要展开一下 GraphDef, MetaGraphDef, SignatureDef, tags 这些东西的概念。对于 MetaGraph，<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_38542085/article/details/78554550">这篇文章</a>解释得很清楚。SignatureDef 是对应了一种图的输入和输出，可以依据这个进行 serving API 的调用，类似于函数签名，相对于一个接口的定义。</p>
<p>tensorflow_serving 自己给了个<a target="_blank" rel="noopener" href="https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/mnist_saved_model.py">例子</a>，执行 <code>python mnist_saved_model.py /tmp/tf-test-2</code> 以后可以获得一个目录，下面有版本 1 的模型数据，执行 <code>saved_model_cli show --dir  /tmp/tf-test-2/1</code> 可以查看对应的签名。可以看到对应的层级关系，默认用于服务的模型会打上 serve 的标签，函数签名有两个，分别对应了 predict 和 classify 的方法。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">MetaGraphDef with tag-set: &#x27;serve&#x27; contains the following SignatureDefs:</span><br><span class="line"></span><br><span class="line">signature_def[&#x27;predict_images&#x27;]:</span><br><span class="line">  The given SavedModel SignatureDef contains the following input(s):</span><br><span class="line">    inputs[&#x27;images&#x27;] tensor_info:</span><br><span class="line">        dtype: DT_FLOAT</span><br><span class="line">        shape: (-1, 784)</span><br><span class="line">        name: x:0</span><br><span class="line">  The given SavedModel SignatureDef contains the following output(s):</span><br><span class="line">    outputs[&#x27;scores&#x27;] tensor_info:</span><br><span class="line">        dtype: DT_FLOAT</span><br><span class="line">        shape: (-1, 10)</span><br><span class="line">        name: y:0</span><br><span class="line">  Method name is: tensorflow/serving/predict</span><br><span class="line"></span><br><span class="line">signature_def[&#x27;serving_default&#x27;]:</span><br><span class="line">  The given SavedModel SignatureDef contains the following input(s):</span><br><span class="line">    inputs[&#x27;inputs&#x27;] tensor_info:</span><br><span class="line">        dtype: DT_STRING</span><br><span class="line">        shape: unknown_rank</span><br><span class="line">        name: tf_example:0</span><br><span class="line">  The given SavedModel SignatureDef contains the following output(s):</span><br><span class="line">    outputs[&#x27;classes&#x27;] tensor_info:</span><br><span class="line">        dtype: DT_STRING</span><br><span class="line">        shape: (-1, 10)</span><br><span class="line">        name: index_to_string_Lookup:0</span><br><span class="line">    outputs[&#x27;scores&#x27;] tensor_info:</span><br><span class="line">        dtype: DT_FLOAT</span><br><span class="line">        shape: (-1, 10)</span><br><span class="line">        name: TopKV2:0</span><br><span class="line">  Method name is: tensorflow/serving/classify</span><br></pre></td></tr></table></figure>
<p>可以参考 tensorflow 的 <a target="_blank" rel="noopener" href="https://www.tensorflow.org/tfx/serving/api_rest">REST API</a>，比如 <code>GET http://host:port/v1/models/$&#123;MODEL_NAME&#125;[/versions/$&#123;MODEL_VERSION&#125;]</code> 其实对应这个例子就是 <code>GET http://host:port/v1/models/tf-test-2/versions/1</code>，然后感觉函数签名不同的 method name，可以调用不同的 request，比如 <code>POST http://host:port/v1/models/$&#123;MODEL_NAME&#125;[/versions/$&#123;MODEL_VERSION&#125;]:predict</code> 这个格式，如果输入和输出对应的是 <code>images</code> 和 <code>scores</code> 那么就对应了第一个签名。</p>
<h2 id="冻结"><a href="#冻结" class="headerlink" title="冻结"></a>冻结</h2><p>冻结的情况就是变量不再需要修改，直接把变量转化成常量保存成单一的模型，方便在部署的场景下使用。<br>冻结模型的代码在<a target="_blank" rel="noopener" href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py">这里</a>，他的主要流程如下</p>
<ol>
<li>清除所有 Op 中的 device，让原来在指定 CPU/GPU/节点 上的 Op 不再绑定。</li>
<li>通过 <code>graph_util.convert_variables_to_constants</code> 将所有的 Variable <code>eval</code> 一次，把变量的 Op 的结果拿到，替换成 constant</li>
</ol>
<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>除了冻结模型以外，还可以删减一些多余的节点，比如 Summary 节点或者 Identity 节点，甚者把 16bit 的浮点数权重修改为 8bit 的浮点数权重（这个在 Tensorflow Lite 里很有用）。<a target="_blank" rel="noopener" href="https://medium.com/google-cloud/optimizing-tensorflow-models-for-serving-959080e9ddbf">这篇文章</a> 列出了详细的优化方式，主要是靠 <code>transform_graph</code> 这个工具，地址在<a target="_blank" rel="noopener" href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md">这</a>，他有很详细的柴剪列表，并且可以自己编写裁剪函数，充分做到模型在部署环节的“纯净化”，调用方式也很简单。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">transform_graph \</span><br><span class="line">--in_graph=tensorflow_inception_graph.pb \</span><br><span class="line">--out_graph=optimized_inception_graph.pb \</span><br><span class="line">--inputs=&#x27;Mul:0&#x27; \</span><br><span class="line">--outputs=&#x27;softmax:0&#x27; \</span><br><span class="line">--transforms=&#x27;</span><br><span class="line">strip_unused_nodes(type=float, shape=&quot;1,299,299,3&quot;)</span><br><span class="line">remove_nodes(op=Identity, op=CheckNumerics)</span><br><span class="line">fold_old_batch_norms</span><br><span class="line">&#x27;</span><br></pre></td></tr></table></figure>
<p>在<code>transforms</code>里面加入你想进行优化的 transformer 和对应的参数即可，在科赛上也有在线可以跑的<a target="_blank" rel="noopener" href="https://www.kesci.com/home/project/5c8219e31e7104002b3747d6">notebook</a></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a target="_blank" rel="noopener" href="https://cloud.google.com/ml-engine/docs/tensorflow/deploying-models#build_an_optimal_prediction_graph">Cloud ML Engine</a></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2014 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">ggaaooppeenngg</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.umd.js" integrity="sha256-a+H7FYzJv6oU2hfsfDGM2Ohw/cR9v+hPfxHCLdmCrE8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  



  <script src="/js/third-party/fancybox.js"></script>



  




<script class="next-config" data-name="disqus" type="application/json">{"enable":true,"shortname":"ggaaooppeenngg","count":true,"i18n":{"disqus":"disqus"}}</script>
<script src="/js/third-party/comments/disqus.js"></script>

</body>
</html>
