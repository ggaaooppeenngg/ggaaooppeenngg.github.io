<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="_85tctgPWrqH2EPVuuD5IT6KE-tW8nH0hTISJDMnShg">
  <meta name="baidu-site-verification" content="bb16c5b1fd3302c18e0015bef11eea42">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"ggaaooppeenngg.github.io","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.22.0","exturl":false,"sidebar":{"position":"right","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12,"onmobile":false},"hljswrap":true,"copycode":{"enable":true,"style":"default"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="从一些大模型的训练技术报告来看有一些比较有代表性的挑战，比如 Meta 的 Research Super Compute (RSC) 和 X 的 Grok Infra。这些技术报告中提到了一些关键的技术挑战和解决方案，包括 GPU 架构与互联、存储系统、训练的稳定性等。 X Grok Infra从 Grok-1.5 Infra 的技术报告中可以窥见，Grok-1.5 在基础设施方面具有以下核心优势">
<meta property="og:type" content="article">
<meta property="og:title" content="AI Infra 的一些挑战">
<meta property="og:url" content="https://ggaaooppeenngg.github.io/zh-CN/2025/02/16/AI-Infra-%E7%9A%84%E4%B8%BB%E8%A6%81%E6%8C%91%E6%88%98%E6%80%BB%E7%BB%93/index.html">
<meta property="og:site_name" content="ggaaooppeenngg">
<meta property="og:description" content="从一些大模型的训练技术报告来看有一些比较有代表性的挑战，比如 Meta 的 Research Super Compute (RSC) 和 X 的 Grok Infra。这些技术报告中提到了一些关键的技术挑战和解决方案，包括 GPU 架构与互联、存储系统、训练的稳定性等。 X Grok Infra从 Grok-1.5 Infra 的技术报告中可以窥见，Grok-1.5 在基础设施方面具有以下核心优势">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-02-16T08:08:40.000Z">
<meta property="article:modified_time" content="2025-03-28T10:51:03.508Z">
<meta property="article:author" content="ggaaooppeenngg">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="Infra">
<meta property="article:tag" content="AI Infra">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://ggaaooppeenngg.github.io/zh-CN/2025/02/16/AI-Infra-%E7%9A%84%E4%B8%BB%E8%A6%81%E6%8C%91%E6%88%98%E6%80%BB%E7%BB%93/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://ggaaooppeenngg.github.io/zh-CN/2025/02/16/AI-Infra-%E7%9A%84%E4%B8%BB%E8%A6%81%E6%8C%91%E6%88%98%E6%80%BB%E7%BB%93/","path":"zh-CN/2025/02/16/AI-Infra-的主要挑战总结/","title":"AI Infra 的一些挑战"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>AI Infra 的一些挑战 | ggaaooppeenngg</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-62096626-1"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"UA-62096626-1","only_pageview":false,"measure_protocol_api_secret":null}</script>
  <script src="/js/third-party/analytics/google-analytics.js"></script>

  <script src="/js/third-party/analytics/baidu-analytics.js"></script>
  <script async src="https://hm.baidu.com/hm.js?bb16c5b1fd3302c18e0015bef11eea42"></script>







  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">ggaaooppeenngg</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">为什么计算机科学是无限的但生命是有限的</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签<span class="badge">136</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="th fa-fw"></i>分类<span class="badge">14</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档<span class="badge">80</span></a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#X-Grok-Infra"><span class="nav-number">1.</span> <span class="nav-text">X Grok Infra</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Meta-Reasearch-Super-Compute"><span class="nav-number">2.</span> <span class="nav-text">Meta Reasearch Super Compute</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%97%E5%8A%9B%E8%A7%84%E6%A8%A1"><span class="nav-number">2.1.</span> <span class="nav-text">算力规模</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E4%BA%92%E8%81%94"><span class="nav-number">2.2.</span> <span class="nav-text">网络互联</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E6%8B%93%E6%89%91"><span class="nav-number">2.2.1.</span> <span class="nav-text">网络拓扑</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1"><span class="nav-number">2.2.2.</span> <span class="nav-text">负载均衡</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6"><span class="nav-number">2.2.3.</span> <span class="nav-text">拥塞控制</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F"><span class="nav-number">2.3.</span> <span class="nav-text">存储系统</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">3.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GPU-%E6%9E%B6%E6%9E%84%E4%B8%8E%E4%BA%92%E8%81%94"><span class="nav-number">4.</span> <span class="nav-text">GPU 架构与互联</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#GPU%E4%BA%92%E8%81%94%E6%8B%93%E6%89%91"><span class="nav-number">4.1.</span> <span class="nav-text">GPU互联拓扑</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GPU%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><span class="nav-number">4.2.</span> <span class="nav-text">GPU分配策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B7%A8%E8%8A%82%E7%82%B9%E7%9A%84%E9%80%9A%E4%BF%A1"><span class="nav-number">4.3.</span> <span class="nav-text">跨节点的通信</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%A9%E7%94%A8-Kubernetes-Pod-%E4%BA%B2%E5%92%8C%E6%80%A7%E4%BC%98%E5%8C%96%E7%BD%91%E7%BB%9C%E6%8B%93%E6%89%91"><span class="nav-number">4.4.</span> <span class="nav-text">利用 Kubernetes Pod 亲和性优化网络拓扑</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F-1"><span class="nav-number">5.</span> <span class="nav-text">存储系统</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E6%B5%B7%E9%87%8F%E5%B0%8F%E6%96%87%E4%BB%B6%E9%97%AE%E9%A2%98"><span class="nav-number">5.1.</span> <span class="nav-text">1. 海量小文件问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Checkpoint-%E5%AD%98%E5%82%A8%E6%8C%91%E6%88%98"><span class="nav-number">5.2.</span> <span class="nav-text">2. Checkpoint 存储挑战</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E7%9A%84%E7%A8%B3%E5%AE%9A%E6%80%A7"><span class="nav-number">6.</span> <span class="nav-text">训练的稳定性</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E-torchrun-%E7%9A%84%E5%BC%B9%E6%80%A7%E8%AE%AD%E7%BB%83"><span class="nav-number">6.1.</span> <span class="nav-text">基于 torchrun 的弹性训练</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E-DeepSpeed-%E7%9A%84%E5%BC%B9%E6%80%A7%E8%AE%AD%E7%BB%83"><span class="nav-number">6.2.</span> <span class="nav-text">基于 DeepSpeed 的弹性训练</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%B9%E6%80%A7%E8%AE%AD%E7%BB%83%E6%8E%A7%E5%88%B6%E5%99%A8"><span class="nav-number">6.3.</span> <span class="nav-text">弹性训练控制器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%8A%82%E7%82%B9%E7%9A%84%E9%97%AE%E9%A2%98%E5%8F%91%E7%8E%B0"><span class="nav-number">6.4.</span> <span class="nav-text">节点的问题发现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93-1"><span class="nav-number">7.</span> <span class="nav-text">总结</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">ggaaooppeenngg</p>
  <div class="site-description" itemprop="description">为什么计算机科学是无限的但生命是有限的</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">80</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">136</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/ggaaooppeenngg" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;ggaaooppeenngg" rel="noopener me" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:peng.gao.dut@gmail.com" title="E-Mail → mailto:peng.gao.dut@gmail.com" rel="noopener me" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ggaaooppeenngg.github.io/zh-CN/2025/02/16/AI-Infra-%E7%9A%84%E4%B8%BB%E8%A6%81%E6%8C%91%E6%88%98%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ggaaooppeenngg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ggaaooppeenngg">
      <meta itemprop="description" content="为什么计算机科学是无限的但生命是有限的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="AI Infra 的一些挑战 | ggaaooppeenngg">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          AI Infra 的一些挑战
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-02-16 16:08:40" itemprop="dateCreated datePublished" datetime="2025-02-16T16:08:40+08:00">2025-02-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-28 18:51:03" itemprop="dateModified" datetime="2025-03-28T18:51:03+08:00">2025-03-28</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/zh-CN/2025/02/16/AI-Infra-%E7%9A%84%E4%B8%BB%E8%A6%81%E6%8C%91%E6%88%98%E6%80%BB%E7%BB%93/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="zh-CN/2025/02/16/AI-Infra-的主要挑战总结/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>从一些大模型的训练技术报告来看有一些比较有代表性的挑战，比如 Meta 的 Research Super Compute (RSC) 和 X 的 Grok Infra。这些技术报告中提到了一些关键的技术挑战和解决方案，包括 GPU 架构与互联、存储系统、训练的稳定性等。</p>
<h2 id="X-Grok-Infra"><a href="#X-Grok-Infra" class="headerlink" title="X Grok Infra"></a>X Grok Infra</h2><p>从 <a target="_blank" rel="noopener" href="https://x.ai/blog/grok-1.5">Grok-1.5 Infra</a> 的技术报告中可以窥见，Grok-1.5 在基础设施方面具有以下核心优势：</p>
<ol>
<li>先进的分布式训练框架：基于 JAX、Rust 和 Kubernetes 的技术栈，不仅确保了高性能，还能快速适配和训练新的模型架构。</li>
<li>卓越的可靠性和可用性：通过自研的训练协调器，系统能够智能地检测并隔离故障节点，大幅降低训练任务中断的风险。</li>
<li>高效的存储与数据处理：在检查点存储、数据加载和训练作业重启等环节都进行了深度优化，将训练过程中的停机时间降至最低。</li>
</ol>
<h2 id="Meta-Reasearch-Super-Compute"><a href="#Meta-Reasearch-Super-Compute" class="headerlink" title="Meta Reasearch Super Compute"></a>Meta Reasearch Super Compute</h2><p>另一个典型案例是 Meta 的 <a target="_blank" rel="noopener" href="https://engineering.fb.com/2024/03/12/data-center-engineering/building-metas-genai-infrastructure/">Research Super Compute (RSC)</a> 超算集群，在这上面训练了Llama3.2，有一份92页的<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.21783">技术报告</a>，RSC的<a target="_blank" rel="noopener" href="https://www.usenix.org/conference/osdi24/presentation/choudhury">相关Talk</a>，以及里面用到的<a target="_blank" rel="noopener" href="https://www.usenix.org/system/files/osdi24-choudhury.pdf">MAST论文</a>调度器：</p>
<h3 id="算力规模"><a href="#算力规模" class="headerlink" title="算力规模"></a>算力规模</h3><p>已升级至 16,000 张 H100 GPU，算力获得质的飞跃。每个服务器配备了 8 块 GPU 和 2 块 CPU。在服务器内部，八块 GPU 通过 NVLink 连接。</p>
<h3 id="网络互联"><a href="#网络互联" class="headerlink" title="网络互联"></a>网络互联</h3><p>采用双网络方案：</p>
<ul>
<li><strong>NVIDIA Quantum InfiniBand</strong>，带宽高达 1600 Gb/s，RoCE（RDMA over Converged Ethernet）作为补充互联方案。</li>
</ul>
<h4 id="网络拓扑"><a href="#网络拓扑" class="headerlink" title="网络拓扑"></a>网络拓扑</h4><ul>
<li><strong>底层网络（第一个层）</strong>：每个机架（rack）包含 16 块 GPU，分散在两个服务器上，并通过一个 Minipack2 顶层网络（ToR）交换机连接。</li>
<li><strong>中间网络（第二层）</strong>：192 个这样的机架通过 Cluster Switches 连接，形成一个包含 3,072 块 GPU 的 Pod。这种设计确保了从任何两个 GPU 之间的通信都有满速带宽，没有过度订阅。</li>
<li><strong>顶层网络（第三层）</strong>：八个这样的 Pod 通过 Aggregation Switches 连接，形成一个包含 24,000 块 GPU 的集群。然而，顶层网络的连接没有保持满速带宽，而是存在过度订阅比例为 1：7。</li>
</ul>
<h4 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h4><ul>
<li><strong>Collective library</strong> 将 16 个网络流中的两个 GPU 之间的数据传输从一个流变为 16 个流。</li>
<li><strong>Enhanced-ECMP（E-ECMP）协议</strong> 通过在 RoCE（Rdma over Converged Ethernet）报头中添加额外的字段，进行 hash 计算，从而有效地在不同网络路径上平衡 16 个流。</li>
</ul>
<h4 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h4><p>使用深度缓冲区（deep-buffer switches）来解决在 Spine（Gangidi et al., 2024）中由于集体通信模式引起的暂时拥堵和缓冲问题。</p>
<h3 id="存储系统"><a href="#存储系统" class="headerlink" title="存储系统"></a>存储系统</h3><p>采用自研的 Tectonic 文件系统，通过 FUSE 提供标准的 Linux 文件系统接口，确保高效的数据访问。</p>
<ul>
<li><strong>存储容量</strong>：240 PB，基于 7,500 台 SSD servers</li>
<li><strong>支持的最大吞吐量</strong>：7 TB/s</li>
<li><strong>支持的可持续吞吐量</strong>：2 TB/s</li>
<li><strong>检查点写入</strong>：非常时断时续，导致存储网络饱和</li>
<li><strong>检查点的目标</strong>：因为 checkpoint 非常大，最小化 GPU 停顿时间，加快检查点频率也变得非常重要</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>从这些实践可以看出，现代 AI 基础设施主要围绕三大核心要素展开：</p>
<ul>
<li>计算能力（以 GPU 为核心）</li>
<li>网络互联（RoCE 或 InfiniBand）</li>
<li>存储系统</li>
</ul>
<p>而在上层的编排调度领域，系统的容错能力和可靠性则成为关键考量因素。</p>
<h2 id="GPU-架构与互联"><a href="#GPU-架构与互联" class="headerlink" title="GPU 架构与互联"></a>GPU 架构与互联</h2><p>在当前AI训练领域，主流的GPU型号主要是NVIDIA的A100、H100和H200系列，它们按照发布时间依次提供了更强大的算力和更优化的架构设计。关于GPU的详细架构，特别是其拓扑结构，可以参考<a target="_blank" rel="noopener" href="https://arthurchiao.art/blog/gpu-advanced-notes-1-zh/">这篇深度解析文章</a>。</p>
<h3 id="GPU互联拓扑"><a href="#GPU互联拓扑" class="headerlink" title="GPU互联拓扑"></a>GPU互联拓扑</h3><p>GPU之间的互联拓扑结构主要取决于不同总线间的传输特性，GPU之间可以通过NVIDIA专有的NVLink高速互联技术直接通信。在现代GPU集群中，主要有以下几种互联方式：</p>
<ol>
<li>NVSwitch架构：通过NVIDIA的交换架构实现所有GPU之间的全互联</li>
<li>走网卡，如果卡之间没有NVSwitch的话，可以绕过CPU走网卡：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GPU0 -&gt; PCIe -&gt; IB(InfiniBand) -&gt; PCIe -&gt; GPU1</span><br></pre></td></tr></table></figure>
这种通信模式由NCCL（NVIDIA Collective Communications Library）负责协调和优化。</li>
</ol>
<h3 id="GPU分配策略"><a href="#GPU分配策略" class="headerlink" title="GPU分配策略"></a>GPU分配策略</h3><p>NVIDIA开源的<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/go-gpuallocator">go-gpuallocator</a>库提供了一系列基于拓扑关系的GPU分配策略。例如，其中的<code>NewStaticDGX1Policy</code>专门针对DGX-1标准配置优化。考虑到单机环境下GPU组合的可能性有限，这种基于静态规则的分配策略已经能够很好地满足需求。</p>
<p>这些分配策略的核心目标是最小化跨总线和跨NUMA节点的通信开销，确保GPU间通信尽可能利用最高带宽的数据通路，从而提供最优的训练性能。</p>
<h3 id="跨节点的通信"><a href="#跨节点的通信" class="headerlink" title="跨节点的通信"></a>跨节点的通信</h3><p>在分布式训练场景下，跨节点通信需要经过更长的数据传输路径：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GPU -&gt; NIC -&gt; 叶层交换机 -&gt; 核心交换机 -&gt; NIC -&gt; GPU</span><br></pre></td></tr></table></figure>

<p>这种通信模式面临两个主要的优化方向：</p>
<ol>
<li><p><strong>本地化优化</strong>：尽可能将相关联的GPU任务分配在物理位置相近的节点上，以减少网络延迟。</p>
</li>
<li><p><strong>负载均衡</strong>：避免将所有任务集中在同一交换机下，防止出现网络拥塞。过度集中可能导致局部带宽饱和，反而降低整体训练效率。</p>
</li>
</ol>
<p>这种权衡本质上是一个网络流优化问题。通过图论中的网络流算法，可以在通信延迟和带宽利用率之间找到最优平衡点，从而实现更高效的跨节点通信。</p>
<p>一个分布式训练的带宽瓶颈来源于带宽最低的那条路径。</p>
<h3 id="利用-Kubernetes-Pod-亲和性优化网络拓扑"><a href="#利用-Kubernetes-Pod-亲和性优化网络拓扑" class="headerlink" title="利用 Kubernetes Pod 亲和性优化网络拓扑"></a>利用 Kubernetes Pod 亲和性优化网络拓扑</h3><p>在 Kubernetes 环境下，我们可以通过 Pod 亲和性（Affinity）和规则来优化 GPU 任务的分配。主要可以从以下几个方面入手：</p>
<p><strong>拓扑感知调度</strong>：使用 <code>topologyKey</code> 确保相关联的 Pod 被调度到网络拓扑上接近的节点：<br>例如同一个分布式训练任务<code>(training-group = group1)</code>尽让分配在一个机架上，同交换机，同核心交换机也是类似的。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">affinity:</span></span><br><span class="line">  <span class="attr">podAffinity:</span></span><br><span class="line">    <span class="attr">preferredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">50</span></span><br><span class="line">      <span class="attr">podAffinityTerm:</span></span><br><span class="line">        <span class="attr">labelSelector:</span></span><br><span class="line">          <span class="attr">matchExpressions:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">training-group</span></span><br><span class="line">            <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">            <span class="attr">values:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">group1</span></span><br><span class="line">        <span class="attr">topologyKey:</span> <span class="string">topology.kubernetes.io/rack</span>  <span class="comment"># 同机架优先</span></span><br></pre></td></tr></table></figure>

<p>这种方案的优势在于：</p>
<ul>
<li>配置简单，易于理解和维护</li>
<li>充分利用 Kubernetes 原生能力，无需额外组件</li>
<li>可以根据实际需求灵活调整权重和策略</li>
</ul>
<h2 id="存储系统-1"><a href="#存储系统-1" class="headerlink" title="存储系统"></a>存储系统</h2><p>AI训练中的存储系统面临着两个主要挑战：</p>
<h3 id="1-海量小文件问题"><a href="#1-海量小文件问题" class="headerlink" title="1. 海量小文件问题"></a>1. 海量小文件问题</h3><p>AI训练数据集通常包含大量的小文件，这对传统文件系统的性能和管理造成了巨大压力。一些现代分布式文件系统提供了很好的解决方案，例如 Meta 的 Tectonic 和与其架构类似的 JuiceFS，它们采用了以下优化方案：</p>
<p><strong>元数据管理优化</strong>：</p>
<ul>
<li>使用元数据库管理文件结构，将 <code>ls</code> 命令转化为简单的字符串前缀匹配操作</li>
<li>避免了传统 Linux 文件系统依赖 inode 管理的方式</li>
<li>解决了 inode 臃肿问题（在传统系统中，一个 inode 的大小可能与文件本身相当）</li>
</ul>
<h3 id="2-Checkpoint-存储挑战"><a href="#2-Checkpoint-存储挑战" class="headerlink" title="2. Checkpoint 存储挑战"></a>2. Checkpoint 存储挑战</h3><p>分布式训练中的 checkpoint 文件体积巨大，这在大语言模型训练中尤为明显：</p>
<ul>
<li>以 LLaMA-2-70B 为例，单个完整的 checkpoint 就需要 140GB 存储空间（FP16格式）</li>
<li>训练过程中需要定期保存 checkpoint，累积存储需求可能达到 TB 甚至 PB 级别</li>
<li>需要存储系统能够提供高带宽和低延迟的读写性能，同时保证数据的可靠性</li>
</ul>
<p>这些挑战要求存储系统具备：</p>
<ul>
<li>强大的扩展性</li>
<li>高效的数据压缩能力</li>
<li>智能的数据分层存储机制</li>
<li>可靠的数据备份和恢复能力</li>
</ul>
<h2 id="训练的稳定性"><a href="#训练的稳定性" class="headerlink" title="训练的稳定性"></a>训练的稳定性</h2><p>在大规模 AI 训练中，硬件故障是一个常见问题。特别是新型号显卡往往会有较高的故障率，再加上传统的硬件错误，这些都可能导致训练中断。因此，快速识别错误并恢复训练成为了一个关键挑战。目前主流的解决方案主要有以下两种：</p>
<h3 id="基于-torchrun-的弹性训练"><a href="#基于-torchrun-的弹性训练" class="headerlink" title="基于 torchrun 的弹性训练"></a>基于 torchrun 的弹性训练</h3><p>torchrun 提供了两种容错机制：简单重试和弹性训练。</p>
<ol>
<li><p><strong>简单重试模式</strong>：<br>通过 <code>--max-restarts</code> 参数配置重试次数：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">torchrun \</span><br><span class="line">    --nnodes=<span class="variable">$NUM_NODES</span> \</span><br><span class="line">    --nproc-per-node=<span class="variable">$NUM_TRAINERS</span> \</span><br><span class="line">    --max-restarts=3 \</span><br><span class="line">    --rdzv-id=<span class="variable">$JOB_ID</span> \</span><br><span class="line">    --rdzv-backend=c10d \</span><br><span class="line">    --rdzv-endpoint=<span class="variable">$HOST_NODE_ADDR</span> \</span><br><span class="line">    YOUR_TRAINING_SCRIPT.py [script args...]</span><br></pre></td></tr></table></figure></li>
<li><p><strong>弹性训练模式</strong>：<br>通过设置 <code>nnodes</code> 的范围来支持动态节点数：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">torchrun \</span><br><span class="line">    --nnodes=1:4 \  <span class="comment"># 支持1-4个节点的动态伸缩</span></span><br><span class="line">    --nproc-per-node=<span class="variable">$NUM_TRAINERS</span> \</span><br><span class="line">    --max-restarts=3 \</span><br><span class="line">    --rdzv-id=<span class="variable">$JOB_ID</span> \</span><br><span class="line">    --rdzv-backend=c10d \</span><br><span class="line">    --rdzv-endpoint=<span class="variable">$HOST_NODE_ADDR</span> \</span><br><span class="line">    YOUR_TRAINING_SCRIPT.py [script args...]</span><br></pre></td></tr></table></figure></li>
</ol>
<p>弹性训练模式需要配置服务发现机制，默认使用 c10d 作为内置的节点发现服务，也支持使用 etcd 等外部服务。</p>
<p>当节点发生变化时，系统会自动处理以下场景：</p>
<ul>
<li><strong>节点离开（缩容）</strong>：系统通知 agent，停止现有 workers，重新组建 WorkerGroup，使用新的 RANK 和 WORLD_SIZE 启动所有 workers</li>
<li><strong>节点加入（扩容）</strong>：接纳新节点，按照相同流程重组 WorkerGroup</li>
</ul>
<h3 id="基于-DeepSpeed-的弹性训练"><a href="#基于-DeepSpeed-的弹性训练" class="headerlink" title="基于 DeepSpeed 的弹性训练"></a>基于 DeepSpeed 的弹性训练</h3><p>DeepSpeed 提供了更细粒度的弹性训练配置：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;elasticity&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;enabled&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;max_train_batch_size&quot;</span><span class="punctuation">:</span> <span class="string">&quot;seqlen&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;micro_batch_sizes&quot;</span><span class="punctuation">:</span> <span class="number">8</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;min_gpus&quot;</span><span class="punctuation">:</span> <span class="number">1024</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;max_gpus&quot;</span><span class="punctuation">:</span> <span class="string">&quot;fixed_linear&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;min_time&quot;</span><span class="punctuation">:</span> <span class="string">&quot;seqlen&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="number">8</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;ignore_non_elastic_batch_info&quot;</span><span class="punctuation">:</span> <span class="number">1024</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;num_gpus_per_node&quot;</span><span class="punctuation">:</span> <span class="string">&quot;fixed_linear&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;model_parallel_size&quot;</span><span class="punctuation">:</span> MODEL_PARALLEL_SIZE</span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>DeepSpeed 的特点是：</p>
<ul>
<li>支持动态调整 batch size</li>
<li>以 GPU 为粒度进行弹性伸缩（而不是节点级别）</li>
<li>提供更丰富的训练参数配置</li>
</ul>
<h3 id="弹性训练控制器"><a href="#弹性训练控制器" class="headerlink" title="弹性训练控制器"></a>弹性训练控制器</h3><p>要实现完整的弹性训练支持，控制器需要：</p>
<ol>
<li>依赖服务发现机制进行节点注册和健康检查</li>
<li>动态调整弹性策略（如 min_nodes、max_nodes 等参数）</li>
</ol>
<p>对于简单的降级场景，通过静态配置即可实现：</p>
<ul>
<li>将 max_nodes 设置为总资源规格</li>
<li>将 min_nodes 设置为最小运行要求（如设置为 1:4 表示支持 1-4 张显卡的动态伸缩）</li>
</ul>
<h3 id="节点的问题发现"><a href="#节点的问题发现" class="headerlink" title="节点的问题发现"></a>节点的问题发现</h3><p>在大规模语言模型（LLM）预训练过程中，常见的硬件异常包括：</p>
<ol>
<li><p><strong>GPU ECC 错误</strong>：当 GPU 发生不可纠正的显存 ECC（Error Correcting Code）错误时，通常需要重置 GPU 或重启节点来清除这个错误。 </p>
</li>
<li><p><strong>Infiniband（IB）/NCCL 问题</strong>：这类问题通常源于硬件故障，如网卡损坏或网络抖动，可能导致训练速度下降或任务异常中断。</p>
</li>
<li><p><strong>任务挂起（Hang）</strong>：通常与 IB/NCCL 问题相关，需要人工检测和处理。</p>
</li>
<li><p><strong>GPU 掉卡</strong>：此时一般会触发 CUDA 错误或程序异常退出，可能需要重置 GPU 或重启节点来解决。</p>
</li>
<li><p><strong>机器异常</strong>：包括 GPU 之外的硬件异常，如硬盘、CPU 等，甚至整机故障，可能需要更换硬件或进行系统维护。</p>
</li>
<li><p><strong>机器配置异常</strong>：例如，某台机器意外启用了 MIG（多实例 GPU），可能影响训练任务的正常运行。</p>
</li>
<li><p><strong>集群维护</strong>：集群中的其他任务或系统维护、升级，可能需要暂停当前训练任务。</p>
</li>
</ol>
<p>可以使用<a target="_blank" rel="noopener" href="https://github.com/kubernetes/node-problem-detector">node-promblem-detector</a>，<br>node-problem-detector 是一个用于在集群管理栈的上游层次中使各个节点问题可见的守护进程。它在每个节点上运行，检测节点问题并将其报告给 apiserver。</p>
<p>监控和容错是一个比较难的问题，需要结合硬件和软件的特性，以及业务需求，进行综合考量。<br>特别是万卡集群，MFU 只有 50%左右。</p>
<p>在训练 OPT-175B 模型的过程中，Meta团队使用了 992 个 80GB 的 A100 GPU，每个 GPU 实现了约 147 TFLOP/s 的性能，对应的机器浮点利用率（MFU）约为 47%（147/312）。 </p>
<p>为了应对可能的硬件故障，团队额外准备了 12 台备用机器，以便在出现问题时进行替换。在训练期间，平均每天约有 2 台机器发生故障，即每台机器每天发生故障的概率约为 1.61%。</p>
<p>整个训练过程持续了约 2 个多月，包括从 2021 年 10 月 20 日到 2021 年 11 月 11 日的测试阶段，以及从 2021 年 11 月 11 日到 2022 年 1 月 6 日的正式训练阶段，正式训练约 57 天。</p>
<p>根据预估，实际训练时间应为约 25 天，但由于各种问题，实际有效训练时间仅占总时间的约 44%。在前期，由于各种问题，团队至少手动重启了 35 次任务。为减少人工干预，后续引入了自动重启机制，但由于硬件故障，仍触发了超过 70 次重启，平均每天需要重启一次任务。</p>
<p>这些经验表明，在大规模模型训练中，硬件故障和其他问题会显著影响训练效率。为此，团队采取了多种措施来应对这些挑战，包括准备备用硬件、引入自动重启机制等，以确保训练过程的顺利进行。  </p>
<p>这个问题在用新的卡的时候会有更多问题。</p>
<h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><blockquote>
<p>To train our largest Llama 3 models, we combined three types of parallelization: data parallelization, model parallelization, and pipeline parallelization. Our most efficient implementation achieves a compute utilization of over 400 TFLOPS per GPU when trained on 16K GPUs simultaneously. We performed training runs on two custom-built 24K GPU clusters. To maximize GPU uptime, we developed an advanced new training stack that automates error detection, handling, and maintenance. We also greatly improved our hardware reliability and detection mechanisms for silent data corruption, and we developed new scalable storage systems that reduce overheads of checkpointing and rollback. Those improvements resulted in an overall effective training time of more than 95%. Combined, these improvements increased the efficiency of Llama 3 training by ~three times compared to Llama 2.</p>
</blockquote>
<p>LLAMA3 的<a target="_blank" rel="noopener" href="https://ai.meta.com/blog/meta-llama-3/">技术博客</a>揭示了许多令人振奋的优化成果，这些优化背后蕴含着大量值得深入研究的技术细节。虽然我们可能难以直接接触如此大规模的训练集群及其面临的挑战，但这些技术进展仍然为整个 AI 基础设施领域提供了宝贵的参考和启发。</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/AI/" rel="tag"># AI</a>
              <a href="/tags/Infra/" rel="tag"># Infra</a>
              <a href="/tags/AI-Infra/" rel="tag"># AI Infra</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/zh-CN/2025/01/24/CacheBlend%E5%88%86%E6%9E%90/" rel="prev" title="CacheBlend分析">
                  <i class="fa fa-angle-left"></i> CacheBlend分析
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/zh-CN/2025/03/19/Triton%E4%BD%BF%E7%94%A8%E5%92%8CSoftmax%E5%AE%9E%E7%8E%B0/" rel="next" title="Triton使用和Softmax实现">
                  Triton使用和Softmax实现 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    
  <div class="comments" id="disqus_thread">
    <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
  </div>
  
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2014 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">ggaaooppeenngg</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.umd.js" integrity="sha256-a+H7FYzJv6oU2hfsfDGM2Ohw/cR9v+hPfxHCLdmCrE8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  



  <script src="/js/third-party/fancybox.js"></script>



  




<script class="next-config" data-name="disqus" type="application/json">{"enable":true,"shortname":"ggaaooppeenngg","count":true,"i18n":{"disqus":"disqus"}}</script>
<script src="/js/third-party/comments/disqus.js"></script>

</body>
</html>
